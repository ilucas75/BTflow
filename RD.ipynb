{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "beed069e67d94e97992c55a952131d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10645098459b426a9e4c2a3d54896121",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9035f108395c405ca0e84571ec9fc9aa",
              "IPY_MODEL_0461130cca1e45c98535d547bdac394c"
            ]
          }
        },
        "10645098459b426a9e4c2a3d54896121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9035f108395c405ca0e84571ec9fc9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_792d2132b2524181951ec27ad0d40271",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 637,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 637,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_397033f9c84d481b9afa61de5f522036"
          }
        },
        "0461130cca1e45c98535d547bdac394c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee85d4ec9d7c4a6ca5c20e56d15453d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 637/637 [00:15&lt;00:00, 39.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1ee12f4abe64849ae3f1d6038a7284c"
          }
        },
        "792d2132b2524181951ec27ad0d40271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "397033f9c84d481b9afa61de5f522036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee85d4ec9d7c4a6ca5c20e56d15453d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1ee12f4abe64849ae3f1d6038a7284c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2164c3967314b8f8cd7ab5da4277896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d98f409801d4bc8bbf2fa350e39b24d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c735862484944b25bbd1f8ee6290e1c4",
              "IPY_MODEL_44df3a67cc224c22bb3f80b183c98ec5"
            ]
          }
        },
        "1d98f409801d4bc8bbf2fa350e39b24d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c735862484944b25bbd1f8ee6290e1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17a0df3496c7481593344ec64c96b65d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 545172724,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 545172724,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3dfbf01c4ac427db61d28c8a191dca9"
          }
        },
        "44df3a67cc224c22bb3f80b183c98ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37b6869bb4d54ab28328b8fe62dc0152",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 545M/545M [00:14&lt;00:00, 36.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a21027aa6a44d3c9e2da18a54dac427"
          }
        },
        "17a0df3496c7481593344ec64c96b65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3dfbf01c4ac427db61d28c8a191dca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37b6869bb4d54ab28328b8fe62dc0152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a21027aa6a44d3c9e2da18a54dac427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilucas75/BTflow/blob/dev/RD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiFWWecB8meR",
        "colab_type": "text"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEcyr9cyjnct",
        "colab_type": "code",
        "outputId": "3f0d76cd-8adb-4de0-b38b-94d51504f2a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pdfminer.six\n",
        "!pip install spacy\n",
        "!pip install tabula-py\n",
        "!python -m spacy download fr_core_news_md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfminer.six\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/04/f62d5834c2bdf90afcaeb23bb5241033c44e27000de64ad8472253daa4a8/pdfminer.six-20200402-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.6/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Collecting pycryptodome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/16/da16a22d47bac9bf9db39f3b9af74e8eeed8855c0df96be20b580ef92fff/pycryptodome-3.9.7-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 235kB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from pdfminer.six) (2.1.0)\n",
            "Installing collected packages: pycryptodome, pdfminer.six\n",
            "Successfully installed pdfminer.six-20200402 pycryptodome-3.9.7\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Collecting tabula-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/a4/66add528eca00398af98f181772006750019eb9f2d68c7c6fdd53ba661c5/tabula_py-2.1.0-py3-none-any.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from tabula-py) (1.0.3)\n",
            "Collecting distro\n",
            "  Downloading https://files.pythonhosted.org/packages/25/b7/b3c4270a11414cb22c6352ebc7a83aaa3712043be29daa05018fd5a5c956/distro-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tabula-py) (1.18.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25.3->tabula-py) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.25.3->tabula-py) (1.12.0)\n",
            "Installing collected packages: distro, tabula-py\n",
            "Successfully installed distro-1.5.0 tabula-py-2.1.0\n",
            "Collecting fr_core_news_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.2.5/fr_core_news_md-2.2.5.tar.gz (88.6MB)\n",
            "\u001b[K     |████████████████████████████████| 88.6MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-md\n",
            "  Building wheel for fr-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-md: filename=fr_core_news_md-2.2.5-cp36-none-any.whl size=90338488 sha256=851d62daff56c4ed9f8e869ca54e8af769063f991cf8d6731a3c056e46f16412\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2dlaednj/wheels/c6/18/b6/f628642acc7872a53cf81269dd1c394d96da69564ccfac5425\n",
            "Successfully built fr-core-news-md\n",
            "Installing collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teO5hnSS8Dj3",
        "colab_type": "text"
      },
      "source": [
        "## Upload PDF and Json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBtUJahtkUKq",
        "colab_type": "code",
        "outputId": "7c07841f-d357-4af9-8044-3e49ee5ce296",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-05d544a5-4948-43a5-92fa-1a4c14ed998e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-05d544a5-4948-43a5-92fa-1a4c14ed998e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 0070C022_220C0700.json to 0070C022_220C0700.json\n",
            "Saving 0340C022_220C0430.json to 0340C022_220C0430.json\n",
            "Saving 0510C022_220C0150.json to 0510C022_220C0150.json\n",
            "Saving 0540C022_220C0450.json to 0540C022_220C0450.json\n",
            "Saving 0620C022_220C0260.json to 0620C022_220C0260.json\n",
            "Saving 0810C022_220C0180.json to 0810C022_220C0180.json\n",
            "Saving 0820C022_220C0280.json to 0820C022_220C0280.json\n",
            "Saving 0900C022_220C0090.json to 0900C022_220C0090.json\n",
            "Saving 0940C022_220C0490.json to 0940C022_220C0490.json\n",
            "Saving 0960C022_220C0690.json to 0960C022_220C0690.json\n",
            "Saving 0980C022_220C0890.json to 0980C022_220C0890.json\n",
            "Saving 1040C022_220C0401.json to 1040C022_220C0401.json\n",
            "Saving 1080C022_220C0801.json to 1080C022_220C0801.json\n",
            "Saving 1090C022_220C0901.json to 1090C022_220C0901.json\n",
            "Saving 1200C022_220C0021.json to 1200C022_220C0021.json\n",
            "Saving 1270C022_220C0721.json to 1270C022_220C0721.json\n",
            "Saving 1360C022_220C0631.json to 1360C022_220C0631.json\n",
            "Saving 1380C022_220C0831.json to 1380C022_220C0831.json\n",
            "Saving 1430C022_220C0341.json to 1430C022_220C0341.json\n",
            "Saving 1500C022_220C0051.json to 1500C022_220C0051.json\n",
            "Saving 1550C022_220C0551.json to 1550C022_220C0551.json\n",
            "Saving 1640C022_220C0461.json to 1640C022_220C0461.json\n",
            "Saving 1960C022_220C0691.json to 1960C022_220C0691.json\n",
            "Saving 1980C022_220C0891.json to 1980C022_220C0891.json\n",
            "Saving 2030C022_220C0302.json to 2030C022_220C0302.json\n",
            "Saving 2080C022_220C0802.json to 2080C022_220C0802.json\n",
            "Saving 2090C022_220C0902.json to 2090C022_220C0902.json\n",
            "Saving 2260C022_220C0622.json to 2260C022_220C0622.json\n",
            "Saving 2410C022_220C0142.json to 2410C022_220C0142.json\n",
            "Saving 2550C022_220C0552.json to 2550C022_220C0552.json\n",
            "Saving 2620C022_220C0262.json to 2620C022_220C0262.json\n",
            "Saving 2640C022_220C0462.json to 2640C022_220C0462.json\n",
            "Saving 2920C022_220C0292.json to 2920C022_220C0292.json\n",
            "Saving 3040C022_220C0403.json to 3040C022_220C0403.json\n",
            "Saving 3060C022_220C0603.json to 3060C022_220C0603.json\n",
            "Saving 3080C022_220C0803.json to 3080C022_220C0803.json\n",
            "Saving 3090C022_220C0903.json to 3090C022_220C0903.json\n",
            "Saving 3100C022_220C0013.json to 3100C022_220C0013.json\n",
            "Saving 3170C022_220C0713.json to 3170C022_220C0713.json\n",
            "Saving 3190C022_220C0913.json to 3190C022_220C0913.json\n",
            "Saving 3200C022_220C0023.json to 3200C022_220C0023.json\n",
            "Saving 3270C022_220C0723.json to 3270C022_220C0723.json\n",
            "Saving 3310C022_220C0133.json to 3310C022_220C0133.json\n",
            "Saving 3350C022_220C0533.json to 3350C022_220C0533.json\n",
            "Saving 3460C022_220C0643.json to 3460C022_220C0643.json\n",
            "Saving 3540C022_220C0453.json to 3540C022_220C0453.json\n",
            "Saving 3570C022_220C0753.json to 3570C022_220C0753.json\n",
            "Saving 3610C022_220C0163.json to 3610C022_220C0163.json\n",
            "Saving 3620C022_220C0263.json to 3620C022_220C0263.json\n",
            "Saving 3710C022_220C0173.json to 3710C022_220C0173.json\n",
            "Saving 3770C022_220C0773.json to 3770C022_220C0773.json\n",
            "Saving 3810C022_220C0183.json to 3810C022_220C0183.json\n",
            "Saving 3830C022_220C0383.json to 3830C022_220C0383.json\n",
            "Saving 3950C022_220C0593.json to 3950C022_220C0593.json\n",
            "Saving 4040C022_220C0404.json to 4040C022_220C0404.json\n",
            "Saving 4060C022_220C0604.json to 4060C022_220C0604.json\n",
            "Saving 4170C022_220C0714.json to 4170C022_220C0714.json\n",
            "Saving 4280C022_220C0824.json to 4280C022_220C0824.json\n",
            "Saving 4480C022_220C0844.json to 4480C022_220C0844.json\n",
            "Saving 4530C022_220C0354.json to 4530C022_220C0354.json\n",
            "Saving 4540C022_220C0454.json to 4540C022_220C0454.json\n",
            "Saving 4620C022_220C0264.json to 4620C022_220C0264.json\n",
            "Saving 4630C022_220C0364.json to 4630C022_220C0364.json\n",
            "Saving 4870C022_220C0784.json to 4870C022_220C0784.json\n",
            "Saving 4960C022_220C0694.json to 4960C022_220C0694.json\n",
            "Saving 5100C022_220C0015.json to 5100C022_220C0015.json\n",
            "Saving 5140C022_220C0415.json to 5140C022_220C0415.json\n",
            "Saving 5300C022_220C0035.json to 5300C022_220C0035.json\n",
            "Saving 5330C022_220C0335.json to 5330C022_220C0335.json\n",
            "Saving 5380C022_220C0835.json to 5380C022_220C0835.json\n",
            "Saving 5440C022_220C0445.json to 5440C022_220C0445.json\n",
            "Saving 5480C022_220C0845.json to 5480C022_220C0845.json\n",
            "Saving 5600C022_220C0065.json to 5600C022_220C0065.json\n",
            "Saving 5650C022_220C0565.json to 5650C022_220C0565.json\n",
            "Saving 5930C022_220C0395.json to 5930C022_220C0395.json\n",
            "Saving 5960C022_220C0695.json to 5960C022_220C0695.json\n",
            "Saving 6060C022_220C0606.json to 6060C022_220C0606.json\n",
            "Saving 6240C022_220C0426.json to 6240C022_220C0426.json\n",
            "Saving 6340C022_220C0436.json to 6340C022_220C0436.json\n",
            "Saving 6350C022_220C0536.json to 6350C022_220C0536.json\n",
            "Saving 6360C022_220C0636.json to 6360C022_220C0636.json\n",
            "Saving 6620C022_220C0266.json to 6620C022_220C0266.json\n",
            "Saving 6650C022_220C0566.json to 6650C022_220C0566.json\n",
            "Saving 6720C022_220C0276.json to 6720C022_220C0276.json\n",
            "Saving 7120C022_220C0217.json to 7120C022_220C0217.json\n",
            "Saving 7230C022_220C0327.json to 7230C022_220C0327.json\n",
            "Saving 7320C022_220C0237.json to 7320C022_220C0237.json\n",
            "Saving 7350C022_220C0537.json to 7350C022_220C0537.json\n",
            "Saving 7480C022_220C0847.json to 7480C022_220C0847.json\n",
            "Saving 7570C022_220C0757.json to 7570C022_220C0757.json\n",
            "Saving 7620C022_220C0267.json to 7620C022_220C0267.json\n",
            "Saving 7780C022_220C0877.json to 7780C022_220C0877.json\n",
            "Saving 7800C022_220C0087.json to 7800C022_220C0087.json\n",
            "Saving 7820C022_220C0287.json to 7820C022_220C0287.json\n",
            "Saving 7910C022_220C0197.json to 7910C022_220C0197.json\n",
            "Saving 8030C022_220C0308.json to 8030C022_220C0308.json\n",
            "Saving 8120C022_220C0218.json to 8120C022_220C0218.json\n",
            "Saving 8140C022_220C0418.json to 8140C022_220C0418.json\n",
            "Saving 8330C022_220C0338.json to 8330C022_220C0338.json\n",
            "Saving 8340C022_220C0438.json to 8340C022_220C0438.json\n",
            "Saving 8350C022_220C0538.json to 8350C022_220C0538.json\n",
            "Saving 8400C022_220C0048.json to 8400C022_220C0048.json\n",
            "Saving 8430C022_220C0348.json to 8430C022_220C0348.json\n",
            "Saving 8470C022_220C0748.json to 8470C022_220C0748.json\n",
            "Saving 8570C022_220C0758.json to 8570C022_220C0758.json\n",
            "Saving 8780C022_220C0878.json to 8780C022_220C0878.json\n",
            "Saving 8840C022_220C0488.json to 8840C022_220C0488.json\n",
            "Saving 8850C022_220C0588.json to 8850C022_220C0588.json\n",
            "Saving 8980C022_220C0898.json to 8980C022_220C0898.json\n",
            "Saving 9140C022_220C0419.json to 9140C022_220C0419.json\n",
            "Saving 9150C022_220C0519.json to 9150C022_220C0519.json\n",
            "Saving 9320C022_220C0239.json to 9320C022_220C0239.json\n",
            "Saving 9330C022_220C0339.json to 9330C022_220C0339.json\n",
            "Saving 9530C022_220C0359.json to 9530C022_220C0359.json\n",
            "Saving 9610C022_220C0169.json to 9610C022_220C0169.json\n",
            "Saving 9670C022_220C0769.json to 9670C022_220C0769.json\n",
            "Saving 9900C022_220C0099.json to 9900C022_220C0099.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8gfeF9kR3E",
        "colab_type": "code",
        "outputId": "3485b324-606c-4c99-9502-7f53a64fad48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset.json  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkxF_Nod7OcP",
        "colab_type": "text"
      },
      "source": [
        "## Table PDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXNXlRcB4aJK",
        "colab_type": "code",
        "outputId": "2a33522a-9e0a-4794-ebb4-faa418713959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from tabula import read_pdf\n",
        "import pandas as pd\n",
        "\n",
        "def extract_tables(filename):\n",
        "  dfs = read_pdf(list_pdf[0], pages='all')\n",
        "  tables_str = []\n",
        "  for df in dfs:\n",
        "  if not df.empty:\n",
        "    table_str = \"\"\n",
        "    for c in df.columns:\n",
        "      if not \"Unnamed:\" in c:\n",
        "        table_str += c + \" \"\n",
        "    for _, r in df.iterrows():\n",
        "      for c in df.columns:\n",
        "        if pd.notna(r[c]):\n",
        "          table_str += r[c] + \" \"\n",
        "    tables_str.append(table_str)\n",
        "  return dfs, tables_str"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got stderr: Mar 31, 2020 7:14:33 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSerif' for 'TimesNewRomanPSMT'\n",
            "Mar 31, 2020 7:14:33 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSerif-Bold' for 'TimesNewRomanPS-BoldMT'\n",
            "Mar 31, 2020 7:14:33 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSerif-Italic' for 'TimesNewRomanPS-ItalicMT'\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Xzx42u7wXi",
        "colab_type": "text"
      },
      "source": [
        "## Extract PDF text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0YioujofEk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        " \n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer.pdfinterp import PDFResourceManager\n",
        "from pdfminer.pdfpage import PDFPage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hYsJfqyvELy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    resource_manager = PDFResourceManager()\n",
        "    fake_file_handle = io.StringIO()\n",
        "    converter = TextConverter(resource_manager, fake_file_handle)\n",
        "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
        " \n",
        "    with open(pdf_path, 'rb') as fh:\n",
        "        for page in PDFPage.get_pages(fh, \n",
        "                                      caching=True,\n",
        "                                      check_extractable=True):\n",
        "            page_interpreter.process_page(page)\n",
        " \n",
        "        text = fake_file_handle.getvalue()\n",
        " \n",
        "    # close open handles\n",
        "    converter.close()\n",
        "    fake_file_handle.close()\n",
        " \n",
        "    if text:\n",
        "        return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_Wnrm2J6GyI",
        "colab_type": "text"
      },
      "source": [
        "## Load PDF and Json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpm_Cs4vb24P",
        "colab_type": "code",
        "outputId": "f89b6592-9b92-4b7a-bf86-f2cd7f076faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "import os \n",
        "\n",
        "data = {}\n",
        "data_label = {}\n",
        "data_no_label = {}\n",
        "\n",
        "for f in uploaded.keys():\n",
        "  try:\n",
        "    name, ext = os.path.splitext(f)\n",
        "    if ext == '.pdf' and name not in pdfs:\n",
        "      text=extract_text_from_pdf(f)\n",
        "      if \"Déclaration de franchissement de seuils\" in text:\n",
        "        x =  {\"file\": f, \"text\": text}\n",
        "        data[name] = x\n",
        "        data_no_label[name] = x\n",
        "    elif ext == '.json':\n",
        "      with open(f) as fd:\n",
        "        x = json.load(fd)\n",
        "        data[name] = x\n",
        "        if 'entities' in x and len(x['entities']) != 0:\n",
        "          data_label[name] = x\n",
        "          if name in data_no_label:\n",
        "            del data_no_label[name]\n",
        "        else:\n",
        "          data_no_label[name] = x\n",
        "  except Exception as e:\n",
        "    print(\"Error : \", f)\n",
        "    print(e)\n",
        "data = [v for k, v in sorted(data.items(), key=lambda t: t[0])]\n",
        "data_label = [v for k, v in sorted(data_label.items(), key=lambda t: t[0])]\n",
        "data_no_label = [v for k, v in sorted(data_no_label.items(), key=lambda t: t[0])]\n",
        "print(len(data), \"texts with\", len(data_label), \"labeled and\", len(data_no_label), 'to label')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "117 texts with 117 labeled and 0 to label\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp1hEiec6inO",
        "colab_type": "text"
      },
      "source": [
        "## Labellisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddtCboWtjHe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "import os\n",
        "\n",
        "class AnnotWidget():\n",
        "  def __init__(self, to_annot, start=0, model=None):\n",
        "    self.to_annot = to_annot\n",
        "    self.cur = start\n",
        "    self.model = model\n",
        "    self.colors_labels = [\n",
        "        (\"rgb(255, 0, 0)\", \"ISSUER\", 'A'),\n",
        "        (\"rgb(255, 0, 255)\", \"FIRM\", 'Z'),\n",
        "        (\"rgb(0, 255, 255)\", \"NUMBER\", 'E'),\n",
        "        (\"rgb(160, 160, 255)\", \"PERCENT\", 'R'),\n",
        "        (\"rgb(192, 192, 192)\", \"TYPE\", 'T'),\n",
        "        (\"rgb(255, 255, 0)\", \"DIRECTION\", 'S'),\n",
        "        (\"rgb(0, 255, 0)\", \"DATE\", 'D'),\n",
        "        (\"rgb(255, 180, 180)\", \"FILIALE\", 'F'),\n",
        "        (\"rgb(230, 171, 0)\", 'INSTRUMENT', 'G')\n",
        "      ]\n",
        "    self.controls = \"\"\n",
        "    for c, l, k in self.colors_labels:\n",
        "      self.controls += '''<button id=\"key_'''+k+'''\" style=\"background-color: '''+\\\n",
        "        c+''';\" onclick='document.execCommand(\"backColor\", false, \"'''+c+'''\")'>'''+l+\" (\"+k+\")</button>\"\n",
        "\n",
        "  def text_entities_to_html(self):\n",
        "    if 'entities' not in self.to_annot[self.cur] or len(self.to_annot[self.cur]['entities']) == 0:\n",
        "      return self.to_annot[self.cur][\"text\"]\n",
        "    res = \"\"\n",
        "    offset = 0\n",
        "    text = self.to_annot[self.cur][\"text\"]\n",
        "    for ent_s, ent_e, label in self.to_annot[self.cur]['entities']:\n",
        "      res += text[offset:ent_s]\n",
        "      res += '''<span style=\"background-color: '''+ self.get_color(label) + '''\">'''\n",
        "      res += text[ent_s:ent_e]\n",
        "      res += \"</span>\"\n",
        "      offset = ent_e\n",
        "    res += text[offset:]\n",
        "    return res\n",
        "\n",
        "  def run(self):\n",
        "    display(IPython.display.HTML('''\n",
        "    <p>'''+str(self.cur) + \"/\" + str(len(self.to_annot)) + '''</p>\n",
        "    <fieldset>\n",
        "    '''+ self.controls +'''\n",
        "      <button id=\"key_Q\" onclick=\"document.execCommand('removeFormat', false, null)\">remove (Q)</button>\n",
        "      <button id=\"key_P\" onclick=\"google.colab.kernel.invokeFunction('notebook.Prediction');\">pred (P)</button>\n",
        "      <button id='prev'>prev</button>\n",
        "      <button id='next'>next</button>\n",
        "    </fieldset>\n",
        "    <div id=\"ed\" contenteditable=\"true\">'''+self.text_entities_to_html()+'''</div>\n",
        "    <script>\n",
        "      function change(dir) {\n",
        "        children = document.querySelector(\"#ed\").childNodes;\n",
        "        res = [];\n",
        "        offset = 0;\n",
        "        for (var i = 0; i < children.length; i++) {\n",
        "          next_offset = offset + children[i].textContent.length;\n",
        "          if (children[i].nodeType != Node.TEXT_NODE) {\n",
        "            rgb = children[i].style.backgroundColor\n",
        "            res.push([offset, next_offset, rgb])\n",
        "          }\n",
        "          offset = next_offset;\n",
        "        }\n",
        "        google.colab.kernel.invokeFunction('notebook.SaveEntities', [res, dir]);\n",
        "        document.querySelector('#ed').innerHTML = next_text;\n",
        "      };\n",
        "      document.querySelector('#prev').onclick = () => {\n",
        "        change(-1);\n",
        "      };\n",
        "      document.querySelector('#next').onclick = () => {\n",
        "        change(1);\n",
        "      };\n",
        "      document.querySelector('#ed').onkeydown = (ev) => {\n",
        "        ev.preventDefault();\n",
        "      };\n",
        "      document.querySelector('#ed').onkeypress = (ev) => {\n",
        "        ev.preventDefault();\n",
        "      };\n",
        "      document.querySelector('#ed').onkeyup = (ev) => {\n",
        "        ev.preventDefault();\n",
        "        button_id = \"#key_\" + String.fromCharCode(ev.keyCode);\n",
        "        button = document.querySelector(button_id)\n",
        "        if (button) {\n",
        "          button.click();\n",
        "        }\n",
        "      };\n",
        "    </script>\n",
        "    '''))\n",
        "    output.register_callback('notebook.SaveEntities', self.save_entities)\n",
        "    output.register_callback('notebook.Console', self.console)\n",
        "    output.register_callback('notebook.Prediction', self.prediction)\n",
        "\n",
        "  def get_color(self, label):\n",
        "    for c, l, _ in self.colors_labels:\n",
        "        if l == label:\n",
        "          return c\n",
        "\n",
        "  def get_label(self, color):\n",
        "    for c, l, _ in self.colors_labels:\n",
        "        if c == color:\n",
        "          return l\n",
        "\n",
        "  def save_entities(self, res, inc=1):\n",
        "    self.to_annot[self.cur]['entities'] = []\n",
        "    for ent_s, ent_e, color in res:\n",
        "      self.to_annot[self.cur]['entities'].append((ent_s, ent_e, self.get_label(color)))\n",
        "    if len(self.to_annot[self.cur]['entities']) != 0:\n",
        "      name, _ = os.path.splitext(self.to_annot[self.cur]['file'])\n",
        "      with open(name+'.json', 'w+') as f:\n",
        "        json.dump(self.to_annot[self.cur], f)\n",
        "    print(\"hello\")\n",
        "    output.clear()\n",
        "    if (self.cur < len(self.to_annot) and inc == 1) or (self.cur > 0 and inc == -1):\n",
        "      self.cur += inc\n",
        "    self.run()\n",
        "\n",
        "  def console(self, s):\n",
        "    print(s)\n",
        "\n",
        "  def prediction(self):\n",
        "    if (self.model is not None) and (('entities' not in self.to_annot[self.cur]) or (len(self.to_annot[self.cur]['entities']) == 0)):\n",
        "      doc = self.model(self.to_annot[self.cur][\"text\"])\n",
        "      self.to_annot[self.cur]['entities'] = []\n",
        "      for ent in doc.ents:\n",
        "        self.to_annot[self.cur]['entities'].append([ent.start_char, ent.end_char, ent.label_])\n",
        "      output.clear()\n",
        "      self.run()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj65OVbhWrac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = AnnotWidget(data, start=0, model=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQLXIHWSnAUG",
        "colab_type": "code",
        "outputId": "fccfadec-022a-4e61-b7a4-087c079de662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "w.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <p>0/117</p>\n",
              "    <fieldset>\n",
              "    <button id=\"key_A\" style=\"background-color: rgb(255, 0, 0);\" onclick='document.execCommand(\"backColor\", false, \"rgb(255, 0, 0)\")'>ISSUER (A)</button><button id=\"key_Z\" style=\"background-color: rgb(255, 0, 255);\" onclick='document.execCommand(\"backColor\", false, \"rgb(255, 0, 255)\")'>FIRM (Z)</button><button id=\"key_E\" style=\"background-color: rgb(0, 255, 255);\" onclick='document.execCommand(\"backColor\", false, \"rgb(0, 255, 255)\")'>NUMBER (E)</button><button id=\"key_R\" style=\"background-color: rgb(160, 160, 255);\" onclick='document.execCommand(\"backColor\", false, \"rgb(160, 160, 255)\")'>PERCENT (R)</button><button id=\"key_T\" style=\"background-color: rgb(192, 192, 192);\" onclick='document.execCommand(\"backColor\", false, \"rgb(192, 192, 192)\")'>TYPE (T)</button><button id=\"key_S\" style=\"background-color: rgb(255, 255, 0);\" onclick='document.execCommand(\"backColor\", false, \"rgb(255, 255, 0)\")'>DIRECTION (S)</button><button id=\"key_D\" style=\"background-color: rgb(0, 255, 0);\" onclick='document.execCommand(\"backColor\", false, \"rgb(0, 255, 0)\")'>DATE (D)</button><button id=\"key_F\" style=\"background-color: rgb(255, 180, 180);\" onclick='document.execCommand(\"backColor\", false, \"rgb(255, 180, 180)\")'>FILIALE (F)</button><button id=\"key_G\" style=\"background-color: rgb(230, 171, 0);\" onclick='document.execCommand(\"backColor\", false, \"rgb(230, 171, 0)\")'>INSTRUMENT (G)</button>\n",
              "      <button id=\"key_Q\" onclick=\"document.execCommand('removeFormat', false, null)\">remove (Q)</button>\n",
              "      <button id=\"key_P\" onclick=\"google.colab.kernel.invokeFunction('notebook.Prediction');\">pred (P)</button>\n",
              "      <button id='prev'>prev</button>\n",
              "      <button id='next'>next</button>\n",
              "    </fieldset>\n",
              "    <div id=\"ed\" contenteditable=\"true\">220C0700-FR0000034639-FS0185            220C0700 FR0000034639-FS0185 <span style=\"background-color: rgb(0, 255, 0)\">21 février 2020</span>   Déclaration de franchissement de seuils (article L. 233-7 du code de commerce)   <span style=\"background-color: rgb(255, 0, 0)\">ALTRAN TECHNOLOGIES</span>  (Euronext Paris)   Par courrier reçu le <span style=\"background-color: rgb(0, 255, 0)\">20 février 2020</span>, complété par un courrier reçu le <span style=\"background-color: rgb(0, 255, 0)\">21 février</span>, la société <span style=\"background-color: rgb(255, 0, 255)\">Bank of America Corporation</span> (Corporation Trust Center, Orange Street, Wilmington, DE 19801, Etats-Unis) a déclaré avoir franchi <span style=\"background-color: rgb(255, 255, 0)\">en hausse</span>, indirectement par l’intermédiaire des sociétés qu’elle contrôle, le <span style=\"background-color: rgb(0, 255, 0)\">17 février 2020</span>, les seuils de <span style=\"background-color: rgb(160, 160, 255)\">5%</span> du <span style=\"background-color: rgb(192, 192, 192)\">capital</span> et des <span style=\"background-color: rgb(192, 192, 192)\">droits de vote</span> de la société <span style=\"background-color: rgb(255, 0, 0)\">A</span><span style=\"background-color: rgb(255, 0, 0)\">LTRAN TECHNOLOGIES</span> et détenir <span style=\"background-color: rgb(0, 255, 255)\">14 377 895</span> <span style=\"background-color: rgb(192, 192, 192)\">actions</span> <span style=\"background-color: rgb(255, 0, 0)\">ALTRAN TECHNOLOGIES</span> représentant autant de droits de vote, soit <span style=\"background-color: rgb(160, 160, 255)\">5,59%</span> du <span style=\"background-color: rgb(192, 192, 192)\">capital</span> et <span style=\"background-color: rgb(160, 160, 255)\">5,58%</span> des <span style=\"background-color: rgb(192, 192, 192)\">droits de vote</span> de cette société1, répartis comme suit :   Actions % capital Droits de vote % droits de vote Merrill Lynch International 14 101 661 5,49 14 101 661 5,47 BofA Securities Europe SA 276 021 0,11 276 021 0,11 BofA Securities, Inc. 213 ns 213 ns Total Bank of America Corporation 14 377 895 5,59 14 377 895 5,58  Ce franchissement de seuils résulte d’une acquisition d’actions <span style=\"background-color: rgb(255, 0, 0)\">ALTRAN TECHNOLOGIES</span> sur le marché et d’une augmentation du nombre d’actions <span style=\"background-color: rgb(255, 0, 0)\">ALTRAN TECHNOLOGIES</span> détenues à titre d’emprunts et de swaps.  À cette occasion, la société <span style=\"background-color: rgb(255, 180, 180)\">Merrill Lynch International</span> a déclaré avoir franchi individuellement <span style=\"background-color: rgb(255, 255, 0)\">en hausse</span> les mêmes seuils.  Au titre de l’article L. 233-9 I, 4° du code de commerce et de l’article 223-14 IV du règlement général :  - la société <span style=\"background-color: rgb(255, 180, 180)\">Merrill Lynch International</span> a précisé détenir <span style=\"background-color: rgb(0, 255, 255)\">13 784 025</span> <span style=\"background-color: rgb(192, 192, 192)\">actions</span> <span style=\"background-color: rgb(255, 0, 0)\">ALTRAN TECHNOLOGIES</span> (prises en compte dans la détention par assimilation visée ci-dessus) résultant de la conclusion d’un contrat avec un tiers (propriétaire desdites actions) conférant le droit à la société <span style=\"background-color: rgb(255, 180, 180)\">Merrill Lynch International</span> d’utiliser lesdites actions à tout moment ; et  - la société <span style=\"background-color: rgb(255, 180, 180)\">BofA Securities Europe SA</span> a précisé détenir <span style=\"background-color: rgb(0, 255, 255)\">274 482</span> <span style=\"background-color: rgb(192, 192, 192)\">actions</span> <span style=\"background-color: rgb(255, 0, 0)\">ALTRAN TECHNOLOGIES</span> (prises en compte dans la détention par assimilation visée ci-dessus) résultant de la conclusion d’un contrat avec un tiers (propriétaire desdites actions) conférant le droit à la société <span style=\"background-color: rgb(255, 180, 180)\">BofA Securities Europe SA</span> d’utiliser lesdites actions à tout moment.  En outre, au titre de l’article L. 233-9 I, 4° bis du code de commerce et de l’article 223-14 V du règlement général, la société <span style=\"background-color: rgb(255, 180, 180)\">Merrill Lynch International</span> a précisé détenir <span style=\"background-color: rgb(0, 255, 255)\">17 749</span> <span style=\"background-color: rgb(192, 192, 192)\">actions</span> <span style=\"background-color: rgb(255, 0, 0)\">ALTRAN TECHNOLOGIES</span> (prises en compte au premier alinéa)2 au titre de contrats « <span style=\"background-color: rgb(230, 171, 0)\">cash-settled equity swap</span> » à dénouement en espèces, exerçables à tout moment et d’échéances entre le <span style=\"background-color: rgb(0, 255, 0)\">26 octobre 2020</span> et le <span style=\"background-color: rgb(0, 255, 0)\">30 octobre 2020</span>. _______                                                            1 Sur la base d'un capital composé de <span style=\"background-color: rgb(0, 255, 255)\">257 021 105</span> <span style=\"background-color: rgb(192, 192, 192)\">actions</span> représentant <span style=\"background-color: rgb(0, 255, 255)\">257 652 732</span> <span style=\"background-color: rgb(192, 192, 192)\">droits de vote</span>, en application du 2ème alinéa de l’article 223-11 du règlement général. 2 Sur la base d’un delta de 1. \f</div>\n",
              "    <script>\n",
              "      function change(dir) {\n",
              "        children = document.querySelector(\"#ed\").childNodes;\n",
              "        res = [];\n",
              "        offset = 0;\n",
              "        for (var i = 0; i < children.length; i++) {\n",
              "          next_offset = offset + children[i].textContent.length;\n",
              "          if (children[i].nodeType != Node.TEXT_NODE) {\n",
              "            rgb = children[i].style.backgroundColor\n",
              "            res.push([offset, next_offset, rgb])\n",
              "          }\n",
              "          offset = next_offset;\n",
              "        }\n",
              "        google.colab.kernel.invokeFunction('notebook.SaveEntities', [res, dir]);\n",
              "        document.querySelector('#ed').innerHTML = next_text;\n",
              "      };\n",
              "      document.querySelector('#prev').onclick = () => {\n",
              "        change(-1);\n",
              "      };\n",
              "      document.querySelector('#next').onclick = () => {\n",
              "        change(1);\n",
              "      };\n",
              "      document.querySelector('#ed').onkeydown = (ev) => {\n",
              "        ev.preventDefault();\n",
              "      };\n",
              "      document.querySelector('#ed').onkeypress = (ev) => {\n",
              "        ev.preventDefault();\n",
              "      };\n",
              "      document.querySelector('#ed').onkeyup = (ev) => {\n",
              "        ev.preventDefault();\n",
              "        button_id = \"#key_\" + String.fromCharCode(ev.keyCode);\n",
              "        button = document.querySelector(button_id)\n",
              "        if (button) {\n",
              "          button.click();\n",
              "        }\n",
              "      };\n",
              "    </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPy2Dzh8Mz3N",
        "colab_type": "code",
        "outputId": "4c7181f7-41e6-4680-b085-bedbeafd2b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'file': '0070C022_220C0700.pdf', 'text': \"220C0700-FR0000034639-FS0185            220C0700 FR0000034639-FS0185 21 février 2020   Déclaration de franchissement de seuils (article L. 233-7 du code de commerce)   ALTRAN TECHNOLOGIES  (Euronext Paris)   Par courrier reçu le 20 février 2020, complété par un courrier reçu le 21 février, la société Bank of America Corporation (Corporation Trust Center, Orange Street, Wilmington, DE 19801, Etats-Unis) a déclaré avoir franchi en hausse, indirectement par l’intermédiaire des sociétés qu’elle contrôle, le 17 février 2020, les seuils de 5% du capital et des droits de vote de la société ALTRAN TECHNOLOGIES et détenir 14 377 895 actions ALTRAN TECHNOLOGIES représentant autant de droits de vote, soit 5,59% du capital et 5,58% des droits de vote de cette société1, répartis comme suit :   Actions % capital Droits de vote % droits de vote Merrill Lynch International 14 101 661 5,49 14 101 661 5,47 BofA Securities Europe SA 276 021 0,11 276 021 0,11 BofA Securities, Inc. 213 ns 213 ns Total Bank of America Corporation 14 377 895 5,59 14 377 895 5,58  Ce franchissement de seuils résulte d’une acquisition d’actions ALTRAN TECHNOLOGIES sur le marché et d’une augmentation du nombre d’actions ALTRAN TECHNOLOGIES détenues à titre d’emprunts et de swaps.  À cette occasion, la société Merrill Lynch International a déclaré avoir franchi individuellement en hausse les mêmes seuils.  Au titre de l’article L. 233-9 I, 4° du code de commerce et de l’article 223-14 IV du règlement général :  - la société Merrill Lynch International a précisé détenir 13 784 025 actions ALTRAN TECHNOLOGIES (prises en compte dans la détention par assimilation visée ci-dessus) résultant de la conclusion d’un contrat avec un tiers (propriétaire desdites actions) conférant le droit à la société Merrill Lynch International d’utiliser lesdites actions à tout moment ; et  - la société BofA Securities Europe SA a précisé détenir 274 482 actions ALTRAN TECHNOLOGIES (prises en compte dans la détention par assimilation visée ci-dessus) résultant de la conclusion d’un contrat avec un tiers (propriétaire desdites actions) conférant le droit à la société BofA Securities Europe SA d’utiliser lesdites actions à tout moment.  En outre, au titre de l’article L. 233-9 I, 4° bis du code de commerce et de l’article 223-14 V du règlement général, la société Merrill Lynch International a précisé détenir 17 749 actions ALTRAN TECHNOLOGIES (prises en compte au premier alinéa)2 au titre de contrats « cash-settled equity swap » à dénouement en espèces, exerçables à tout moment et d’échéances entre le 26 octobre 2020 et le 30 octobre 2020. _______                                                            1 Sur la base d'un capital composé de 257 021 105 actions représentant 257 652 732 droits de vote, en application du 2ème alinéa de l’article 223-11 du règlement général. 2 Sur la base d’un delta de 1. \\x0c\", 'entities': [(69, 84, 'DATE'), (168, 187, 'ISSUER'), (229, 244, 'DATE'), (279, 289, 'DATE'), (302, 329, 'FIRM'), (430, 439, 'DIRECTION'), (509, 524, 'DATE'), (540, 542, 'PERCENT'), (546, 553, 'TYPE'), (561, 575, 'TYPE'), (590, 591, 'ISSUER'), (591, 609, 'ISSUER'), (621, 631, 'NUMBER'), (632, 639, 'TYPE'), (640, 659, 'ISSUER'), (704, 709, 'PERCENT'), (713, 720, 'TYPE'), (724, 729, 'PERCENT'), (734, 748, 'TYPE'), (1121, 1140, 'ISSUER'), (1197, 1216, 'ISSUER'), (1288, 1315, 'FILIALE'), (1357, 1366, 'DIRECTION'), (1506, 1533, 'FILIALE'), (1552, 1562, 'NUMBER'), (1563, 1570, 'TYPE'), (1571, 1590, 'ISSUER'), (1779, 1806, 'FILIALE'), (1868, 1893, 'FILIALE'), (1912, 1919, 'NUMBER'), (1920, 1927, 'TYPE'), (1928, 1947, 'ISSUER'), (2136, 2161, 'FILIALE'), (2335, 2362, 'FILIALE'), (2381, 2387, 'NUMBER'), (2388, 2395, 'TYPE'), (2396, 2415, 'ISSUER'), (2477, 2501, 'INSTRUMENT'), (2578, 2593, 'DATE'), (2600, 2615, 'DATE'), (2722, 2733, 'NUMBER'), (2734, 2741, 'TYPE'), (2755, 2766, 'NUMBER'), (2767, 2781, 'TYPE')]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKBDmobv-iHg",
        "colab_type": "code",
        "outputId": "dfacf8f6-b5ed-4866-ac52-3cf3a0f9d171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data = {x['file'] : x for x in data}\n",
        "data_label = {x['file'] : x for x in data_label}\n",
        "data_no_label = {x['file'] : x for x in data_no_label}\n",
        "for x in w.to_annot:\n",
        "  if 'entities' in x and len(x['entities']) != 0:\n",
        "    data[x['file']] = x\n",
        "    data_label[x['file']] = x\n",
        "    if x['file'] in data_no_label:\n",
        "      del data_no_label[x['file']]\n",
        "data = [v for k, v in sorted(data.items(), key=lambda t: t[0])]\n",
        "data_label = [v for k, v in sorted(data_label.items(), key=lambda t: t[0])]\n",
        "data_no_label = [v for k, v in sorted(data_no_label.items(), key=lambda t: t[0])]\n",
        "print(len(data), \"texts with\", len(data_label), \"labeled and\", len(data_no_label), 'to label')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "117 texts with 117 labeled and 0 to label\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKyD0r0i6ylv",
        "colab_type": "text"
      },
      "source": [
        "## Download Json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnehMhWlHT0Q",
        "colab_type": "code",
        "outputId": "45156d3e-ce44-457d-b8bf-b297381dd7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!zip dataset.zip *.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: 0070C022_220C0700.json (deflated 66%)\n",
            "  adding: 0340C022_220C0430.json (deflated 59%)\n",
            "  adding: 0510C022_220C0150.json (deflated 51%)\n",
            "  adding: 0540C022_220C0450.json (deflated 62%)\n",
            "  adding: 0620C022_220C0260.json (deflated 50%)\n",
            "  adding: 0810C022_220C0180.json (deflated 69%)\n",
            "  adding: 0820C022_220C0280.json (deflated 60%)\n",
            "  adding: 0900C022_220C0090.json (deflated 74%)\n",
            "  adding: 0940C022_220C0490.json (deflated 56%)\n",
            "  adding: 0960C022_220C0690.json (deflated 69%)\n",
            "  adding: 0980C022_220C0890.json (deflated 54%)\n",
            "  adding: 1040C022_220C0401.json (deflated 61%)\n",
            "  adding: 1080C022_220C0801.json (deflated 51%)\n",
            "  adding: 1090C022_220C0901.json (deflated 66%)\n",
            "  adding: 1200C022_220C0021.json (deflated 58%)\n",
            "  adding: 1270C022_220C0721.json (deflated 64%)\n",
            "  adding: 1360C022_220C0631.json (deflated 65%)\n",
            "  adding: 1380C022_220C0831.json (deflated 55%)\n",
            "  adding: 1430C022_220C0341.json (deflated 67%)\n",
            "  adding: 1500C022_220C0051.json (deflated 59%)\n",
            "  adding: 1550C022_220C0551.json (deflated 66%)\n",
            "  adding: 1640C022_220C0461.json (deflated 61%)\n",
            "  adding: 1960C022_220C0691.json (deflated 57%)\n",
            "  adding: 1980C022_220C0891.json (deflated 58%)\n",
            "  adding: 2030C022_220C0302.json (deflated 60%)\n",
            "  adding: 2080C022_220C0802.json (deflated 50%)\n",
            "  adding: 2090C022_220C0902.json (deflated 58%)\n",
            "  adding: 2260C022_220C0622.json (deflated 58%)\n",
            "  adding: 2410C022_220C0142.json (deflated 59%)\n",
            "  adding: 2550C022_220C0552.json (deflated 59%)\n",
            "  adding: 2620C022_220C0262.json (deflated 55%)\n",
            "  adding: 2640C022_220C0462.json (deflated 56%)\n",
            "  adding: 2920C022_220C0292.json (deflated 57%)\n",
            "  adding: 3040C022_220C0403.json (deflated 70%)\n",
            "  adding: 3060C022_220C0603.json (deflated 60%)\n",
            "  adding: 3080C022_220C0803.json (deflated 58%)\n",
            "  adding: 3090C022_220C0903.json (deflated 60%)\n",
            "  adding: 3100C022_220C0013.json (deflated 50%)\n",
            "  adding: 3170C022_220C0713.json (deflated 65%)\n",
            "  adding: 3190C022_220C0913.json (deflated 61%)\n",
            "  adding: 3200C022_220C0023.json (deflated 60%)\n",
            "  adding: 3270C022_220C0723.json (deflated 57%)\n",
            "  adding: 3310C022_220C0133.json (deflated 62%)\n",
            "  adding: 3350C022_220C0533.json (deflated 53%)\n",
            "  adding: 3460C022_220C0643.json (deflated 55%)\n",
            "  adding: 3540C022_220C0453.json (deflated 56%)\n",
            "  adding: 3570C022_220C0753.json (deflated 55%)\n",
            "  adding: 3610C022_220C0163.json (deflated 60%)\n",
            "  adding: 3620C022_220C0263.json (deflated 61%)\n",
            "  adding: 3710C022_220C0173.json (deflated 54%)\n",
            "  adding: 3770C022_220C0773.json (deflated 61%)\n",
            "  adding: 3810C022_220C0183.json (deflated 60%)\n",
            "  adding: 3830C022_220C0383.json (deflated 59%)\n",
            "  adding: 3950C022_220C0593.json (deflated 55%)\n",
            "  adding: 4040C022_220C0404.json (deflated 58%)\n",
            "  adding: 4060C022_220C0604.json (deflated 65%)\n",
            "  adding: 4170C022_220C0714.json (deflated 55%)\n",
            "  adding: 4280C022_220C0824.json (deflated 58%)\n",
            "  adding: 4480C022_220C0844.json (deflated 64%)\n",
            "  adding: 4530C022_220C0354.json (deflated 65%)\n",
            "  adding: 4540C022_220C0454.json (deflated 64%)\n",
            "  adding: 4620C022_220C0264.json (deflated 62%)\n",
            "  adding: 4630C022_220C0364.json (deflated 60%)\n",
            "  adding: 4870C022_220C0784.json (deflated 56%)\n",
            "  adding: 4960C022_220C0694.json (deflated 56%)\n",
            "  adding: 5100C022_220C0015.json (deflated 62%)\n",
            "  adding: 5140C022_220C0415.json (deflated 54%)\n",
            "  adding: 5300C022_220C0035.json (deflated 51%)\n",
            "  adding: 5330C022_220C0335.json (deflated 60%)\n",
            "  adding: 5380C022_220C0835.json (deflated 55%)\n",
            "  adding: 5440C022_220C0445.json (deflated 60%)\n",
            "  adding: 5480C022_220C0845.json (deflated 57%)\n",
            "  adding: 5600C022_220C0065.json (deflated 58%)\n",
            "  adding: 5650C022_220C0565.json (deflated 57%)\n",
            "  adding: 5930C022_220C0395.json (deflated 55%)\n",
            "  adding: 5960C022_220C0695.json (deflated 65%)\n",
            "  adding: 6060C022_220C0606.json (deflated 64%)\n",
            "  adding: 6240C022_220C0426.json (deflated 55%)\n",
            "  adding: 6340C022_220C0436.json (deflated 64%)\n",
            "  adding: 6350C022_220C0536.json (deflated 61%)\n",
            "  adding: 6360C022_220C0636.json (deflated 63%)\n",
            "  adding: 6620C022_220C0266.json (deflated 69%)\n",
            "  adding: 6650C022_220C0566.json (deflated 56%)\n",
            "  adding: 6720C022_220C0276.json (deflated 62%)\n",
            "  adding: 7120C022_220C0217.json (deflated 68%)\n",
            "  adding: 7230C022_220C0327.json (deflated 60%)\n",
            "  adding: 7320C022_220C0237.json (deflated 62%)\n",
            "  adding: 7350C022_220C0537.json (deflated 60%)\n",
            "  adding: 7480C022_220C0847.json (deflated 63%)\n",
            "  adding: 7570C022_220C0757.json (deflated 62%)\n",
            "  adding: 7620C022_220C0267.json (deflated 60%)\n",
            "  adding: 7780C022_220C0877.json (deflated 59%)\n",
            "  adding: 7800C022_220C0087.json (deflated 58%)\n",
            "  adding: 7820C022_220C0287.json (deflated 57%)\n",
            "  adding: 7910C022_220C0197.json (deflated 62%)\n",
            "  adding: 8030C022_220C0308.json (deflated 53%)\n",
            "  adding: 8120C022_220C0218.json (deflated 71%)\n",
            "  adding: 8140C022_220C0418.json (deflated 53%)\n",
            "  adding: 8330C022_220C0338.json (deflated 64%)\n",
            "  adding: 8340C022_220C0438.json (deflated 60%)\n",
            "  adding: 8350C022_220C0538.json (deflated 69%)\n",
            "  adding: 8400C022_220C0048.json (deflated 64%)\n",
            "  adding: 8430C022_220C0348.json (deflated 59%)\n",
            "  adding: 8470C022_220C0748.json (deflated 57%)\n",
            "  adding: 8570C022_220C0758.json (deflated 67%)\n",
            "  adding: 8780C022_220C0878.json (deflated 57%)\n",
            "  adding: 8840C022_220C0488.json (deflated 61%)\n",
            "  adding: 8850C022_220C0588.json (deflated 60%)\n",
            "  adding: 8980C022_220C0898.json (deflated 69%)\n",
            "  adding: 9140C022_220C0419.json (deflated 66%)\n",
            "  adding: 9150C022_220C0519.json (deflated 58%)\n",
            "  adding: 9320C022_220C0239.json (deflated 60%)\n",
            "  adding: 9330C022_220C0339.json (deflated 58%)\n",
            "  adding: 9530C022_220C0359.json (deflated 64%)\n",
            "  adding: 9610C022_220C0169.json (deflated 58%)\n",
            "  adding: 9670C022_220C0769.json (deflated 56%)\n",
            "  adding: 9900C022_220C0099.json (deflated 65%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd8U4Hu3JyAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('dataset.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yqUSLTV7Cat",
        "colab_type": "text"
      },
      "source": [
        "## Train NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxZGXdRdj1eu",
        "colab_type": "code",
        "outputId": "980632dd-3a5e-4033-d7b5-2df5ceaee347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "split = 0.33\n",
        "train_data = []\n",
        "for x in data_label:\n",
        "  entities = [tuple(ent) for ent in  x[\"entities\"]]\n",
        "  train_data.append((x['text'], {'entities' : entities}))\n",
        "labels = ['ISSUER', 'FIRM', 'NUMBER', 'PERCENT', 'TYPE', 'DIRECTION', 'DATE', 'FILIALE', 'INSTRUMENT']\n",
        "split = int(split * len(train_data))\n",
        "test_data = train_data[:split]\n",
        "train_data = train_data[split:]\n",
        "print(len(test_data), len(train_data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huoXcIdQmGgR",
        "colab_type": "code",
        "outputId": "71fcde0e-8846-4c83-cbcd-4ba78a5f70ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "import random\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "import fr_core_news_md\n",
        "\n",
        "n_iter=40\n",
        "nlp = fr_core_news_md.load()\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "for label in labels:\n",
        "  ner.add_label(label)\n",
        "optimizer = nlp.resume_training()\n",
        "pipe_exceptions = [\"ner\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "  sizes = compounding(1.0, 4.0, 1.001)\n",
        "  # batch up the examples using spaCy's minibatch\n",
        "  for itn in range(n_iter):\n",
        "    random.shuffle(train_data)\n",
        "    batches = minibatch(train_data, size=sizes)\n",
        "    losses = {}\n",
        "    for batch in batches:\n",
        "      texts, annotations = zip(*batch)\n",
        "      nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "    print(\"Losses\", losses)\n",
        "  score = nlp.evaluate(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 20281.23872630823}\n",
            "Losses {'ner': 18359.395397767425}\n",
            "Losses {'ner': 18034.401956422953}\n",
            "Losses {'ner': 17661.076287855394}\n",
            "Losses {'ner': 17754.452405526303}\n",
            "Losses {'ner': 17263.59386597504}\n",
            "Losses {'ner': 17120.939673734232}\n",
            "Losses {'ner': 17112.690230745124}\n",
            "Losses {'ner': 17258.234536451288}\n",
            "Losses {'ner': 17194.213365793228}\n",
            "Losses {'ner': 16996.494131974876}\n",
            "Losses {'ner': 17171.376155279577}\n",
            "Losses {'ner': 16872.84184090793}\n",
            "Losses {'ner': 16799.044024169445}\n",
            "Losses {'ner': 17211.805298149586}\n",
            "Losses {'ner': 16804.13332286477}\n",
            "Losses {'ner': 16984.96086921543}\n",
            "Losses {'ner': 16796.667815968394}\n",
            "Losses {'ner': 16621.641098976135}\n",
            "Losses {'ner': 17223.622693538666}\n",
            "Losses {'ner': 16959.608881918248}\n",
            "Losses {'ner': 16742.974809485866}\n",
            "Losses {'ner': 16795.66036939621}\n",
            "Losses {'ner': 16653.796668052673}\n",
            "Losses {'ner': 16932.72894887626}\n",
            "Losses {'ner': 16924.9821113348}\n",
            "Losses {'ner': 16736.068982839584}\n",
            "Losses {'ner': 17094.829356193542}\n",
            "Losses {'ner': 16693.397944808006}\n",
            "Losses {'ner': 16913.299830675125}\n",
            "Losses {'ner': 16849.234180927277}\n",
            "Losses {'ner': 16872.384038686752}\n",
            "Losses {'ner': 16867.865071058273}\n",
            "Losses {'ner': 16698.894248723984}\n",
            "Losses {'ner': 16823.50058722496}\n",
            "Losses {'ner': 16486.839023590088}\n",
            "Losses {'ner': 17041.93279981613}\n",
            "Losses {'ner': 16625.0246540308}\n",
            "Losses {'ner': 16788.598021507263}\n",
            "Losses {'ner': 16806.02382659912}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFcObvF2aK7q",
        "colab_type": "code",
        "outputId": "973ec648-0a41-4a3f-8369-4c04e897d297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "score.scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ents_f': 89.84771573604061,\n",
              " 'ents_p': 88.05970149253731,\n",
              " 'ents_per_type': {'DATE': {'f': 98.4126984126984, 'p': 96.875, 'r': 100.0},\n",
              "  'DIRECTION': {'f': 100.0, 'p': 100.0, 'r': 100.0},\n",
              "  'FILIALE': {'f': 85.71428571428571,\n",
              "   'p': 85.71428571428571,\n",
              "   'r': 85.71428571428571},\n",
              "  'FIRM': {'f': 50.0, 'p': 41.17647058823529, 'r': 63.63636363636363},\n",
              "  'INSTRUMENT': {'f': 66.66666666666666,\n",
              "   'p': 66.66666666666666,\n",
              "   'r': 66.66666666666666},\n",
              "  'ISSUER': {'f': 89.1566265060241,\n",
              "   'p': 84.0909090909091,\n",
              "   'r': 94.87179487179486},\n",
              "  'NUMBER': {'f': 85.71428571428572, 'p': 90.0, 'r': 81.81818181818183},\n",
              "  'PERCENT': {'f': 97.67441860465117, 'p': 100.0, 'r': 95.45454545454545},\n",
              "  'TYPE': {'f': 94.62365591397848,\n",
              "   'p': 95.65217391304348,\n",
              "   'r': 93.61702127659575}},\n",
              " 'ents_r': 91.70984455958549,\n",
              " 'las': 0.0,\n",
              " 'las_per_type': {'': {'f': 0.0, 'p': 0.0, 'r': 0.0}},\n",
              " 'tags_acc': 0.0,\n",
              " 'textcat_score': 0.0,\n",
              " 'textcats_per_cat': {},\n",
              " 'token_acc': 100.0,\n",
              " 'uas': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjbCTab3wApL",
        "colab_type": "code",
        "outputId": "3d47247f-97ac-4c94-a256-086195ad5a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "from spacy import displacy\n",
        "doc = nlp(data[0]['text'])\n",
        "\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">220C0700-FR0000034639-FS0185            220C0700 FR0000034639-FS0185 \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    21 février 2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "   Déclaration de franchissement de seuils (article L. 233-7 du code de commerce)   \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ALTRAN TECHNOLOGIES\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ISSUER</span>\n",
              "</mark>\n",
              "  (Euronext Paris)   Par courrier reçu le \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    20 février 2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", complété par un courrier reçu le \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    21 février,\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bank of America Corporation\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FIRM</span>\n",
              "</mark>\n",
              " (Corporation Trust Center, Orange Street, Wilmington, DE 19801, Etats-Unis) a déclaré avoir franchi \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    en hausse\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DIRECTION</span>\n",
              "</mark>\n",
              ", indirectement par l’intermédiaire des sociétés qu’elle contrôle, le \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    17 février 2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", les seuils de \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    5%\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
              "</mark>\n",
              " du \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    capital\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " et des \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    droits de vote\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " de la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ALTRAN TECHNOLOGIES\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ISSUER</span>\n",
              "</mark>\n",
              " et détenir \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    14 377 895\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    actions\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ALTRAN TECHNOLOGIES\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ISSUER</span>\n",
              "</mark>\n",
              " représentant autant de droits de vote, soit \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    5,59%\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
              "</mark>\n",
              " du \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    capital\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " et \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    5,58%\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
              "</mark>\n",
              " des \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    droits de vote\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " de cette société1, répartis comme suit :   Actions % capital Droits de vote % droits de vote Merrill Lynch International 14 101 661 5,49 14 101 661 5,47 BofA Securities Europe SA 276 021 0,11 276 021 0,11 BofA Securities, Inc. 213 ns 213 ns Total Bank of America Corporation 14 377 895 5,59 14 377 895 5,58  Ce franchissement de seuils résulte d’une acquisition d’actions ALTRAN TECHNOLOGIES sur le marché et d’une augmentation du nombre d’actions \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ALTRAN TECHNOLOGIES\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ISSUER</span>\n",
              "</mark>\n",
              " détenues à titre d’emprunts et de swaps.  À cette occasion, la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Merrill Lynch International\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FILIALE</span>\n",
              "</mark>\n",
              " a déclaré avoir franchi individuellement \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    en hausse\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DIRECTION</span>\n",
              "</mark>\n",
              " les mêmes seuils.  Au titre de l’article L. 233-9 I, 4° du code de commerce et de l’article 223-14 IV du règlement général :  - la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Merrill Lynch International\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FILIALE</span>\n",
              "</mark>\n",
              " a précisé détenir \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    13 784 025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    actions\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ALTRAN TECHNOLOGIES\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ISSUER</span>\n",
              "</mark>\n",
              " (prises en compte dans la détention par assimilation visée ci-dessus) résultant de la conclusion d’un contrat avec un tiers (propriétaire desdites actions) conférant le droit à la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Merrill Lynch International\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FILIALE</span>\n",
              "</mark>\n",
              " d’utiliser lesdites actions à tout moment ; et  - la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    BofA Securities Europe SA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FILIALE</span>\n",
              "</mark>\n",
              " a précisé détenir \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    274 482\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    actions\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " ALTRAN TECHNOLOGIES (prises en compte dans la détention par assimilation visée ci-dessus) résultant de la conclusion d’un contrat avec un tiers (propriétaire desdites actions) conférant le droit à la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    BofA Securities Europe SA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FILIALE</span>\n",
              "</mark>\n",
              " d’utiliser lesdites actions à tout moment.  En outre, au titre de l’article L. 233-9 I, 4° bis du code de commerce et de l’article 223-14 V du règlement général, la société \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Merrill Lynch International\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FILIALE</span>\n",
              "</mark>\n",
              " a précisé détenir \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    17 749\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    actions\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ALTRAN TECHNOLOGIES\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ISSUER</span>\n",
              "</mark>\n",
              " (prises en compte au premier alinéa)2 au titre de contrats « cash-settled equity swap » à dénouement en espèces, exerçables à tout moment et d’échéances entre le \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    26 octobre 2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " et le \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    30 octobre 2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". _______                                                            1 Sur la base d'un capital composé de \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    257 021 105\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    actions\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              " représentant \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    257 652 732\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    droits de vote\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TYPE</span>\n",
              "</mark>\n",
              ", en application du 2ème alinéa de l’article 223-11 du règlement général. 2 Sur la base d’un delta de 1. \f</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKlCPKmijp3F",
        "colab_type": "code",
        "outputId": "8b10561a-bb73-45f4-d04a-031fa1d3c2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for t in test_data:\n",
        "  doc = nlp(t[0])\n",
        "  label_set = set([(e_s, e_e, e_t) for e_s, e_e, e_t in t[1]['entities']])\n",
        "  pred_set = set([(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
        "  #print(label_set)\n",
        "  print(pred_set - label_set)\n",
        "  print(label_set - pred_set)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{(279, 290, 'DATE'), (1121, 1127, 'ISSUER'), (590, 609, 'ISSUER')}\n",
            "{(590, 591, 'ISSUER'), (1121, 1140, 'ISSUER'), (591, 609, 'ISSUER'), (1928, 1947, 'ISSUER'), (2477, 2501, 'INSTRUMENT'), (279, 289, 'DATE')}\n",
            "{(1109, 1112, 'TYPE'), (511, 516, 'ISSUER'), (1608, 1618, 'INSTRUMENT'), (804, 814, 'INSTRUMENT'), (1113, 1118, 'ISSUER'), (1103, 1108, 'NUMBER'), (589, 595, 'ISSUER')}\n",
            "{(589, 594, 'ISSUER'), (511, 516, 'FIRM')}\n",
            "{(171, 190, 'ISSUER'), (552, 562, 'INSTRUMENT')}\n",
            "{(171, 191, 'ISSUER')}\n",
            "{(697, 718, 'ISSUER'), (904, 925, 'ISSUER'), (216, 237, 'ISSUER'), (1878, 1892, 'ISSUER'), (1338, 1352, 'ISSUER'), (611, 625, 'ISSUER'), (928, 942, 'ISSUER'), (587, 608, 'ISSUER'), (1314, 1335, 'ISSUER'), (1642, 1663, 'ISSUER'), (297, 311, 'DATE'), (1987, 2008, 'ISSUER'), (1854, 1875, 'ISSUER'), (1666, 1680, 'ISSUER'), (1546, 1567, 'ISSUER'), (240, 254, 'ISSUER')}\n",
            "{(1987, 2025, 'ISSUER'), (697, 735, 'ISSUER'), (1854, 1892, 'ISSUER'), (587, 625, 'ISSUER'), (216, 254, 'ISSUER'), (1642, 1680, 'ISSUER'), (1546, 1584, 'ISSUER'), (1314, 1352, 'ISSUER')}\n",
            "set()\n",
            "{(807, 813, 'TYPE'), (800, 806, 'NUMBER'), (612, 631, 'ISSUER')}\n",
            "{(2042, 2062, 'FILIALE'), (1713, 1733, 'FILIALE'), (633, 653, 'FILIALE'), (3129, 3153, 'ISSUER'), (659, 679, 'FILIALE'), (3056, 3076, 'FIRM'), (2827, 2851, 'ISSUER'), (1548, 1568, 'FILIALE'), (266, 287, 'FIRM')}\n",
            "{(3056, 3094, 'FILIALE'), (1713, 1737, 'FILIALE'), (2042, 2080, 'FILIALE'), (266, 284, 'FIRM'), (659, 697, 'FILIALE'), (3129, 3152, 'ISSUER'), (1548, 1586, 'FILIALE'), (633, 657, 'FILIALE'), (2827, 2850, 'ISSUER')}\n",
            "{(1631, 1641, 'INSTRUMENT'), (588, 594, 'ISSUER')}\n",
            "{(588, 593, 'ISSUER')}\n",
            "{(3562, 3575, 'INSTRUMENT'), (5284, 5291, 'ISSUER'), (5022, 5043, 'FILIALE'), (3998, 4009, 'TYPE'), (5202, 5209, 'ISSUER'), (4717, 4724, 'ISSUER'), (4600, 4621, 'FILIALE'), (5000, 5005, 'ISSUER'), (4780, 4787, 'ISSUER'), (2774, 2781, 'ISSUER'), (4862, 4869, 'ISSUER'), (3769, 3774, 'TYPE'), (2916, 2939, 'NUMBER'), (5139, 5146, 'ISSUER'), (2889, 2911, 'ISSUER'), (261, 307, 'FIRM'), (4578, 4583, 'ISSUER'), (2183, 2202, 'FIRM'), (3145, 3165, 'NUMBER')}\n",
            "{(3769, 3774, 'INSTRUMENT'), (4717, 4724, 'FIRM'), (5000, 5005, 'FIRM'), (261, 306, 'FIRM'), (5284, 5291, 'FIRM'), (3152, 3165, 'INSTRUMENT'), (2889, 2910, 'ISSUER'), (2803, 2826, 'INSTRUMENT'), (4862, 4869, 'FIRM'), (2916, 2922, 'NUMBER'), (2183, 2201, 'FILIALE'), (3145, 3151, 'NUMBER'), (4780, 4787, 'FIRM'), (2989, 3005, 'INSTRUMENT'), (2923, 2939, 'INSTRUMENT'), (2801, 2802, 'NUMBER'), (4543, 4566, 'INSTRUMENT'), (2774, 2795, 'ISSUER'), (4578, 4583, 'FIRM'), (5139, 5146, 'FIRM'), (5202, 5209, 'FIRM')}\n",
            "{(272, 282, 'DATE'), (446, 467, 'FILIALE'), (294, 305, 'FIRM'), (170, 177, 'ISSUER'), (893, 904, 'ISSUER'), (308, 329, 'FILIALE')}\n",
            "{(446, 468, 'FILIALE'), (893, 903, 'ISSUER'), (294, 306, 'FIRM'), (272, 281, 'DATE'), (170, 180, 'ISSUER')}\n",
            "{(2170, 2185, 'INSTRUMENT'), (3058, 3078, 'FIRM'), (1554, 1574, 'FILIALE'), (3131, 3155, 'ISSUER'), (2829, 2853, 'ISSUER'), (2046, 2066, 'FILIALE'), (636, 656, 'FILIALE'), (1717, 1737, 'FILIALE'), (662, 682, 'FILIALE')}\n",
            "{(3058, 3096, 'FIRM'), (3131, 3154, 'ISSUER'), (1554, 1592, 'FILIALE'), (636, 660, 'FILIALE'), (1717, 1741, 'FILIALE'), (2046, 2084, 'FIRM'), (2829, 2852, 'ISSUER'), (662, 700, 'FILIALE')}\n",
            "{(1362, 1380, 'FIRM'), (1197, 1202, 'ISSUER'), (837, 888, 'FIRM'), (336, 352, 'FIRM'), (555, 570, 'ISSUER'), (1494, 1502, 'FIRM'), (1548, 1561, 'FIRM'), (194, 202, 'ISSUER'), (1417, 1465, 'FIRM'), (180, 190, 'ISSUER'), (601, 605, 'ISSUER'), (1252, 1295, 'FIRM')}\n",
            "{(336, 350, 'FIRM'), (555, 597, 'ISSUER'), (180, 202, 'ISSUER')}\n",
            "{(1520, 1535, 'DATE')}\n",
            "{(434, 437, 'PERCENT')}\n",
            "{(372, 379, 'TYPE'), (387, 401, 'TYPE'), (520, 530, 'INSTRUMENT')}\n",
            "{(731, 737, 'NUMBER'), (738, 744, 'TYPE')}\n",
            "{(2443, 2447, 'ISSUER'), (1372, 1392, 'FILIALE'), (2353, 2373, 'FILIALE'), (1947, 1967, 'FILIALE')}\n",
            "{(1947, 1985, 'FILIALE'), (1372, 1396, 'FILIALE'), (2443, 2446, 'ISSUER'), (2353, 2391, 'FILIALE')}\n",
            "set()\n",
            "{(1367, 1372, 'NUMBER'), (1373, 1376, 'INSTRUMENT')}\n",
            "{(2263, 2272, 'ISSUER'), (656, 670, 'TYPE'), (1882, 1893, 'TYPE')}\n",
            "{(2263, 2271, 'ISSUER'), (2336, 2360, 'INSTRUMENT'), (656, 670, 'NUMBER')}\n",
            "{(1706, 1726, 'FILIALE'), (2197, 2204, 'TYPE'), (2205, 2209, 'ISSUER'), (2115, 2135, 'FILIALE'), (2476, 2496, 'FIRM'), (1417, 1437, 'FILIALE'), (245, 278, 'FIRM')}\n",
            "{(245, 282, 'FIRM'), (1706, 1744, 'FIRM'), (2115, 2153, 'FIRM'), (2205, 2208, 'ISSUER'), (2476, 2496, 'FILIALE'), (1417, 1441, 'FILIALE')}\n",
            "{(459, 469, 'ISSUER'), (538, 552, 'TYPE'), (523, 530, 'TYPE'), (390, 404, 'TYPE'), (375, 382, 'TYPE')}\n",
            "{(459, 468, 'ISSUER'), (232, 243, 'FIRM')}\n",
            "{(326, 367, 'FIRM'), (2799, 2851, 'FIRM'), (683, 701, 'ISSUER'), (2517, 2537, 'FILIALE')}\n",
            "{(1010, 1012, 'NUMBER'), (2962, 2964, 'NUMBER'), (326, 366, 'FIRM'), (1013, 1020, 'INSTRUMENT'), (2799, 2851, 'FILIALE'), (1206, 1207, 'NUMBER'), (3224, 3231, 'INSTRUMENT'), (683, 700, 'ISSUER'), (2965, 2972, 'INSTRUMENT'), (3166, 3173, 'INSTRUMENT')}\n",
            "{(268, 294, 'FIRM'), (1879, 1904, 'FILIALE'), (1361, 1372, 'ISSUER'), (1129, 1133, 'PERCENT'), (1172, 1189, 'FIRM'), (742, 775, 'NUMBER'), (1205, 1233, 'FILIALE')}\n",
            "{(1879, 1904, 'FIRM'), (268, 293, 'FIRM')}\n",
            "{(1716, 1740, 'FILIALE'), (2610, 2614, 'TYPE'), (1376, 1400, 'FILIALE'), (1968, 1992, 'FILIALE'), (1175, 1199, 'FILIALE'), (1425, 1432, 'TYPE'), (2537, 2546, 'ISSUER'), (2478, 2502, 'FILIALE'), (2237, 2244, 'TYPE'), (169, 177, 'ISSUER'), (1630, 1654, 'FILIALE')}\n",
            "{(2048, 2072, 'FIRM'), (1175, 1199, 'FIRM'), (2610, 2634, 'INSTRUMENT'), (2237, 2244, 'INSTRUMENT'), (169, 179, 'ISSUER'), (2151, 2157, 'NUMBER'), (2478, 2502, 'FIRM'), (1968, 1992, 'FIRM'), (1716, 1740, 'FIRM'), (2537, 2545, 'ISSUER'), (1630, 1654, 'FIRM'), (1759, 1762, 'NUMBER'), (1376, 1400, 'FIRM')}\n",
            "{(758, 803, 'INSTRUMENT'), (958, 1003, 'INSTRUMENT'), (456, 460, 'ISSUER')}\n",
            "{(232, 243, 'FIRM'), (758, 798, 'INSTRUMENT'), (958, 998, 'INSTRUMENT'), (456, 459, 'ISSUER')}\n",
            "{(1476, 1495, 'FIRM'), (1517, 1543, 'INSTRUMENT'), (289, 309, 'FILIALE'), (1188, 1204, 'ISSUER'), (1410, 1419, 'FIRM'), (1595, 1630, 'FIRM'), (259, 277, 'ISSUER'), (313, 344, 'FILIALE'), (688, 706, 'ISSUER'), (1224, 1230, 'ISSUER'), (1255, 1277, 'FILIALE'), (662, 669, 'TYPE')}\n",
            "{(313, 343, 'FIRM'), (289, 308, 'FIRM'), (259, 286, 'FIRM')}\n",
            "{(1728, 1733, 'ISSUER'), (1375, 1423, 'FIRM'), (355, 402, 'FIRM'), (1210, 1253, 'FIRM'), (194, 202, 'ISSUER'), (1506, 1519, 'FIRM'), (1320, 1338, 'FIRM'), (604, 608, 'ISSUER'), (1452, 1460, 'FIRM'), (1109, 1113, 'ISSUER'), (290, 341, 'FIRM')}\n",
            "{(290, 340, 'FIRM'), (190, 202, 'ISSUER'), (355, 401, 'FIRM'), (1109, 1112, 'FIRM'), (573, 600, 'ISSUER')}\n",
            "{(767, 812, 'INSTRUMENT'), (967, 1012, 'INSTRUMENT'), (459, 463, 'ISSUER'), (650, 660, 'INSTRUMENT')}\n",
            "{(234, 245, 'FIRM'), (459, 462, 'ISSUER')}\n",
            "{(266, 278, 'FIRM')}\n",
            "{(697, 703, 'TYPE'), (266, 280, 'FIRM'), (690, 696, 'NUMBER')}\n",
            "{(269, 297, 'FIRM'), (559, 563, 'ISSUER')}\n",
            "{(559, 562, 'ISSUER'), (269, 298, 'FIRM')}\n",
            "{(1269, 1286, 'FILIALE'), (251, 263, 'ISSUER'), (1246, 1253, 'FIRM'), (962, 973, 'INSTRUMENT'), (911, 923, 'ISSUER'), (1297, 1312, 'INSTRUMENT'), (1329, 1341, 'ISSUER')}\n",
            "{(251, 267, 'FIRM'), (1329, 1345, 'FIRM'), (911, 927, 'FIRM')}\n",
            "{(852, 856, 'TYPE'), (1513, 1528, 'INSTRUMENT'), (248, 277, 'FIRM'), (1011, 1052, 'INSTRUMENT')}\n",
            "{(248, 276, 'FIRM'), (1160, 1162, 'NUMBER'), (1163, 1198, 'INSTRUMENT'), (1011, 1051, 'INSTRUMENT')}\n",
            "{(1018, 1038, 'FILIALE'), (604, 624, 'FILIALE'), (1164, 1184, 'FILIALE'), (258, 303, 'FIRM')}\n",
            "{(825, 841, 'ISSUER'), (1018, 1056, 'FILIALE'), (604, 628, 'FILIALE'), (1164, 1188, 'FILIALE'), (1222, 1238, 'ISSUER'), (258, 272, 'FIRM')}\n",
            "{(279, 300, 'FILIALE')}\n",
            "set()\n",
            "{(468, 478, 'ISSUER'), (665, 675, 'INSTRUMENT')}\n",
            "{(238, 249, 'FIRM'), (468, 477, 'ISSUER')}\n",
            "{(596, 616, 'ISSUER'), (967, 978, 'FILIALE'), (284, 300, 'FIRM'), (982, 993, 'FILIALE')}\n",
            "{(821, 840, 'ISSUER'), (284, 299, 'FIRM'), (596, 615, 'ISSUER')}\n",
            "{(2999, 3020, 'FILIALE'), (3207, 3220, 'FILIALE'), (2905, 2915, 'FIRM'), (4838, 4844, 'ISSUER'), (1439, 1449, 'FIRM'), (2957, 2979, 'FILIALE'), (4164, 4170, 'ISSUER'), (1009, 1052, 'FIRM'), (3541, 3554, 'FILIALE'), (3746, 3756, 'FILIALE'), (2014, 2021, 'TYPE'), (3920, 3942, 'FIRM'), (1094, 1101, 'NUMBER'), (3054, 3064, 'FIRM'), (2004, 2010, 'PERCENT'), (2095, 2099, 'ISSUER'), (3347, 3357, 'FIRM'), (3516, 3526, 'FILIALE'), (493, 504, 'FIRM'), (1768, 1791, 'FIRM'), (3760, 3773, 'FILIALE'), (613, 623, 'FILIALE'), (5368, 5389, 'FIRM'), (3193, 3203, 'FILIALE'), (762, 772, 'ISSUER')}\n",
            "{(2957, 2978, 'FIRM'), (3347, 3357, 'ISSUER'), (613, 623, 'FIRM'), (3746, 3756, 'FIRM'), (3193, 3226, 'PERCENT'), (527, 548, 'FIRM'), (3541, 3554, 'ISSUER'), (2905, 2916, 'FIRM'), (1009, 1030, 'FIRM'), (4164, 4169, 'ISSUER'), (1768, 1791, 'ISSUER'), (1439, 1464, 'FIRM'), (493, 503, 'FIRM'), (3516, 3526, 'ISSUER'), (4838, 4843, 'ISSUER'), (1525, 1530, 'ISSUER'), (2095, 2099, 'FIRM'), (3920, 3941, 'FIRM'), (762, 772, 'FIRM'), (1857, 1867, 'FIRM'), (2999, 3020, 'FIRM'), (3054, 3064, 'ISSUER')}\n",
            "{(440, 464, 'FIRM')}\n",
            "{(440, 464, 'FILIALE')}\n",
            "{(860, 886, 'FIRM'), (258, 284, 'FIRM'), (901, 926, 'FILIALE')}\n",
            "{(860, 887, 'FIRM'), (887, 889, 'FIRM'), (258, 283, 'FIRM'), (901, 926, 'FIRM')}\n",
            "{(1284, 1309, 'INSTRUMENT'), (578, 584, 'ISSUER'), (1143, 1146, 'TYPE'), (840, 850, 'INSTRUMENT')}\n",
            "{(1283, 1309, 'INSTRUMENT'), (578, 583, 'ISSUER'), (1143, 1146, 'INSTRUMENT'), (1946, 1957, 'NUMBER')}\n",
            "{(710, 729, 'FILIALE')}\n",
            "{(513, 519, 'NUMBER'), (269, 290, 'FIRM'), (520, 526, 'TYPE')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWhCfR2FTbMl",
        "colab_type": "code",
        "outputId": "4c9faae9-b26f-4bc4-b4f1-7b527431910e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def link_quantities(text, entities, dist_max=15):\n",
        "  linked = []\n",
        "  quantities = []\n",
        "  pos_prev = None\n",
        "  quant_type = None\n",
        "  prev_type = None\n",
        "  for ent_start, ent_end, ent_type in entities:\n",
        "    ent_text = text[ent_start:ent_end]\n",
        "    if ent_type in ['NUMBER', 'PERCENT']:\n",
        "      if (prev_type == ent_type and ent_start - prev_pos < dist_max):\n",
        "        quantities.append(ent_text)\n",
        "        quant_type = ent_type\n",
        "      else:\n",
        "        quantities = [ent_text]\n",
        "        quant_type = ent_type\n",
        "    elif ent_type == 'TYPE':\n",
        "      if len(quantities) != 0 and (prev_type in ['NUMBER', 'PERCENT', 'TYPE']) and ent_start - prev_pos < dist_max:\n",
        "        linked.append((quantities, ent_text, quant_type))\n",
        "      else:\n",
        "        quantities = []\n",
        "    prev_type = ent_type\n",
        "    prev_pos = ent_end\n",
        "  return pd.DataFrame.from_records(linked, columns=['quants', 'unit', 'type'])\n",
        "\n",
        "def get_quantities(df, idx):\n",
        "  if idx >= len(df):\n",
        "    return None\n",
        "  s = df.iloc[idx]\n",
        "  ret = []\n",
        "  for q in s['quants']:\n",
        "    if s['type'] == 'PERCENT':\n",
        "      if '/' in q:\n",
        "        num, den = q.split('/')\n",
        "        ret.append(float(num)/float(den)*100.0)\n",
        "      else:\n",
        "        ret.append(float(q.replace(',', '.').replace('%', '')))\n",
        "    else:\n",
        "      if 'aucun' in q:\n",
        "        ret.append(0)\n",
        "      else:\n",
        "        ret.append(int(q.replace(' ', '')))\n",
        "  return ret\n",
        "\n",
        "\n",
        "\n",
        "def exctract_info(text, entities):\n",
        "  df = pd.DataFrame.from_records([{'text':text[s:e], 'start':s, 'end':e, 'type':t} for s, e, t in entities])\n",
        "  ret = {}\n",
        "  ret['Issuer'] = df[df['type'] == 'ISSUER']['text'].value_counts().index[0]\n",
        "  ret['Firms'] = df[df['type'] == 'FIRM']['text'].value_counts(sort=False).index.to_list()\n",
        "  dir_idx = df[df['type'] == 'DIRECTION'].index[0]\n",
        "  ret['Direction'] = df[df['type'] == 'DIRECTION']['text'].iloc[0]\n",
        "  ret['Date'] = df[(df['type'] == 'DATE') & (df.index > dir_idx)]['text'].iloc[0]\n",
        "  ret['Filiales'] = df[df['type'] == 'FILIALE']['text'].value_counts(sort=False).index.to_list()\n",
        "  ret['Instruments'] = df[df['type'] == 'INSTRUMENT']['text'].value_counts(sort=False).index.to_list()\n",
        "  df_q = link_quantities(text, entities)\n",
        "  cap = df_q[(df_q['type'] == 'PERCENT') & df_q['unit'].str.contains('capital')]\n",
        "  vote = df_q[(df_q['type'] == 'PERCENT') & df_q['unit'].str.contains('vote')]\n",
        "  ret['Action'] = get_quantities(df_q[(df_q['type'] == 'NUMBER') & df_q['unit'].str.contains('action')], 0)\n",
        "  ret['ThreasholdCapital'] = get_quantities(cap, 0)\n",
        "  ret['Capital'] = get_quantities(cap, 1)\n",
        "  ret['ThreasholdVote'] = get_quantities(vote, 0)\n",
        "  ret['Vote'] = get_quantities(vote, 1)\n",
        "\n",
        "  print(ret)\n",
        "\n",
        "\n",
        "for d in test_data:\n",
        "  exctract_info(d[0], d[1]['entities'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Issuer': 'ALTRAN TECHNOLOGIES', 'Firms': ['Bank of America Corporation'], 'Direction': 'en hausse', 'Date': '17 février 2020', 'Filiales': ['Merrill Lynch International', 'BofA Securities Europe SA'], 'Instruments': ['cash-settled equity swap'], 'Action': [14377895], 'ThreasholdCapital': [5.0], 'Capital': [5.59], 'ThreasholdVote': [5.0], 'Vote': [5.58]}\n",
            "{'Issuer': 'VALEO', 'Firms': ['VALEO', 'BlackRock, Inc.'], 'Direction': 'en baisse', 'Date': '29 janvier 2020', 'Filiales': [], 'Instruments': ['contracts for differences'], 'Action': [11878005], 'ThreasholdCapital': [5.0], 'Capital': [4.93], 'ThreasholdVote': [5.0], 'Vote': [4.81]}\n",
            "{'Issuer': 'ALTRAN TECHNOLOGIES', 'Firms': ['Société Générale'], 'Direction': 'en baisse', 'Date': '9 janvier 2020', 'Filiales': [], 'Instruments': [], 'Action': None, 'ThreasholdCapital': [5.0], 'Capital': None, 'ThreasholdVote': [5.0], 'Vote': None}\n",
            "{'Issuer': 'INTERNATIONAL FLAVORS & FRAGRANCES INC', 'Firms': ['BlackRock Inc.'], 'Direction': 'en hausse', 'Date': '31 janvier 2020', 'Filiales': [], 'Instruments': ['collatéral', 'contracts for differences'], 'Action': [6522431], 'ThreasholdCapital': [5.0], 'Capital': [5.07], 'ThreasholdVote': [5.0], 'Vote': [5.07]}\n",
            "{'Issuer': 'ALTRAN TECHNOLOGIES', 'Firms': ['UBS Group AG'], 'Direction': 'en baisse', 'Date': '15 janvier 2020', 'Filiales': [], 'Instruments': [], 'Action': [0], 'ThreasholdCapital': [5.0], 'Capital': None, 'ThreasholdVote': [5.0], 'Vote': None}\n",
            "{'Issuer': 'EUROPCAR MOBILITY GROUP', 'Firms': ['Morgan Stanley Plc'], 'Direction': 'en hausse', 'Date': '8 janvier 2020', 'Filiales': ['Morgan Stanley Capital Services LLC', 'Morgan Stanley France S.A.', 'Morgan Stanley & Co. LLC', 'Morgan Stanley & Co. International plc'], 'Instruments': ['equity swap', 'right to recall'], 'Action': [11499507], 'ThreasholdCapital': [5.0], 'Capital': [7.02], 'ThreasholdVote': [5.0], 'Vote': [6.99]}\n",
            "{'Issuer': 'REXEL', 'Firms': ['BlackRock Inc.'], 'Direction': 'en hausse', 'Date': '20 janvier 2020', 'Filiales': [], 'Instruments': ['collatéral', 'contracts for differences'], 'Action': [15875831], 'ThreasholdCapital': [5.0], 'Capital': [5.22], 'ThreasholdVote': [5.0], 'Vote': [5.22]}\n",
            "{'Issuer': 'UBISOFT ENTERTAINMENT', 'Firms': ['Vivendi', 'CACIB', 'Crédit Agricole Corporate and Investment Bank'], 'Direction': 'en baisse', 'Date': '31 décembre 2019', 'Filiales': ['Crédit Agricole SA'], 'Instruments': ['océanes', 'calls', 'puts warrants', 'promissory notes', 'contrat à terme prépayé', 'Contrat à terme prépayé'], 'Action': [12836501], 'ThreasholdCapital': [10.64], 'Capital': None, 'ThreasholdVote': [10.0], 'Vote': [9.67]}\n",
            "{'Issuer': 'GENEURO SA', 'Firms': ['Invesco Ltd.'], 'Direction': 'en hausse', 'Date': '4 février 2020', 'Filiales': ['Invesco Advisers, Inc.'], 'Instruments': [], 'Action': [1661017], 'ThreasholdCapital': [5.0], 'Capital': [8.07], 'ThreasholdVote': [5.0], 'Vote': [8.07]}\n",
            "{'Issuer': 'EUROPCAR MOBILITY GROUP', 'Firms': ['Morgan Stanley & Co. International plc', 'Morgan Stanley Corp.'], 'Direction': 'en hausse', 'Date': '14 février 2020', 'Filiales': ['Morgan Stanley Capital Services LLC', 'Morgan Stanley France S.A.', 'Morgan Stanley & Co. LLC', 'Morgan Stanley & Co. International plc'], 'Instruments': ['equity swap', 'right to recall'], 'Action': [13372152], 'ThreasholdCapital': [5.0], 'Capital': [8.16], 'ThreasholdVote': [5.0], 'Vote': [8.13]}\n",
            "{'Issuer': 'SABC', 'Firms': ['Heineken N.V.1'], 'Direction': 'en baisse', 'Date': '4 mars 2020', 'Filiales': [], 'Instruments': [], 'Action': [501977], 'ThreasholdCapital': [5.0], 'Capital': None, 'ThreasholdVote': [5.0], 'Vote': None}\n",
            "{'Issuer': 'ALTRAN TECHNOLOGIES', 'Firms': ['Capgemini'], 'Direction': 'en hausse', 'Date': '27 janvier 2020', 'Filiales': [], 'Instruments': [], 'Action': [140136345], 'ThreasholdCapital': [15.0, 20.0, 25.0, 30.0, 33.33333333333333, 50.0], 'Capital': [54.52], 'ThreasholdVote': [15.0, 20.0, 25.0, 30.0, 33.33333333333333, 50.0], 'Vote': [54.37]}\n",
            "{'Issuer': 'INGENICO', 'Firms': ['Société Générale'], 'Direction': 'en baisse', 'Date': '26 février 2020', 'Filiales': [], 'Instruments': [], 'Action': [0], 'ThreasholdCapital': None, 'Capital': None, 'ThreasholdVote': None, 'Vote': None}\n",
            "{'Issuer': 'CGG', 'Firms': ['Morgan Stanley Corp.'], 'Direction': 'en hausse', 'Date': '20 février 2020', 'Filiales': ['Morgan Stanley & Co. LLC', 'Morgan Stanley Europe SE', 'Morgan Stanley & Co. International plc'], 'Instruments': ['equity swap', 'right to recall'], 'Action': [35588487], 'ThreasholdCapital': [5.0], 'Capital': [5.01], 'ThreasholdVote': [5.0], 'Vote': [5.01]}\n",
            "{'Issuer': 'ALTRAN TECHNOLOGIES', 'Firms': ['Société Générale'], 'Direction': 'en hausse', 'Date': '31 décembre 2019', 'Filiales': [], 'Instruments': ['collatéral', 'CFD'], 'Action': [13676497], 'ThreasholdCapital': [5.0], 'Capital': [5.32], 'ThreasholdVote': [5.0], 'Vote': [5.31]}\n",
            "{'Issuer': 'INGENICO', 'Firms': ['JP Morgan Chase & Co.'], 'Direction': 'en hausse', 'Date': '18 février 2020', 'Filiales': ['JP Morgan Securities LLC', 'JP Morgan Securities plc', 'JP Morgan Chase & Co.'], 'Instruments': ['océanes', 'cash-settled equity swap'], 'Action': [3467358], 'ThreasholdCapital': [5.0], 'Capital': [5.44], 'ThreasholdVote': [5.0], 'Vote': None}\n",
            "{'Issuer': 'CGG', 'Firms': ['Morgan Stanley & Co. International plc', 'Morgan Stanley & Co International plc'], 'Direction': 'en hausse', 'Date': '11 février 2020', 'Filiales': ['Morgan Stanley & Co. LLC', 'Morgan Stanley Corp.'], 'Instruments': ['equity swap', 'right to recall'], 'Action': [37182936], 'ThreasholdCapital': [5.0], 'Capital': [5.24], 'ThreasholdVote': [5.0], 'Vote': [5.24]}\n",
            "{'Issuer': 'KLEPIERRE', 'Firms': ['Norges Bank'], 'Direction': 'en baisse', 'Date': '2 mars 2020', 'Filiales': [], 'Instruments': ['collatéral'], 'Action': [14920354], 'ThreasholdCapital': None, 'Capital': None, 'ThreasholdVote': None, 'Vote': None}\n",
            "{'Issuer': 'SAFE ORTHOPAEDICS', 'Firms': ['European High Growth Opportunities Manco'], 'Direction': 'en hausse', 'Date': '21 janvier 2020', 'Filiales': ['European High Growth Opportunities Securization Fund'], 'Instruments': ['bons de souscription d’actions', 'océanes'], 'Action': [248447], 'ThreasholdCapital': [5.0, 10.0, 15.0], 'Capital': [16.14], 'ThreasholdVote': [5.0, 10.0, 15.0], 'Vote': [15.67]}\n",
            "{'Issuer': 'APRIL', 'Firms': ['Andromeda Investissements', 'Androméda Investissements'], 'Direction': 'en hausse', 'Date': '31 décembre 2019', 'Filiales': [], 'Instruments': [], 'Action': [40637087], 'ThreasholdCapital': [90.0, 95.0], 'Capital': [99.01], 'ThreasholdVote': [90.0, 95.0], 'Vote': [98.71]}\n",
            "{'Issuer': 'INGENICO', 'Firms': ['JP Morgan Chase & Co.', 'JP Morgan Securities plc', 'JP Morgan Securities LLC'], 'Direction': 'en hausse', 'Date': '5 février 2020', 'Filiales': [], 'Instruments': ['océanes', 'cash-settled equity swap'], 'Action': [3834494], 'ThreasholdCapital': [5.0], 'Capital': [6.02], 'ThreasholdVote': [5.0], 'Vote': [5.63]}\n",
            "{'Issuer': 'CGG', 'Firms': ['Norges Bank'], 'Direction': 'en hausse', 'Date': '3 février 2020', 'Filiales': [], 'Instruments': ['collatéral', 'bons de souscription d’actions nouvelles'], 'Action': [37355380], 'ThreasholdCapital': [5.0], 'Capital': [5.26], 'ThreasholdVote': [5.0], 'Vote': [5.26]}\n",
            "{'Issuer': 'ICADE', 'Firms': ['ICAMAP Investments S.à r.l.', 'GIC Private Limited', 'Future Fund Board of Guardians'], 'Direction': 'en baisse', 'Date': '19 février 2020', 'Filiales': [], 'Instruments': [], 'Action': [3673553], 'ThreasholdCapital': [5.0], 'Capital': [4.93], 'ThreasholdVote': [5.0], 'Vote': [4.93]}\n",
            "{'Issuer': 'SABC', 'Firms': ['Société des Brasseries & Glacières Internationales', 'BGI', 'Société Nationale d’Investissement du Cameroun'], 'Direction': 'en hausse', 'Date': '4 mars 2020', 'Filiales': [], 'Instruments': [], 'Action': [5383984], 'ThreasholdCapital': [90.0], 'Capital': [93.86], 'ThreasholdVote': [90.0], 'Vote': [93.86]}\n",
            "{'Issuer': 'CGG', 'Firms': ['Norges Bank'], 'Direction': 'en hausse', 'Date': '21 janvier 2020', 'Filiales': [], 'Instruments': ['collatéral'], 'Action': [35608075], 'ThreasholdCapital': [5.0], 'Capital': [5.02], 'ThreasholdVote': [5.0], 'Vote': [5.01]}\n",
            "{'Issuer': 'INGENICO', 'Firms': ['UBS Group AG ('], 'Direction': 'en baisse', 'Date': '25 février 2020', 'Filiales': [], 'Instruments': [], 'Action': [0], 'ThreasholdCapital': [5.0], 'Capital': None, 'ThreasholdVote': [5.0], 'Vote': None}\n",
            "{'Issuer': 'CGG', 'Firms': ['The Goldman Sachs Group, Inc.'], 'Direction': 'en baisse', 'Date': '3 mars 2020', 'Filiales': ['Goldman Sachs International'], 'Instruments': [], 'Action': [1172802], 'ThreasholdCapital': [5.0], 'Capital': [0.17], 'ThreasholdVote': [5.0], 'Vote': [0.17]}\n",
            "{'Issuer': 'INVENTIVA', 'Firms': ['BVF Partners, LP', 'BVF Partners LP.'], 'Direction': 'en hausse', 'Date': '10 février 2020', 'Filiales': [], 'Instruments': [], 'Action': [8110525], 'ThreasholdCapital': [25.0], 'Capital': [26.43], 'ThreasholdVote': [15.0], 'Vote': [19.92]}\n",
            "{'Issuer': 'ARCHOS', 'Firms': ['Yorkville Advisors Global LP'], 'Direction': 'en baisse', 'Date': '7 janvier 2020', 'Filiales': ['YA II PN Ltd'], 'Instruments': ['bons de souscription d’actions nouvelles', 'obligations convertibles en actions'], 'Action': [3489394], 'ThreasholdCapital': [5.0], 'Capital': [4.06], 'ThreasholdVote': [5.0], 'Vote': [3.9]}\n",
            "{'Issuer': 'DBV TECHNOLOGIES', 'Firms': ['Morgan Stanley'], 'Direction': 'en baisse', 'Date': '4 février 2020', 'Filiales': ['Morgan Stanley & Co. LLC', 'Morgan Stanley & Co. International plc'], 'Instruments': ['right to recall'], 'Action': [43120], 'ThreasholdCapital': [5.0], 'Capital': [0.08], 'ThreasholdVote': [5.0], 'Vote': [0.08]}\n",
            "{'Issuer': 'EUROPCAR MOBILITY GROUP', 'Firms': ['Invesco Ltd.'], 'Direction': 'en baisse', 'Date': '17 janvier 2020', 'Filiales': [], 'Instruments': [], 'Action': [8117866], 'ThreasholdCapital': [5.0], 'Capital': [4.95], 'ThreasholdVote': [5.0], 'Vote': [4.94]}\n",
            "{'Issuer': 'KLEPIERRE', 'Firms': ['Norges Bank'], 'Direction': 'en hausse', 'Date': '3 février 2020', 'Filiales': [], 'Instruments': ['collatéral'], 'Action': [15351804], 'ThreasholdCapital': [5.0], 'Capital': [5.07], 'ThreasholdVote': [5.0], 'Vote': [5.07]}\n",
            "{'Issuer': 'ALTRAN TECHNOLOGIES', 'Firms': ['Syquant Capital'], 'Direction': 'en hausse', 'Date': '20 janvier 2020', 'Filiales': [], 'Instruments': ['contracts for differences'], 'Action': [13405770], 'ThreasholdCapital': [5.0], 'Capital': [5.22], 'ThreasholdVote': [5.0], 'Vote': [5.2]}\n",
            "{'Issuer': 'SAMSE', 'Firms': ['Blackstone', 'Dumont Investissement', 'BME France et constitutif', 'BME France', 'BME France ', 'FCPE'], 'Direction': 'en hausse', 'Date': '24 janvier 2020', 'Filiales': [], 'Instruments': [], 'Action': [730640], 'ThreasholdCapital': [21.13], 'Capital': [24.86], 'ThreasholdVote': [66.85], 'Vote': [27.03]}\n",
            "{'Issuer': 'INGENICO', 'Firms': ['JP Morgan Chase & Co.'], 'Direction': 'en baisse', 'Date': '10 février 2020', 'Filiales': ['JP Morgan Securities LLC', 'JP Morgan Securities plc'], 'Instruments': [], 'Action': [14234], 'ThreasholdCapital': [5.0], 'Capital': [0.02], 'ThreasholdVote': [5.0], 'Vote': [0.02]}\n",
            "{'Issuer': 'VOLUNTIS', 'Firms': ['A.', 'Sycomore Asset Management', 'Assicurazioni Generali S.p.'], 'Direction': 'en hausse', 'Date': '26 février 2020', 'Filiales': [], 'Instruments': [], 'Action': [383797], 'ThreasholdCapital': [5.0], 'Capital': [5.05], 'ThreasholdVote': [5.0], 'Vote': [5.05]}\n",
            "{'Issuer': 'VALEO', 'Firms': ['BlackRock, Inc.'], 'Direction': 'en baisse', 'Date': '6 mars 2020', 'Filiales': [], 'Instruments': ['collatéral', 'ADR', ' contracts for differences'], 'Action': [11871928], 'ThreasholdCapital': [5.0], 'Capital': [4.93], 'ThreasholdVote': [5.0], 'Vote': [4.82]}\n",
            "{'Issuer': 'APRIL', 'Firms': ['Persée Participations'], 'Direction': 'en baisse', 'Date': '31 décembre 2019', 'Filiales': [], 'Instruments': [], 'Action': [0], 'ThreasholdCapital': [10.0, 5.0], 'Capital': None, 'ThreasholdVote': [10.0, 5.0], 'Vote': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfgXppRI7ZIQ",
        "colab_type": "code",
        "outputId": "68a05b62-52a4-4231-8bac-2ae28f07d4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text, chunk.label_, chunk.root.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 220C0426-FR0000121964-FS0115             220C0426 FR0000121964-FS0115 31 janvier 2020    NP 220C0426-FR0000121964-FS0115\n",
            "de franchissement de seuils NP franchissement\n",
            "article L. 233 NP article\n",
            "7 du code de commerce)    KLEPIERRE  (Euronext Paris)    Par courrier NP code\n",
            "Bankplassen 2 NP Bankplassen\n",
            ", Sentrum NP Sentrum\n",
            "les seuils de 5% du capital et des droits de vote de la société KLEPIERRE et détenir 15 072 929 actions KLEPIERRE2 NP seuils\n",
            "de droits de vote NP droits\n",
            "soit 4,98% du capital et des droits de vote de cette société3 NP %\n",
            "Ce franchissement de seuils résulte d’une restitution d’actions KLEPIERRE à titre de collatéral.   NP franchissement\n",
            "_ NP _\n",
            "_ NP _\n",
            "_ NP _\n",
            "_ NP _\n",
            "_ NP _\n",
            "_                                                             NP _\n",
            "1 La Banque Centrale de Norvège. NP Banque\n",
            "Dont NP Dont\n",
            "126 actions détenues à titre de collatéral NP actions\n",
            "Sur la base d'un capital composé de 302 664 095 actions représentant autant de droits de vote, en application du 2ème alinéa de l’article 223 NP base\n",
            "-11 du règlement général. \f NP règlement\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkErWdRX6Hl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVhNBXbq9gIy",
        "colab_type": "text"
      },
      "source": [
        "## Hugging face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPyFMJfG9l-A",
        "colab_type": "code",
        "outputId": "5b37cc0c-f0d6-4c75-b7f4-f4ae1d83d66d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 4.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 61.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=5bf82966c9017110ab670dc3883fd48a8f747d7d26d3db60ebc3ad895072e259\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUx9lf089pky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "# Named entity recognition pipeline, passing in a specific model and tokenizer\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"camembert-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")\n",
        "ner = pipeline('ner', model=model, tokenizer=tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mnpqCZ54qIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_label(data, tokenizer):\n",
        "  X = []\n",
        "  Y = []\n",
        "  for text, labels in data:\n",
        "    offset = 0\n",
        "    idx_ent = 0\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    y = []\n",
        "    for tok in tokens:\n",
        "      if idx_ent >= len(labels['entities']):\n",
        "        y = y + ['O']*(len(tokens) - len(y))\n",
        "        break\n",
        "      offset_tok = 1 if tok[0] == '▁' else 0\n",
        "      tok_s = None\n",
        "      for offset_tok in range(offset_tok, len(tok)):\n",
        "        while offset < len(text) and text[offset] != tok[offset_tok]:\n",
        "          offset += 1\n",
        "        if tok_s is None:\n",
        "          tok_s = offset\n",
        "        offset += 1\n",
        "      tok_e = offset\n",
        "      ent_s, ent_e, ent_t = labels['entities'][idx_ent]\n",
        "      if tok_s is not None and tok_s >= ent_s:\n",
        "        y.append(ent_t)\n",
        "        if tok_e >= ent_e:\n",
        "          idx_ent += 1\n",
        "      else:\n",
        "        y.append('O')\n",
        "    X.append(tokens)\n",
        "    Y.append(y)\n",
        "  return X, Y\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPp-b33rK5O1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06718467-9030-4702-9655-4c13ee1b7808"
      },
      "source": [
        "len(X[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhnavQBCE53c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "cc21b63a-819e-49fa-97ef-75d9e640d14c"
      },
      "source": [
        "import pandas as pd\n",
        "%load_ext google.colab.data_table\n",
        "\n",
        "X, Y = transform_label(train_data, tokenizer)\n",
        "df = pd.DataFrame()\n",
        "df['X'] = X[0]\n",
        "df['Y'] = Y[0]\n",
        "df\n",
        "#print(df)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"\\u2581220\",\n\"O\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"C\",\n\"O\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"07\",\n\"O\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"13\",\n\"O\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"-\",\n\"O\"],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"FR\",\n\"O\"],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"00\",\n\"O\"],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"13\",\n\"O\"],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"1818\",\n\"O\"],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"64\",\n\"O\"],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n\"-\",\n\"O\"],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n\"FS\",\n\"O\"],\n [{\n            'v': 12,\n            'f': \"12\",\n        },\n\"01\",\n\"O\"],\n [{\n            'v': 13,\n            'f': \"13\",\n        },\n\"88\",\n\"O\"],\n [{\n            'v': 14,\n            'f': \"14\",\n        },\n\"\\u2581220\",\n\"O\"],\n [{\n            'v': 15,\n            'f': \"15\",\n        },\n\"C\",\n\"O\"],\n [{\n            'v': 16,\n            'f': \"16\",\n        },\n\"07\",\n\"O\"],\n [{\n            'v': 17,\n            'f': \"17\",\n        },\n\"13\",\n\"O\"],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n\"\\u2581FR\",\n\"O\"],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n\"00\",\n\"O\"],\n [{\n            'v': 20,\n            'f': \"20\",\n        },\n\"13\",\n\"O\"],\n [{\n            'v': 21,\n            'f': \"21\",\n        },\n\"1818\",\n\"O\"],\n [{\n            'v': 22,\n            'f': \"22\",\n        },\n\"64\",\n\"O\"],\n [{\n            'v': 23,\n            'f': \"23\",\n        },\n\"-\",\n\"O\"],\n [{\n            'v': 24,\n            'f': \"24\",\n        },\n\"FS\",\n\"O\"],\n [{\n            'v': 25,\n            'f': \"25\",\n        },\n\"01\",\n\"O\"],\n [{\n            'v': 26,\n            'f': \"26\",\n        },\n\"88\",\n\"O\"],\n [{\n            'v': 27,\n            'f': \"27\",\n        },\n\"\\u258121\",\n\"DATE\"],\n [{\n            'v': 28,\n            'f': \"28\",\n        },\n\"\\u2581f\\u00e9vrier\",\n\"DATE\"],\n [{\n            'v': 29,\n            'f': \"29\",\n        },\n\"\\u25812020\",\n\"DATE\"],\n [{\n            'v': 30,\n            'f': \"30\",\n        },\n\"\\u2581D\\u00e9claration\",\n\"O\"],\n [{\n            'v': 31,\n            'f': \"31\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 32,\n            'f': \"32\",\n        },\n\"\\u2581franchissement\",\n\"O\"],\n [{\n            'v': 33,\n            'f': \"33\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 34,\n            'f': \"34\",\n        },\n\"\\u2581seuil\",\n\"O\"],\n [{\n            'v': 35,\n            'f': \"35\",\n        },\n\"s\",\n\"O\"],\n [{\n            'v': 36,\n            'f': \"36\",\n        },\n\"\\u2581(\",\n\"O\"],\n [{\n            'v': 37,\n            'f': \"37\",\n        },\n\"article\",\n\"O\"],\n [{\n            'v': 38,\n            'f': \"38\",\n        },\n\"\\u2581L\",\n\"O\"],\n [{\n            'v': 39,\n            'f': \"39\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 40,\n            'f': \"40\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 41,\n            'f': \"41\",\n        },\n\"233\",\n\"O\"],\n [{\n            'v': 42,\n            'f': \"42\",\n        },\n\"-7\",\n\"O\"],\n [{\n            'v': 43,\n            'f': \"43\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 44,\n            'f': \"44\",\n        },\n\"\\u2581code\",\n\"O\"],\n [{\n            'v': 45,\n            'f': \"45\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 46,\n            'f': \"46\",\n        },\n\"\\u2581commerce\",\n\"O\"],\n [{\n            'v': 47,\n            'f': \"47\",\n        },\n\")\",\n\"O\"],\n [{\n            'v': 48,\n            'f': \"48\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 49,\n            'f': \"49\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 50,\n            'f': \"50\",\n        },\n\"\\u2581(\",\n\"O\"],\n [{\n            'v': 51,\n            'f': \"51\",\n        },\n\"Euro\",\n\"O\"],\n [{\n            'v': 52,\n            'f': \"52\",\n        },\n\"next\",\n\"O\"],\n [{\n            'v': 53,\n            'f': \"53\",\n        },\n\"\\u2581Paris\",\n\"O\"],\n [{\n            'v': 54,\n            'f': \"54\",\n        },\n\")\",\n\"O\"],\n [{\n            'v': 55,\n            'f': \"55\",\n        },\n\"\\u2581Par\",\n\"O\"],\n [{\n            'v': 56,\n            'f': \"56\",\n        },\n\"\\u2581courrier\",\n\"O\"],\n [{\n            'v': 57,\n            'f': \"57\",\n        },\n\"\\u2581re\\u00e7u\",\n\"O\"],\n [{\n            'v': 58,\n            'f': \"58\",\n        },\n\"\\u2581le\",\n\"O\"],\n [{\n            'v': 59,\n            'f': \"59\",\n        },\n\"\\u258121\",\n\"DATE\"],\n [{\n            'v': 60,\n            'f': \"60\",\n        },\n\"\\u2581f\\u00e9vrier\",\n\"DATE\"],\n [{\n            'v': 61,\n            'f': \"61\",\n        },\n\"\\u25812020\",\n\"DATE\"],\n [{\n            'v': 62,\n            'f': \"62\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 63,\n            'f': \"63\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 64,\n            'f': \"64\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 65,\n            'f': \"65\",\n        },\n\"\\u2581Morgan\",\n\"FIRM\"],\n [{\n            'v': 66,\n            'f': \"66\",\n        },\n\"\\u2581Stanley\",\n\"FIRM\"],\n [{\n            'v': 67,\n            'f': \"67\",\n        },\n\"\\u2581&\",\n\"FIRM\"],\n [{\n            'v': 68,\n            'f': \"68\",\n        },\n\"\\u2581Co\",\n\"FIRM\"],\n [{\n            'v': 69,\n            'f': \"69\",\n        },\n\"\\u2581International\",\n\"FIRM\"],\n [{\n            'v': 70,\n            'f': \"70\",\n        },\n\"\\u2581pl\",\n\"FIRM\"],\n [{\n            'v': 71,\n            'f': \"71\",\n        },\n\"c\",\n\"FIRM\"],\n [{\n            'v': 72,\n            'f': \"72\",\n        },\n\"1\",\n\"O\"],\n [{\n            'v': 73,\n            'f': \"73\",\n        },\n\"\\u2581(25\",\n\"O\"],\n [{\n            'v': 74,\n            'f': \"74\",\n        },\n\"\\u2581Ca\",\n\"O\"],\n [{\n            'v': 75,\n            'f': \"75\",\n        },\n\"bot\",\n\"O\"],\n [{\n            'v': 76,\n            'f': \"76\",\n        },\n\"\\u2581Square\",\n\"O\"],\n [{\n            'v': 77,\n            'f': \"77\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 78,\n            'f': \"78\",\n        },\n\"\\u2581Can\",\n\"O\"],\n [{\n            'v': 79,\n            'f': \"79\",\n        },\n\"ary\",\n\"O\"],\n [{\n            'v': 80,\n            'f': \"80\",\n        },\n\"\\u2581W\",\n\"O\"],\n [{\n            'v': 81,\n            'f': \"81\",\n        },\n\"har\",\n\"O\"],\n [{\n            'v': 82,\n            'f': \"82\",\n        },\n\"f\",\n\"O\"],\n [{\n            'v': 83,\n            'f': \"83\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 84,\n            'f': \"84\",\n        },\n\"\\u2581Londres\",\n\"O\"],\n [{\n            'v': 85,\n            'f': \"85\",\n        },\n\"\\u2581E\",\n\"O\"],\n [{\n            'v': 86,\n            'f': \"86\",\n        },\n\"14\",\n\"O\"],\n [{\n            'v': 87,\n            'f': \"87\",\n        },\n\"\\u25814\",\n\"O\"],\n [{\n            'v': 88,\n            'f': \"88\",\n        },\n\"Q\",\n\"O\"],\n [{\n            'v': 89,\n            'f': \"89\",\n        },\n\"A\",\n\"O\"],\n [{\n            'v': 90,\n            'f': \"90\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 91,\n            'f': \"91\",\n        },\n\"\\u2581Royaume\",\n\"O\"],\n [{\n            'v': 92,\n            'f': \"92\",\n        },\n\"\\u2581Uni\",\n\"O\"],\n [{\n            'v': 93,\n            'f': \"93\",\n        },\n\"),\",\n\"O\"],\n [{\n            'v': 94,\n            'f': \"94\",\n        },\n\"\\u2581a\",\n\"O\"],\n [{\n            'v': 95,\n            'f': \"95\",\n        },\n\"\\u2581d\\u00e9clar\\u00e9\",\n\"O\"],\n [{\n            'v': 96,\n            'f': \"96\",\n        },\n\"\\u2581avoir\",\n\"O\"],\n [{\n            'v': 97,\n            'f': \"97\",\n        },\n\"\\u2581franchi\",\n\"O\"],\n [{\n            'v': 98,\n            'f': \"98\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 99,\n            'f': \"99\",\n        },\n\"individuellement\",\n\"O\"],\n [{\n            'v': 100,\n            'f': \"100\",\n        },\n\"\\u2581en\",\n\"DIRECTION\"],\n [{\n            'v': 101,\n            'f': \"101\",\n        },\n\"\\u2581hausse\",\n\"DIRECTION\"],\n [{\n            'v': 102,\n            'f': \"102\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 103,\n            'f': \"103\",\n        },\n\"\\u2581le\",\n\"O\"],\n [{\n            'v': 104,\n            'f': \"104\",\n        },\n\"\\u258117\",\n\"DATE\"],\n [{\n            'v': 105,\n            'f': \"105\",\n        },\n\"\\u2581f\\u00e9vrier\",\n\"DATE\"],\n [{\n            'v': 106,\n            'f': \"106\",\n        },\n\"\\u25812020\",\n\"DATE\"],\n [{\n            'v': 107,\n            'f': \"107\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 108,\n            'f': \"108\",\n        },\n\"\\u2581les\",\n\"O\"],\n [{\n            'v': 109,\n            'f': \"109\",\n        },\n\"\\u2581seuil\",\n\"O\"],\n [{\n            'v': 110,\n            'f': \"110\",\n        },\n\"s\",\n\"O\"],\n [{\n            'v': 111,\n            'f': \"111\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 112,\n            'f': \"112\",\n        },\n\"\\u25815%\",\n\"PERCENT\"],\n [{\n            'v': 113,\n            'f': \"113\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 114,\n            'f': \"114\",\n        },\n\"\\u2581capital\",\n\"TYPE\"],\n [{\n            'v': 115,\n            'f': \"115\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 116,\n            'f': \"116\",\n        },\n\"\\u2581des\",\n\"O\"],\n [{\n            'v': 117,\n            'f': \"117\",\n        },\n\"\\u2581droits\",\n\"TYPE\"],\n [{\n            'v': 118,\n            'f': \"118\",\n        },\n\"\\u2581de\",\n\"TYPE\"],\n [{\n            'v': 119,\n            'f': \"119\",\n        },\n\"\\u2581vote\",\n\"TYPE\"],\n [{\n            'v': 120,\n            'f': \"120\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 121,\n            'f': \"121\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 122,\n            'f': \"122\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 123,\n            'f': \"123\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 124,\n            'f': \"124\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 125,\n            'f': \"125\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 126,\n            'f': \"126\",\n        },\n\"\\u2581d\\u00e9tenir\",\n\"O\"],\n [{\n            'v': 127,\n            'f': \"127\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 128,\n            'f': \"128\",\n        },\n\"individuellement\",\n\"O\"],\n [{\n            'v': 129,\n            'f': \"129\",\n        },\n\"\\u258135\",\n\"NUMBER\"],\n [{\n            'v': 130,\n            'f': \"130\",\n        },\n\"\\u25817\",\n\"NUMBER\"],\n [{\n            'v': 131,\n            'f': \"131\",\n        },\n\"32\",\n\"NUMBER\"],\n [{\n            'v': 132,\n            'f': \"132\",\n        },\n\"\\u25819\",\n\"NUMBER\"],\n [{\n            'v': 133,\n            'f': \"133\",\n        },\n\"95\",\n\"NUMBER\"],\n [{\n            'v': 134,\n            'f': \"134\",\n        },\n\"\\u2581actions\",\n\"TYPE\"],\n [{\n            'v': 135,\n            'f': \"135\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 136,\n            'f': \"136\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 137,\n            'f': \"137\",\n        },\n\"\\u2581repr\\u00e9sentant\",\n\"O\"],\n [{\n            'v': 138,\n            'f': \"138\",\n        },\n\"\\u2581autant\",\n\"O\"],\n [{\n            'v': 139,\n            'f': \"139\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 140,\n            'f': \"140\",\n        },\n\"\\u2581droits\",\n\"O\"],\n [{\n            'v': 141,\n            'f': \"141\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 142,\n            'f': \"142\",\n        },\n\"\\u2581vote\",\n\"O\"],\n [{\n            'v': 143,\n            'f': \"143\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 144,\n            'f': \"144\",\n        },\n\"\\u2581soit\",\n\"O\"],\n [{\n            'v': 145,\n            'f': \"145\",\n        },\n\"\\u25815\",\n\"PERCENT\"],\n [{\n            'v': 146,\n            'f': \"146\",\n        },\n\",\",\n\"PERCENT\"],\n [{\n            'v': 147,\n            'f': \"147\",\n        },\n\"0\",\n\"PERCENT\"],\n [{\n            'v': 148,\n            'f': \"148\",\n        },\n\"3%\",\n\"PERCENT\"],\n [{\n            'v': 149,\n            'f': \"149\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 150,\n            'f': \"150\",\n        },\n\"\\u2581capital\",\n\"TYPE\"],\n [{\n            'v': 151,\n            'f': \"151\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 152,\n            'f': \"152\",\n        },\n\"\\u2581des\",\n\"O\"],\n [{\n            'v': 153,\n            'f': \"153\",\n        },\n\"\\u2581droits\",\n\"TYPE\"],\n [{\n            'v': 154,\n            'f': \"154\",\n        },\n\"\\u2581de\",\n\"TYPE\"],\n [{\n            'v': 155,\n            'f': \"155\",\n        },\n\"\\u2581vote\",\n\"TYPE\"],\n [{\n            'v': 156,\n            'f': \"156\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 157,\n            'f': \"157\",\n        },\n\"\\u2581cette\",\n\"O\"],\n [{\n            'v': 158,\n            'f': \"158\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 159,\n            'f': \"159\",\n        },\n\"2.\",\n\"O\"],\n [{\n            'v': 160,\n            'f': \"160\",\n        },\n\"\\u2581Ce\",\n\"O\"],\n [{\n            'v': 161,\n            'f': \"161\",\n        },\n\"\\u2581franchissement\",\n\"O\"],\n [{\n            'v': 162,\n            'f': \"162\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 163,\n            'f': \"163\",\n        },\n\"\\u2581seuil\",\n\"O\"],\n [{\n            'v': 164,\n            'f': \"164\",\n        },\n\"s\",\n\"O\"],\n [{\n            'v': 165,\n            'f': \"165\",\n        },\n\"\\u2581r\\u00e9sulte\",\n\"O\"],\n [{\n            'v': 166,\n            'f': \"166\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 167,\n            'f': \"167\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 168,\n            'f': \"168\",\n        },\n\"une\",\n\"O\"],\n [{\n            'v': 169,\n            'f': \"169\",\n        },\n\"\\u2581acquisition\",\n\"O\"],\n [{\n            'v': 170,\n            'f': \"170\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 171,\n            'f': \"171\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 172,\n            'f': \"172\",\n        },\n\"actions\",\n\"O\"],\n [{\n            'v': 173,\n            'f': \"173\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 174,\n            'f': \"174\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 175,\n            'f': \"175\",\n        },\n\"\\u2581hors\",\n\"O\"],\n [{\n            'v': 176,\n            'f': \"176\",\n        },\n\"\\u2581march\\u00e9\",\n\"O\"],\n [{\n            'v': 177,\n            'f': \"177\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 178,\n            'f': \"178\",\n        },\n\"\\u2581\\u00c0\",\n\"O\"],\n [{\n            'v': 179,\n            'f': \"179\",\n        },\n\"\\u2581cette\",\n\"O\"],\n [{\n            'v': 180,\n            'f': \"180\",\n        },\n\"\\u2581occasion\",\n\"O\"],\n [{\n            'v': 181,\n            'f': \"181\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 182,\n            'f': \"182\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 183,\n            'f': \"183\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 184,\n            'f': \"184\",\n        },\n\"\\u2581Morgan\",\n\"FILIALE\"],\n [{\n            'v': 185,\n            'f': \"185\",\n        },\n\"\\u2581Stanley\",\n\"FILIALE\"],\n [{\n            'v': 186,\n            'f': \"186\",\n        },\n\"\\u2581Cor\",\n\"FILIALE\"],\n [{\n            'v': 187,\n            'f': \"187\",\n        },\n\"p\",\n\"FILIALE\"],\n [{\n            'v': 188,\n            'f': \"188\",\n        },\n\".\",\n\"FILIALE\"],\n [{\n            'v': 189,\n            'f': \"189\",\n        },\n\"\\u2581(\",\n\"O\"],\n [{\n            'v': 190,\n            'f': \"190\",\n        },\n\"c\",\n\"O\"],\n [{\n            'v': 191,\n            'f': \"191\",\n        },\n\"/\",\n\"O\"],\n [{\n            'v': 192,\n            'f': \"192\",\n        },\n\"o\",\n\"O\"],\n [{\n            'v': 193,\n            'f': \"193\",\n        },\n\"\\u2581The\",\n\"O\"],\n [{\n            'v': 194,\n            'f': \"194\",\n        },\n\"\\u2581Corporation\",\n\"O\"],\n [{\n            'v': 195,\n            'f': \"195\",\n        },\n\"\\u2581T\",\n\"O\"],\n [{\n            'v': 196,\n            'f': \"196\",\n        },\n\"rust\",\n\"O\"],\n [{\n            'v': 197,\n            'f': \"197\",\n        },\n\"\\u2581Company\",\n\"O\"],\n [{\n            'v': 198,\n            'f': \"198\",\n        },\n\"\\u2581(\",\n\"O\"],\n [{\n            'v': 199,\n            'f': \"199\",\n        },\n\"DE\",\n\"O\"],\n [{\n            'v': 200,\n            'f': \"200\",\n        },\n\"),\",\n\"O\"],\n [{\n            'v': 201,\n            'f': \"201\",\n        },\n\"\\u2581Corporation\",\n\"O\"],\n [{\n            'v': 202,\n            'f': \"202\",\n        },\n\"\\u2581T\",\n\"O\"],\n [{\n            'v': 203,\n            'f': \"203\",\n        },\n\"rust\",\n\"O\"],\n [{\n            'v': 204,\n            'f': \"204\",\n        },\n\"\\u2581Center\",\n\"O\"],\n [{\n            'v': 205,\n            'f': \"205\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 206,\n            'f': \"206\",\n        },\n\"\\u258112\",\n\"O\"],\n [{\n            'v': 207,\n            'f': \"207\",\n        },\n\"09\",\n\"O\"],\n [{\n            'v': 208,\n            'f': \"208\",\n        },\n\"\\u2581Orange\",\n\"O\"],\n [{\n            'v': 209,\n            'f': \"209\",\n        },\n\"\\u2581Street\",\n\"O\"],\n [{\n            'v': 210,\n            'f': \"210\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 211,\n            'f': \"211\",\n        },\n\"\\u2581Wil\",\n\"O\"],\n [{\n            'v': 212,\n            'f': \"212\",\n        },\n\"m\",\n\"O\"],\n [{\n            'v': 213,\n            'f': \"213\",\n        },\n\"ington\",\n\"O\"],\n [{\n            'v': 214,\n            'f': \"214\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 215,\n            'f': \"215\",\n        },\n\"\\u2581Dela\",\n\"O\"],\n [{\n            'v': 216,\n            'f': \"216\",\n        },\n\"ware\",\n\"O\"],\n [{\n            'v': 217,\n            'f': \"217\",\n        },\n\"\\u2581DE\",\n\"O\"],\n [{\n            'v': 218,\n            'f': \"218\",\n        },\n\"\\u25811980\",\n\"O\"],\n [{\n            'v': 219,\n            'f': \"219\",\n        },\n\"1,\",\n\"O\"],\n [{\n            'v': 220,\n            'f': \"220\",\n        },\n\"\\u2581Etats\",\n\"O\"],\n [{\n            'v': 221,\n            'f': \"221\",\n        },\n\"-\",\n\"O\"],\n [{\n            'v': 222,\n            'f': \"222\",\n        },\n\"Unis\",\n\"O\"],\n [{\n            'v': 223,\n            'f': \"223\",\n        },\n\")\",\n\"O\"],\n [{\n            'v': 224,\n            'f': \"224\",\n        },\n\"\\u2581n\",\n\"O\"],\n [{\n            'v': 225,\n            'f': \"225\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 226,\n            'f': \"226\",\n        },\n\"a\",\n\"O\"],\n [{\n            'v': 227,\n            'f': \"227\",\n        },\n\"\\u2581franchi\",\n\"O\"],\n [{\n            'v': 228,\n            'f': \"228\",\n        },\n\"\\u2581aucun\",\n\"O\"],\n [{\n            'v': 229,\n            'f': \"229\",\n        },\n\"\\u2581seuil\",\n\"O\"],\n [{\n            'v': 230,\n            'f': \"230\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 231,\n            'f': \"231\",\n        },\n\"\\u2581a\",\n\"O\"],\n [{\n            'v': 232,\n            'f': \"232\",\n        },\n\"\\u2581pr\\u00e9cis\\u00e9\",\n\"O\"],\n [{\n            'v': 233,\n            'f': \"233\",\n        },\n\"\\u2581d\\u00e9tenir\",\n\"O\"],\n [{\n            'v': 234,\n            'f': \"234\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 235,\n            'f': \"235\",\n        },\n\"\\u2581indirectement\",\n\"O\"],\n [{\n            'v': 236,\n            'f': \"236\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 237,\n            'f': \"237\",\n        },\n\"\\u258135\",\n\"NUMBER\"],\n [{\n            'v': 238,\n            'f': \"238\",\n        },\n\"\\u25817\",\n\"NUMBER\"],\n [{\n            'v': 239,\n            'f': \"239\",\n        },\n\"42\",\n\"NUMBER\"],\n [{\n            'v': 240,\n            'f': \"240\",\n        },\n\"\\u25816\",\n\"NUMBER\"],\n [{\n            'v': 241,\n            'f': \"241\",\n        },\n\"97\",\n\"NUMBER\"],\n [{\n            'v': 242,\n            'f': \"242\",\n        },\n\"\\u2581actions\",\n\"TYPE\"],\n [{\n            'v': 243,\n            'f': \"243\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 244,\n            'f': \"244\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 245,\n            'f': \"245\",\n        },\n\"\\u2581repr\\u00e9sentant\",\n\"O\"],\n [{\n            'v': 246,\n            'f': \"246\",\n        },\n\"\\u2581autant\",\n\"O\"],\n [{\n            'v': 247,\n            'f': \"247\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 248,\n            'f': \"248\",\n        },\n\"\\u2581droits\",\n\"O\"],\n [{\n            'v': 249,\n            'f': \"249\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 250,\n            'f': \"250\",\n        },\n\"\\u2581vote\",\n\"O\"],\n [{\n            'v': 251,\n            'f': \"251\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 252,\n            'f': \"252\",\n        },\n\"\\u2581soit\",\n\"O\"],\n [{\n            'v': 253,\n            'f': \"253\",\n        },\n\"\\u25815\",\n\"PERCENT\"],\n [{\n            'v': 254,\n            'f': \"254\",\n        },\n\",\",\n\"PERCENT\"],\n [{\n            'v': 255,\n            'f': \"255\",\n        },\n\"0\",\n\"PERCENT\"],\n [{\n            'v': 256,\n            'f': \"256\",\n        },\n\"3%\",\n\"PERCENT\"],\n [{\n            'v': 257,\n            'f': \"257\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 258,\n            'f': \"258\",\n        },\n\"\\u2581capital\",\n\"TYPE\"],\n [{\n            'v': 259,\n            'f': \"259\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 260,\n            'f': \"260\",\n        },\n\"\\u2581des\",\n\"O\"],\n [{\n            'v': 261,\n            'f': \"261\",\n        },\n\"\\u2581droits\",\n\"TYPE\"],\n [{\n            'v': 262,\n            'f': \"262\",\n        },\n\"\\u2581de\",\n\"TYPE\"],\n [{\n            'v': 263,\n            'f': \"263\",\n        },\n\"\\u2581vote\",\n\"TYPE\"],\n [{\n            'v': 264,\n            'f': \"264\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 265,\n            'f': \"265\",\n        },\n\"\\u2581cette\",\n\"O\"],\n [{\n            'v': 266,\n            'f': \"266\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 267,\n            'f': \"267\",\n        },\n\"2,\",\n\"O\"],\n [{\n            'v': 268,\n            'f': \"268\",\n        },\n\"\\u2581r\\u00e9partis\",\n\"O\"],\n [{\n            'v': 269,\n            'f': \"269\",\n        },\n\"\\u2581comme\",\n\"O\"],\n [{\n            'v': 270,\n            'f': \"270\",\n        },\n\"\\u2581suit\",\n\"O\"],\n [{\n            'v': 271,\n            'f': \"271\",\n        },\n\"\\u2581:\",\n\"O\"],\n [{\n            'v': 272,\n            'f': \"272\",\n        },\n\"\\u2581Action\",\n\"O\"],\n [{\n            'v': 273,\n            'f': \"273\",\n        },\n\"s\",\n\"O\"],\n [{\n            'v': 274,\n            'f': \"274\",\n        },\n\"\\u2581%\",\n\"O\"],\n [{\n            'v': 275,\n            'f': \"275\",\n        },\n\"\\u2581capital\",\n\"O\"],\n [{\n            'v': 276,\n            'f': \"276\",\n        },\n\"\\u2581Droits\",\n\"O\"],\n [{\n            'v': 277,\n            'f': \"277\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 278,\n            'f': \"278\",\n        },\n\"\\u2581vote\",\n\"O\"],\n [{\n            'v': 279,\n            'f': \"279\",\n        },\n\"\\u2581%\",\n\"O\"],\n [{\n            'v': 280,\n            'f': \"280\",\n        },\n\"\\u2581droits\",\n\"O\"],\n [{\n            'v': 281,\n            'f': \"281\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 282,\n            'f': \"282\",\n        },\n\"\\u2581vote\",\n\"O\"],\n [{\n            'v': 283,\n            'f': \"283\",\n        },\n\"\\u2581Morgan\",\n\"O\"],\n [{\n            'v': 284,\n            'f': \"284\",\n        },\n\"\\u2581Stanley\",\n\"O\"],\n [{\n            'v': 285,\n            'f': \"285\",\n        },\n\"\\u2581&\",\n\"O\"],\n [{\n            'v': 286,\n            'f': \"286\",\n        },\n\"\\u2581Co\",\n\"O\"],\n [{\n            'v': 287,\n            'f': \"287\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 288,\n            'f': \"288\",\n        },\n\"\\u2581International\",\n\"O\"],\n [{\n            'v': 289,\n            'f': \"289\",\n        },\n\"\\u2581pl\",\n\"O\"],\n [{\n            'v': 290,\n            'f': \"290\",\n        },\n\"c\",\n\"O\"],\n [{\n            'v': 291,\n            'f': \"291\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 292,\n            'f': \"292\",\n        },\n\"\\u258135\",\n\"O\"],\n [{\n            'v': 293,\n            'f': \"293\",\n        },\n\"\\u25817\",\n\"O\"],\n [{\n            'v': 294,\n            'f': \"294\",\n        },\n\"32\",\n\"O\"],\n [{\n            'v': 295,\n            'f': \"295\",\n        },\n\"\\u25819\",\n\"O\"],\n [{\n            'v': 296,\n            'f': \"296\",\n        },\n\"95\",\n\"O\"],\n [{\n            'v': 297,\n            'f': \"297\",\n        },\n\"\\u25815\",\n\"O\"],\n [{\n            'v': 298,\n            'f': \"298\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 299,\n            'f': \"299\",\n        },\n\"03\",\n\"O\"],\n [{\n            'v': 300,\n            'f': \"300\",\n        },\n\"\\u258135\",\n\"O\"],\n [{\n            'v': 301,\n            'f': \"301\",\n        },\n\"\\u25817\",\n\"O\"],\n [{\n            'v': 302,\n            'f': \"302\",\n        },\n\"32\",\n\"O\"],\n [{\n            'v': 303,\n            'f': \"303\",\n        },\n\"\\u25819\",\n\"O\"],\n [{\n            'v': 304,\n            'f': \"304\",\n        },\n\"95\",\n\"O\"],\n [{\n            'v': 305,\n            'f': \"305\",\n        },\n\"\\u25815\",\n\"O\"],\n [{\n            'v': 306,\n            'f': \"306\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 307,\n            'f': \"307\",\n        },\n\"03\",\n\"O\"],\n [{\n            'v': 308,\n            'f': \"308\",\n        },\n\"\\u2581Morgan\",\n\"O\"],\n [{\n            'v': 309,\n            'f': \"309\",\n        },\n\"\\u2581Stanley\",\n\"O\"],\n [{\n            'v': 310,\n            'f': \"310\",\n        },\n\"\\u2581&\",\n\"O\"],\n [{\n            'v': 311,\n            'f': \"311\",\n        },\n\"\\u2581Co\",\n\"O\"],\n [{\n            'v': 312,\n            'f': \"312\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 313,\n            'f': \"313\",\n        },\n\"\\u2581L\",\n\"O\"],\n [{\n            'v': 314,\n            'f': \"314\",\n        },\n\"LC\",\n\"O\"],\n [{\n            'v': 315,\n            'f': \"315\",\n        },\n\"\\u25819\",\n\"O\"],\n [{\n            'v': 316,\n            'f': \"316\",\n        },\n\"\\u258170\",\n\"O\"],\n [{\n            'v': 317,\n            'f': \"317\",\n        },\n\"2\",\n\"O\"],\n [{\n            'v': 318,\n            'f': \"318\",\n        },\n\"\\u2581n\",\n\"O\"],\n [{\n            'v': 319,\n            'f': \"319\",\n        },\n\"s\",\n\"O\"],\n [{\n            'v': 320,\n            'f': \"320\",\n        },\n\"\\u25819\",\n\"O\"],\n [{\n            'v': 321,\n            'f': \"321\",\n        },\n\"\\u258170\",\n\"O\"],\n [{\n            'v': 322,\n            'f': \"322\",\n        },\n\"2\",\n\"O\"],\n [{\n            'v': 323,\n            'f': \"323\",\n        },\n\"\\u2581n\",\n\"O\"],\n [{\n            'v': 324,\n            'f': \"324\",\n        },\n\"s\",\n\"O\"],\n [{\n            'v': 325,\n            'f': \"325\",\n        },\n\"\\u2581Total\",\n\"O\"],\n [{\n            'v': 326,\n            'f': \"326\",\n        },\n\"\\u2581Morgan\",\n\"O\"],\n [{\n            'v': 327,\n            'f': \"327\",\n        },\n\"\\u2581Stanley\",\n\"O\"],\n [{\n            'v': 328,\n            'f': \"328\",\n        },\n\"\\u2581Cor\",\n\"O\"],\n [{\n            'v': 329,\n            'f': \"329\",\n        },\n\"p\",\n\"O\"],\n [{\n            'v': 330,\n            'f': \"330\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 331,\n            'f': \"331\",\n        },\n\"\\u258135\",\n\"O\"],\n [{\n            'v': 332,\n            'f': \"332\",\n        },\n\"\\u25817\",\n\"O\"],\n [{\n            'v': 333,\n            'f': \"333\",\n        },\n\"42\",\n\"O\"],\n [{\n            'v': 334,\n            'f': \"334\",\n        },\n\"\\u25816\",\n\"O\"],\n [{\n            'v': 335,\n            'f': \"335\",\n        },\n\"97\",\n\"O\"],\n [{\n            'v': 336,\n            'f': \"336\",\n        },\n\"\\u25815\",\n\"O\"],\n [{\n            'v': 337,\n            'f': \"337\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 338,\n            'f': \"338\",\n        },\n\"03\",\n\"O\"],\n [{\n            'v': 339,\n            'f': \"339\",\n        },\n\"\\u258135\",\n\"O\"],\n [{\n            'v': 340,\n            'f': \"340\",\n        },\n\"\\u25817\",\n\"O\"],\n [{\n            'v': 341,\n            'f': \"341\",\n        },\n\"42\",\n\"O\"],\n [{\n            'v': 342,\n            'f': \"342\",\n        },\n\"\\u25816\",\n\"O\"],\n [{\n            'v': 343,\n            'f': \"343\",\n        },\n\"97\",\n\"O\"],\n [{\n            'v': 344,\n            'f': \"344\",\n        },\n\"\\u25815\",\n\"O\"],\n [{\n            'v': 345,\n            'f': \"345\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 346,\n            'f': \"346\",\n        },\n\"03\",\n\"O\"],\n [{\n            'v': 347,\n            'f': \"347\",\n        },\n\"\\u2581Au\",\n\"O\"],\n [{\n            'v': 348,\n            'f': \"348\",\n        },\n\"\\u2581titre\",\n\"O\"],\n [{\n            'v': 349,\n            'f': \"349\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 350,\n            'f': \"350\",\n        },\n\"\\u2581l\",\n\"O\"],\n [{\n            'v': 351,\n            'f': \"351\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 352,\n            'f': \"352\",\n        },\n\"article\",\n\"O\"],\n [{\n            'v': 353,\n            'f': \"353\",\n        },\n\"\\u2581L\",\n\"O\"],\n [{\n            'v': 354,\n            'f': \"354\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 355,\n            'f': \"355\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 356,\n            'f': \"356\",\n        },\n\"233\",\n\"O\"],\n [{\n            'v': 357,\n            'f': \"357\",\n        },\n\"-9\",\n\"O\"],\n [{\n            'v': 358,\n            'f': \"358\",\n        },\n\"\\u2581I\",\n\"O\"],\n [{\n            'v': 359,\n            'f': \"359\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 360,\n            'f': \"360\",\n        },\n\"\\u25816\",\n\"O\"],\n [{\n            'v': 361,\n            'f': \"361\",\n        },\n\"\\u00b0\",\n\"O\"],\n [{\n            'v': 362,\n            'f': \"362\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 363,\n            'f': \"363\",\n        },\n\"\\u2581code\",\n\"O\"],\n [{\n            'v': 364,\n            'f': \"364\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 365,\n            'f': \"365\",\n        },\n\"\\u2581commerce\",\n\"O\"],\n [{\n            'v': 366,\n            'f': \"366\",\n        },\n\"\\u2581:\",\n\"O\"],\n [{\n            'v': 367,\n            'f': \"367\",\n        },\n\"\\u2581-\",\n\"O\"],\n [{\n            'v': 368,\n            'f': \"368\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 369,\n            'f': \"369\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 370,\n            'f': \"370\",\n        },\n\"\\u2581Morgan\",\n\"FILIALE\"],\n [{\n            'v': 371,\n            'f': \"371\",\n        },\n\"\\u2581Stanley\",\n\"FILIALE\"],\n [{\n            'v': 372,\n            'f': \"372\",\n        },\n\"\\u2581&\",\n\"FILIALE\"],\n [{\n            'v': 373,\n            'f': \"373\",\n        },\n\"\\u2581Co\",\n\"FILIALE\"],\n [{\n            'v': 374,\n            'f': \"374\",\n        },\n\".\",\n\"FILIALE\"],\n [{\n            'v': 375,\n            'f': \"375\",\n        },\n\"\\u2581L\",\n\"FILIALE\"],\n [{\n            'v': 376,\n            'f': \"376\",\n        },\n\"LC\",\n\"FILIALE\"],\n [{\n            'v': 377,\n            'f': \"377\",\n        },\n\"\\u2581a\",\n\"O\"],\n [{\n            'v': 378,\n            'f': \"378\",\n        },\n\"\\u2581pr\\u00e9cis\\u00e9\",\n\"O\"],\n [{\n            'v': 379,\n            'f': \"379\",\n        },\n\"\\u2581d\\u00e9tenir\",\n\"O\"],\n [{\n            'v': 380,\n            'f': \"380\",\n        },\n\"\\u25819\",\n\"NUMBER\"],\n [{\n            'v': 381,\n            'f': \"381\",\n        },\n\"\\u258170\",\n\"NUMBER\"],\n [{\n            'v': 382,\n            'f': \"382\",\n        },\n\"2\",\n\"NUMBER\"],\n [{\n            'v': 383,\n            'f': \"383\",\n        },\n\"\\u2581actions\",\n\"TYPE\"],\n [{\n            'v': 384,\n            'f': \"384\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 385,\n            'f': \"385\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 386,\n            'f': \"386\",\n        },\n\"\\u2581au\",\n\"O\"],\n [{\n            'v': 387,\n            'f': \"387\",\n        },\n\"\\u2581titre\",\n\"O\"],\n [{\n            'v': 388,\n            'f': \"388\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 389,\n            'f': \"389\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 390,\n            'f': \"390\",\n        },\n\"un\",\n\"O\"],\n [{\n            'v': 391,\n            'f': \"391\",\n        },\n\"\\u2581contrat\",\n\"O\"],\n [{\n            'v': 392,\n            'f': \"392\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 393,\n            'f': \"393\",\n        },\n\"\\u2581\\u00ab\",\n\"O\"],\n [{\n            'v': 394,\n            'f': \"394\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 395,\n            'f': \"395\",\n        },\n\"right\",\n\"O\"],\n [{\n            'v': 396,\n            'f': \"396\",\n        },\n\"\\u2581to\",\n\"O\"],\n [{\n            'v': 397,\n            'f': \"397\",\n        },\n\"\\u2581rec\",\n\"O\"],\n [{\n            'v': 398,\n            'f': \"398\",\n        },\n\"all\",\n\"O\"],\n [{\n            'v': 399,\n            'f': \"399\",\n        },\n\"\\u2581\\u00bb\",\n\"O\"],\n [{\n            'v': 400,\n            'f': \"400\",\n        },\n\"\\u2581portant\",\n\"O\"],\n [{\n            'v': 401,\n            'f': \"401\",\n        },\n\"\\u2581sur\",\n\"O\"],\n [{\n            'v': 402,\n            'f': \"402\",\n        },\n\"\\u2581autant\",\n\"O\"],\n [{\n            'v': 403,\n            'f': \"403\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 404,\n            'f': \"404\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 405,\n            'f': \"405\",\n        },\n\"actions\",\n\"O\"],\n [{\n            'v': 406,\n            'f': \"406\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 407,\n            'f': \"407\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 408,\n            'f': \"408\",\n        },\n\"\\u2581(\",\n\"O\"],\n [{\n            'v': 409,\n            'f': \"409\",\n        },\n\"prise\",\n\"O\"],\n [{\n            'v': 410,\n            'f': \"410\",\n        },\n\"\\u2581en\",\n\"O\"],\n [{\n            'v': 411,\n            'f': \"411\",\n        },\n\"\\u2581compte\",\n\"O\"],\n [{\n            'v': 412,\n            'f': \"412\",\n        },\n\"\\u2581dans\",\n\"O\"],\n [{\n            'v': 413,\n            'f': \"413\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 414,\n            'f': \"414\",\n        },\n\"\\u2581d\\u00e9tention\",\n\"O\"],\n [{\n            'v': 415,\n            'f': \"415\",\n        },\n\"\\u2581vis\\u00e9e\",\n\"O\"],\n [{\n            'v': 416,\n            'f': \"416\",\n        },\n\"\\u2581ci\",\n\"O\"],\n [{\n            'v': 417,\n            'f': \"417\",\n        },\n\"-\",\n\"O\"],\n [{\n            'v': 418,\n            'f': \"418\",\n        },\n\"dessus\",\n\"O\"],\n [{\n            'v': 419,\n            'f': \"419\",\n        },\n\")\",\n\"O\"],\n [{\n            'v': 420,\n            'f': \"420\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 421,\n            'f': \"421\",\n        },\n\"\\u2581lui\",\n\"O\"],\n [{\n            'v': 422,\n            'f': \"422\",\n        },\n\"\\u2581permettant\",\n\"O\"],\n [{\n            'v': 423,\n            'f': \"423\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 424,\n            'f': \"424\",\n        },\n\"\\u2581rappeler\",\n\"O\"],\n [{\n            'v': 425,\n            'f': \"425\",\n        },\n\"\\u2581\\u00e0\",\n\"O\"],\n [{\n            'v': 426,\n            'f': \"426\",\n        },\n\"\\u2581tout\",\n\"O\"],\n [{\n            'v': 427,\n            'f': \"427\",\n        },\n\"\\u2581moment\",\n\"O\"],\n [{\n            'v': 428,\n            'f': \"428\",\n        },\n\"\\u2581les\",\n\"O\"],\n [{\n            'v': 429,\n            'f': \"429\",\n        },\n\"\\u2581actions\",\n\"O\"],\n [{\n            'v': 430,\n            'f': \"430\",\n        },\n\"\\u2581vis\\u00e9es\",\n\"O\"],\n [{\n            'v': 431,\n            'f': \"431\",\n        },\n\"\\u2581par\",\n\"O\"],\n [{\n            'v': 432,\n            'f': \"432\",\n        },\n\"\\u2581le\",\n\"O\"],\n [{\n            'v': 433,\n            'f': \"433\",\n        },\n\"\\u2581contrat\",\n\"O\"],\n [{\n            'v': 434,\n            'f': \"434\",\n        },\n\"\\u2581;\",\n\"O\"],\n [{\n            'v': 435,\n            'f': \"435\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 436,\n            'f': \"436\",\n        },\n\"\\u2581-\",\n\"O\"],\n [{\n            'v': 437,\n            'f': \"437\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 438,\n            'f': \"438\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 439,\n            'f': \"439\",\n        },\n\"\\u2581Morgan\",\n\"FIRM\"],\n [{\n            'v': 440,\n            'f': \"440\",\n        },\n\"\\u2581Stanley\",\n\"FIRM\"],\n [{\n            'v': 441,\n            'f': \"441\",\n        },\n\"\\u2581&\",\n\"FIRM\"],\n [{\n            'v': 442,\n            'f': \"442\",\n        },\n\"\\u2581Co\",\n\"FIRM\"],\n [{\n            'v': 443,\n            'f': \"443\",\n        },\n\".\",\n\"FIRM\"],\n [{\n            'v': 444,\n            'f': \"444\",\n        },\n\"\\u2581International\",\n\"FIRM\"],\n [{\n            'v': 445,\n            'f': \"445\",\n        },\n\"\\u2581pl\",\n\"FIRM\"],\n [{\n            'v': 446,\n            'f': \"446\",\n        },\n\"c\",\n\"FIRM\"],\n [{\n            'v': 447,\n            'f': \"447\",\n        },\n\"\\u2581a\",\n\"O\"],\n [{\n            'v': 448,\n            'f': \"448\",\n        },\n\"\\u2581pr\\u00e9cis\\u00e9\",\n\"O\"],\n [{\n            'v': 449,\n            'f': \"449\",\n        },\n\"\\u2581d\\u00e9tenir\",\n\"O\"],\n [{\n            'v': 450,\n            'f': \"450\",\n        },\n\"\\u258131\",\n\"NUMBER\"],\n [{\n            'v': 451,\n            'f': \"451\",\n        },\n\"\\u25812\",\n\"NUMBER\"],\n [{\n            'v': 452,\n            'f': \"452\",\n        },\n\"23\",\n\"NUMBER\"],\n [{\n            'v': 453,\n            'f': \"453\",\n        },\n\"\\u2581actions\",\n\"TYPE\"],\n [{\n            'v': 454,\n            'f': \"454\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 455,\n            'f': \"455\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 456,\n            'f': \"456\",\n        },\n\"\\u2581au\",\n\"O\"],\n [{\n            'v': 457,\n            'f': \"457\",\n        },\n\"\\u2581titre\",\n\"O\"],\n [{\n            'v': 458,\n            'f': \"458\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 459,\n            'f': \"459\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 460,\n            'f': \"460\",\n        },\n\"un\",\n\"O\"],\n [{\n            'v': 461,\n            'f': \"461\",\n        },\n\"\\u2581contrat\",\n\"O\"],\n [{\n            'v': 462,\n            'f': \"462\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 463,\n            'f': \"463\",\n        },\n\"\\u2581\\u00ab\",\n\"O\"],\n [{\n            'v': 464,\n            'f': \"464\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 465,\n            'f': \"465\",\n        },\n\"right\",\n\"INSTRUMENT\"],\n [{\n            'v': 466,\n            'f': \"466\",\n        },\n\"\\u2581to\",\n\"INSTRUMENT\"],\n [{\n            'v': 467,\n            'f': \"467\",\n        },\n\"\\u2581rec\",\n\"INSTRUMENT\"],\n [{\n            'v': 468,\n            'f': \"468\",\n        },\n\"all\",\n\"INSTRUMENT\"],\n [{\n            'v': 469,\n            'f': \"469\",\n        },\n\"\\u2581\\u00bb\",\n\"O\"],\n [{\n            'v': 470,\n            'f': \"470\",\n        },\n\"\\u2581portant\",\n\"O\"],\n [{\n            'v': 471,\n            'f': \"471\",\n        },\n\"\\u2581sur\",\n\"O\"],\n [{\n            'v': 472,\n            'f': \"472\",\n        },\n\"\\u2581autant\",\n\"O\"],\n [{\n            'v': 473,\n            'f': \"473\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 474,\n            'f': \"474\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 475,\n            'f': \"475\",\n        },\n\"actions\",\n\"O\"],\n [{\n            'v': 476,\n            'f': \"476\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 477,\n            'f': \"477\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 478,\n            'f': \"478\",\n        },\n\"\\u2581(\",\n\"O\"],\n [{\n            'v': 479,\n            'f': \"479\",\n        },\n\"prise\",\n\"O\"],\n [{\n            'v': 480,\n            'f': \"480\",\n        },\n\"\\u2581en\",\n\"O\"],\n [{\n            'v': 481,\n            'f': \"481\",\n        },\n\"\\u2581compte\",\n\"O\"],\n [{\n            'v': 482,\n            'f': \"482\",\n        },\n\"\\u2581dans\",\n\"O\"],\n [{\n            'v': 483,\n            'f': \"483\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 484,\n            'f': \"484\",\n        },\n\"\\u2581d\\u00e9tention\",\n\"O\"],\n [{\n            'v': 485,\n            'f': \"485\",\n        },\n\"\\u2581vis\\u00e9e\",\n\"O\"],\n [{\n            'v': 486,\n            'f': \"486\",\n        },\n\"\\u2581ci\",\n\"O\"],\n [{\n            'v': 487,\n            'f': \"487\",\n        },\n\"-\",\n\"O\"],\n [{\n            'v': 488,\n            'f': \"488\",\n        },\n\"dessus\",\n\"O\"],\n [{\n            'v': 489,\n            'f': \"489\",\n        },\n\")\",\n\"O\"],\n [{\n            'v': 490,\n            'f': \"490\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 491,\n            'f': \"491\",\n        },\n\"\\u2581lui\",\n\"O\"],\n [{\n            'v': 492,\n            'f': \"492\",\n        },\n\"\\u2581permettant\",\n\"O\"],\n [{\n            'v': 493,\n            'f': \"493\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 494,\n            'f': \"494\",\n        },\n\"\\u2581rappeler\",\n\"O\"],\n [{\n            'v': 495,\n            'f': \"495\",\n        },\n\"\\u2581\\u00e0\",\n\"O\"],\n [{\n            'v': 496,\n            'f': \"496\",\n        },\n\"\\u2581tout\",\n\"O\"],\n [{\n            'v': 497,\n            'f': \"497\",\n        },\n\"\\u2581moment\",\n\"O\"],\n [{\n            'v': 498,\n            'f': \"498\",\n        },\n\"\\u2581les\",\n\"O\"],\n [{\n            'v': 499,\n            'f': \"499\",\n        },\n\"\\u2581actions\",\n\"O\"],\n [{\n            'v': 500,\n            'f': \"500\",\n        },\n\"\\u2581vis\\u00e9es\",\n\"O\"],\n [{\n            'v': 501,\n            'f': \"501\",\n        },\n\"\\u2581par\",\n\"O\"],\n [{\n            'v': 502,\n            'f': \"502\",\n        },\n\"\\u2581le\",\n\"O\"],\n [{\n            'v': 503,\n            'f': \"503\",\n        },\n\"\\u2581contrat\",\n\"O\"],\n [{\n            'v': 504,\n            'f': \"504\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 505,\n            'f': \"505\",\n        },\n\"\\u2581Au\",\n\"O\"],\n [{\n            'v': 506,\n            'f': \"506\",\n        },\n\"\\u2581titre\",\n\"O\"],\n [{\n            'v': 507,\n            'f': \"507\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 508,\n            'f': \"508\",\n        },\n\"\\u2581l\",\n\"O\"],\n [{\n            'v': 509,\n            'f': \"509\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 510,\n            'f': \"510\",\n        },\n\"article\",\n\"O\"],\n [{\n            'v': 511,\n            'f': \"511\",\n        },\n\"\\u2581L\",\n\"O\"],\n [{\n            'v': 512,\n            'f': \"512\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 513,\n            'f': \"513\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 514,\n            'f': \"514\",\n        },\n\"233\",\n\"O\"],\n [{\n            'v': 515,\n            'f': \"515\",\n        },\n\"-9\",\n\"O\"],\n [{\n            'v': 516,\n            'f': \"516\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 517,\n            'f': \"517\",\n        },\n\"\\u2581I\",\n\"O\"],\n [{\n            'v': 518,\n            'f': \"518\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 519,\n            'f': \"519\",\n        },\n\"\\u25814\",\n\"O\"],\n [{\n            'v': 520,\n            'f': \"520\",\n        },\n\"\\u00b0\",\n\"O\"],\n [{\n            'v': 521,\n            'f': \"521\",\n        },\n\"\\u2581bis\",\n\"O\"],\n [{\n            'v': 522,\n            'f': \"522\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 523,\n            'f': \"523\",\n        },\n\"\\u2581code\",\n\"O\"],\n [{\n            'v': 524,\n            'f': \"524\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 525,\n            'f': \"525\",\n        },\n\"\\u2581commerce\",\n\"O\"],\n [{\n            'v': 526,\n            'f': \"526\",\n        },\n\"\\u2581et\",\n\"O\"],\n [{\n            'v': 527,\n            'f': \"527\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 528,\n            'f': \"528\",\n        },\n\"\\u2581l\",\n\"O\"],\n [{\n            'v': 529,\n            'f': \"529\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 530,\n            'f': \"530\",\n        },\n\"article\",\n\"O\"],\n [{\n            'v': 531,\n            'f': \"531\",\n        },\n\"\\u25812\",\n\"O\"],\n [{\n            'v': 532,\n            'f': \"532\",\n        },\n\"23\",\n\"O\"],\n [{\n            'v': 533,\n            'f': \"533\",\n        },\n\"-14\",\n\"O\"],\n [{\n            'v': 534,\n            'f': \"534\",\n        },\n\"\\u2581V\",\n\"O\"],\n [{\n            'v': 535,\n            'f': \"535\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 536,\n            'f': \"536\",\n        },\n\"\\u2581r\\u00e8glement\",\n\"O\"],\n [{\n            'v': 537,\n            'f': \"537\",\n        },\n\"\\u2581g\\u00e9n\\u00e9ral\",\n\"O\"],\n [{\n            'v': 538,\n            'f': \"538\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 539,\n            'f': \"539\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 540,\n            'f': \"540\",\n        },\n\"\\u2581soci\\u00e9t\\u00e9\",\n\"O\"],\n [{\n            'v': 541,\n            'f': \"541\",\n        },\n\"\\u2581Morgan\",\n\"FIRM\"],\n [{\n            'v': 542,\n            'f': \"542\",\n        },\n\"\\u2581Stanley\",\n\"FIRM\"],\n [{\n            'v': 543,\n            'f': \"543\",\n        },\n\"\\u2581&\",\n\"FIRM\"],\n [{\n            'v': 544,\n            'f': \"544\",\n        },\n\"\\u2581Co\",\n\"FIRM\"],\n [{\n            'v': 545,\n            'f': \"545\",\n        },\n\".\",\n\"FIRM\"],\n [{\n            'v': 546,\n            'f': \"546\",\n        },\n\"\\u2581International\",\n\"FIRM\"],\n [{\n            'v': 547,\n            'f': \"547\",\n        },\n\"\\u2581pl\",\n\"FIRM\"],\n [{\n            'v': 548,\n            'f': \"548\",\n        },\n\"c\",\n\"FIRM\"],\n [{\n            'v': 549,\n            'f': \"549\",\n        },\n\"\\u2581a\",\n\"O\"],\n [{\n            'v': 550,\n            'f': \"550\",\n        },\n\"\\u2581pr\\u00e9cis\\u00e9\",\n\"O\"],\n [{\n            'v': 551,\n            'f': \"551\",\n        },\n\"\\u2581d\\u00e9tenir\",\n\"O\"],\n [{\n            'v': 552,\n            'f': \"552\",\n        },\n\"\\u2581par\",\n\"O\"],\n [{\n            'v': 553,\n            'f': \"553\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 554,\n            'f': \"554\",\n        },\n\"assimilation\",\n\"O\"],\n [{\n            'v': 555,\n            'f': \"555\",\n        },\n\"\\u258117\",\n\"NUMBER\"],\n [{\n            'v': 556,\n            'f': \"556\",\n        },\n\"1\",\n\"NUMBER\"],\n [{\n            'v': 557,\n            'f': \"557\",\n        },\n\"\\u2581500\",\n\"NUMBER\"],\n [{\n            'v': 558,\n            'f': \"558\",\n        },\n\"\\u2581actions\",\n\"TYPE\"],\n [{\n            'v': 559,\n            'f': \"559\",\n        },\n\"\\u2581C\",\n\"ISSUER\"],\n [{\n            'v': 560,\n            'f': \"560\",\n        },\n\"GG\",\n\"ISSUER\"],\n [{\n            'v': 561,\n            'f': \"561\",\n        },\n\"3\",\n\"O\"],\n [{\n            'v': 562,\n            'f': \"562\",\n        },\n\"\\u2581(\",\n\"O\"],\n [{\n            'v': 563,\n            'f': \"563\",\n        },\n\"com\",\n\"O\"],\n [{\n            'v': 564,\n            'f': \"564\",\n        },\n\"prise\",\n\"O\"],\n [{\n            'v': 565,\n            'f': \"565\",\n        },\n\"s\",\n\"O\"],\n [{\n            'v': 566,\n            'f': \"566\",\n        },\n\"\\u2581dans\",\n\"O\"],\n [{\n            'v': 567,\n            'f': \"567\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 568,\n            'f': \"568\",\n        },\n\"\\u2581d\\u00e9tention\",\n\"O\"],\n [{\n            'v': 569,\n            'f': \"569\",\n        },\n\"\\u2581vis\\u00e9e\",\n\"O\"],\n [{\n            'v': 570,\n            'f': \"570\",\n        },\n\"\\u2581au\",\n\"O\"],\n [{\n            'v': 571,\n            'f': \"571\",\n        },\n\"\\u25811\",\n\"O\"],\n [{\n            'v': 572,\n            'f': \"572\",\n        },\n\"er\",\n\"O\"],\n [{\n            'v': 573,\n            'f': \"573\",\n        },\n\"\\u2581paragraphe\",\n\"O\"],\n [{\n            'v': 574,\n            'f': \"574\",\n        },\n\"),\",\n\"O\"],\n [{\n            'v': 575,\n            'f': \"575\",\n        },\n\"\\u2581r\\u00e9sultant\",\n\"O\"],\n [{\n            'v': 576,\n            'f': \"576\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 577,\n            'f': \"577\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 578,\n            'f': \"578\",\n        },\n\"\\u2581d\\u00e9tention\",\n\"O\"],\n [{\n            'v': 579,\n            'f': \"579\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 580,\n            'f': \"580\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 581,\n            'f': \"581\",\n        },\n\"un\",\n\"O\"],\n [{\n            'v': 582,\n            'f': \"582\",\n        },\n\"\\u2581contrat\",\n\"O\"],\n [{\n            'v': 583,\n            'f': \"583\",\n        },\n\"\\u2581\\u00ab\",\n\"O\"],\n [{\n            'v': 584,\n            'f': \"584\",\n        },\n\"\\u2581e\",\n\"INSTRUMENT\"],\n [{\n            'v': 585,\n            'f': \"585\",\n        },\n\"qui\",\n\"INSTRUMENT\"],\n [{\n            'v': 586,\n            'f': \"586\",\n        },\n\"ty\",\n\"INSTRUMENT\"],\n [{\n            'v': 587,\n            'f': \"587\",\n        },\n\"\\u2581swap\",\n\"INSTRUMENT\"],\n [{\n            'v': 588,\n            'f': \"588\",\n        },\n\"\\u2581\\u00bb\",\n\"O\"],\n [{\n            'v': 589,\n            'f': \"589\",\n        },\n\"\\u2581\\u00e0\",\n\"O\"],\n [{\n            'v': 590,\n            'f': \"590\",\n        },\n\"\\u2581d\\u00e9nouement\",\n\"O\"],\n [{\n            'v': 591,\n            'f': \"591\",\n        },\n\"\\u2581en\",\n\"O\"],\n [{\n            'v': 592,\n            'f': \"592\",\n        },\n\"\\u2581esp\\u00e8ces\",\n\"O\"],\n [{\n            'v': 593,\n            'f': \"593\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 594,\n            'f': \"594\",\n        },\n\"\\u2581exer\\u00e7\",\n\"O\"],\n [{\n            'v': 595,\n            'f': \"595\",\n        },\n\"ables\",\n\"O\"],\n [{\n            'v': 596,\n            'f': \"596\",\n        },\n\"\\u2581\\u00e0\",\n\"O\"],\n [{\n            'v': 597,\n            'f': \"597\",\n        },\n\"\\u2581tout\",\n\"O\"],\n [{\n            'v': 598,\n            'f': \"598\",\n        },\n\"\\u2581moment\",\n\"O\"],\n [{\n            'v': 599,\n            'f': \"599\",\n        },\n\"\\u2581jusqu\",\n\"O\"],\n [{\n            'v': 600,\n            'f': \"600\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 601,\n            'f': \"601\",\n        },\n\"au\",\n\"O\"],\n [{\n            'v': 602,\n            'f': \"602\",\n        },\n\"\\u258116\",\n\"DATE\"],\n [{\n            'v': 603,\n            'f': \"603\",\n        },\n\"\\u2581mars\",\n\"DATE\"],\n [{\n            'v': 604,\n            'f': \"604\",\n        },\n\"\\u25812020\",\n\"DATE\"],\n [{\n            'v': 605,\n            'f': \"605\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 606,\n            'f': \"606\",\n        },\n\"\\u2581\",\n\"O\"],\n [{\n            'v': 607,\n            'f': \"607\",\n        },\n\"___\",\n\"O\"],\n [{\n            'v': 608,\n            'f': \"608\",\n        },\n\"____\",\n\"O\"],\n [{\n            'v': 609,\n            'f': \"609\",\n        },\n\"\\u25811\",\n\"O\"],\n [{\n            'v': 610,\n            'f': \"610\",\n        },\n\"\\u2581Contr\",\n\"O\"],\n [{\n            'v': 611,\n            'f': \"611\",\n        },\n\"\\u00f4\",\n\"O\"],\n [{\n            'v': 612,\n            'f': \"612\",\n        },\n\"l\\u00e9e\",\n\"O\"],\n [{\n            'v': 613,\n            'f': \"613\",\n        },\n\"\\u2581par\",\n\"O\"],\n [{\n            'v': 614,\n            'f': \"614\",\n        },\n\"\\u2581Morgan\",\n\"FIRM\"],\n [{\n            'v': 615,\n            'f': \"615\",\n        },\n\"\\u2581Stanley\",\n\"FIRM\"],\n [{\n            'v': 616,\n            'f': \"616\",\n        },\n\"\\u2581Cor\",\n\"FIRM\"],\n [{\n            'v': 617,\n            'f': \"617\",\n        },\n\"p\",\n\"FIRM\"],\n [{\n            'v': 618,\n            'f': \"618\",\n        },\n\".\",\n\"FIRM\"],\n [{\n            'v': 619,\n            'f': \"619\",\n        },\n\"\\u25812\",\n\"O\"],\n [{\n            'v': 620,\n            'f': \"620\",\n        },\n\"\\u2581Sur\",\n\"O\"],\n [{\n            'v': 621,\n            'f': \"621\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 622,\n            'f': \"622\",\n        },\n\"\\u2581base\",\n\"O\"],\n [{\n            'v': 623,\n            'f': \"623\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 624,\n            'f': \"624\",\n        },\n\"'\",\n\"O\"],\n [{\n            'v': 625,\n            'f': \"625\",\n        },\n\"un\",\n\"O\"],\n [{\n            'v': 626,\n            'f': \"626\",\n        },\n\"\\u2581capital\",\n\"O\"],\n [{\n            'v': 627,\n            'f': \"627\",\n        },\n\"\\u2581compos\\u00e9\",\n\"O\"],\n [{\n            'v': 628,\n            'f': \"628\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 629,\n            'f': \"629\",\n        },\n\"\\u25817\",\n\"NUMBER\"],\n [{\n            'v': 630,\n            'f': \"630\",\n        },\n\"09\",\n\"NUMBER\"],\n [{\n            'v': 631,\n            'f': \"631\",\n        },\n\"\\u25819\",\n\"NUMBER\"],\n [{\n            'v': 632,\n            'f': \"632\",\n        },\n\"60\",\n\"NUMBER\"],\n [{\n            'v': 633,\n            'f': \"633\",\n        },\n\"\\u258101\",\n\"NUMBER\"],\n [{\n            'v': 634,\n            'f': \"634\",\n        },\n\"2\",\n\"NUMBER\"],\n [{\n            'v': 635,\n            'f': \"635\",\n        },\n\"\\u2581actions\",\n\"TYPE\"],\n [{\n            'v': 636,\n            'f': \"636\",\n        },\n\"\\u2581repr\\u00e9sentant\",\n\"O\"],\n [{\n            'v': 637,\n            'f': \"637\",\n        },\n\"\\u25817\",\n\"NUMBER\"],\n [{\n            'v': 638,\n            'f': \"638\",\n        },\n\"10\",\n\"NUMBER\"],\n [{\n            'v': 639,\n            'f': \"639\",\n        },\n\"\\u258109\",\n\"NUMBER\"],\n [{\n            'v': 640,\n            'f': \"640\",\n        },\n\"8\",\n\"NUMBER\"],\n [{\n            'v': 641,\n            'f': \"641\",\n        },\n\"\\u25815\",\n\"NUMBER\"],\n [{\n            'v': 642,\n            'f': \"642\",\n        },\n\"78\",\n\"NUMBER\"],\n [{\n            'v': 643,\n            'f': \"643\",\n        },\n\"\\u2581droits\",\n\"TYPE\"],\n [{\n            'v': 644,\n            'f': \"644\",\n        },\n\"\\u2581de\",\n\"TYPE\"],\n [{\n            'v': 645,\n            'f': \"645\",\n        },\n\"\\u2581vote\",\n\"TYPE\"],\n [{\n            'v': 646,\n            'f': \"646\",\n        },\n\",\",\n\"O\"],\n [{\n            'v': 647,\n            'f': \"647\",\n        },\n\"\\u2581en\",\n\"O\"],\n [{\n            'v': 648,\n            'f': \"648\",\n        },\n\"\\u2581application\",\n\"O\"],\n [{\n            'v': 649,\n            'f': \"649\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 650,\n            'f': \"650\",\n        },\n\"\\u25812\",\n\"O\"],\n [{\n            'v': 651,\n            'f': \"651\",\n        },\n\"\\u00e8me\",\n\"O\"],\n [{\n            'v': 652,\n            'f': \"652\",\n        },\n\"\\u2581alin\\u00e9a\",\n\"O\"],\n [{\n            'v': 653,\n            'f': \"653\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 654,\n            'f': \"654\",\n        },\n\"\\u2581l\",\n\"O\"],\n [{\n            'v': 655,\n            'f': \"655\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 656,\n            'f': \"656\",\n        },\n\"article\",\n\"O\"],\n [{\n            'v': 657,\n            'f': \"657\",\n        },\n\"\\u25812\",\n\"O\"],\n [{\n            'v': 658,\n            'f': \"658\",\n        },\n\"23\",\n\"O\"],\n [{\n            'v': 659,\n            'f': \"659\",\n        },\n\"-11\",\n\"O\"],\n [{\n            'v': 660,\n            'f': \"660\",\n        },\n\"\\u2581I\",\n\"O\"],\n [{\n            'v': 661,\n            'f': \"661\",\n        },\n\"\\u2581du\",\n\"O\"],\n [{\n            'v': 662,\n            'f': \"662\",\n        },\n\"\\u2581r\\u00e8glement\",\n\"O\"],\n [{\n            'v': 663,\n            'f': \"663\",\n        },\n\"\\u2581g\\u00e9n\\u00e9ral\",\n\"O\"],\n [{\n            'v': 664,\n            'f': \"664\",\n        },\n\".\",\n\"O\"],\n [{\n            'v': 665,\n            'f': \"665\",\n        },\n\"\\u25813\",\n\"O\"],\n [{\n            'v': 666,\n            'f': \"666\",\n        },\n\"\\u2581Sur\",\n\"O\"],\n [{\n            'v': 667,\n            'f': \"667\",\n        },\n\"\\u2581la\",\n\"O\"],\n [{\n            'v': 668,\n            'f': \"668\",\n        },\n\"\\u2581base\",\n\"O\"],\n [{\n            'v': 669,\n            'f': \"669\",\n        },\n\"\\u2581d\",\n\"O\"],\n [{\n            'v': 670,\n            'f': \"670\",\n        },\n\"\\u2019\",\n\"O\"],\n [{\n            'v': 671,\n            'f': \"671\",\n        },\n\"un\",\n\"O\"],\n [{\n            'v': 672,\n            'f': \"672\",\n        },\n\"\\u2581delta\",\n\"O\"],\n [{\n            'v': 673,\n            'f': \"673\",\n        },\n\"\\u2581de\",\n\"O\"],\n [{\n            'v': 674,\n            'f': \"674\",\n        },\n\"\\u25811.\",\n\"O\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"X\"], [\"string\", \"Y\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>▁220</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>’</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>un</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>▁delta</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673</th>\n",
              "      <td>▁de</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>▁1.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>675 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          X  Y\n",
              "0      ▁220  O\n",
              "1         C  O\n",
              "2        07  O\n",
              "3        13  O\n",
              "4         -  O\n",
              "..      ... ..\n",
              "670       ’  O\n",
              "671      un  O\n",
              "672  ▁delta  O\n",
              "673     ▁de  O\n",
              "674     ▁1.  O\n",
              "\n",
              "[675 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4G2KM7O-KgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "beed069e67d94e97992c55a952131d06",
            "10645098459b426a9e4c2a3d54896121",
            "9035f108395c405ca0e84571ec9fc9aa",
            "0461130cca1e45c98535d547bdac394c",
            "792d2132b2524181951ec27ad0d40271",
            "397033f9c84d481b9afa61de5f522036",
            "ee85d4ec9d7c4a6ca5c20e56d15453d3",
            "a1ee12f4abe64849ae3f1d6038a7284c",
            "d2164c3967314b8f8cd7ab5da4277896",
            "1d98f409801d4bc8bbf2fa350e39b24d",
            "c735862484944b25bbd1f8ee6290e1c4",
            "44df3a67cc224c22bb3f80b183c98ec5",
            "17a0df3496c7481593344ec64c96b65d",
            "c3dfbf01c4ac427db61d28c8a191dca9",
            "37b6869bb4d54ab28328b8fe62dc0152",
            "3a21027aa6a44d3c9e2da18a54dac427"
          ]
        },
        "outputId": "4b979af3-9906-4368-eb43-3d2827118346"
      },
      "source": [
        "from transformers import TFCamembertForTokenClassification\n",
        "model = TFCamembertForTokenClassification.from_pretrained(\"jplu/tf-camembert-base\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beed069e67d94e97992c55a952131d06",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=637, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2164c3967314b8f8cd7ab5da4277896",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=545172724, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyp7Mba4vV-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8c03dfd1-dd41-424b-f8f6-8b1364178aea"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_camembert_for_token_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "roberta (TFRobertaMainLayer) multiple                  110621952 \n",
            "_________________________________________________________________\n",
            "dropout_116 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 110,623,490\n",
            "Trainable params: 110,623,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNa2cdNajppv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e4f71dfa-f87d-48cb-f167-82e8fbaca6b5"
      },
      "source": [
        "import tensorflow as tf\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X, Y)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-5feab09c1af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m                **kwargs):\n\u001b[1;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjwbbjT7GrxE",
        "colab_type": "code",
        "outputId": "a7ed6286-c03b-4b96-d434-e5398757b8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import CamembertModel, CamembertTokenizer\n",
        "\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "camembert = CamembertModel.from_pretrained(\"camembert-base\")\n",
        "\n",
        "camembert.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfSKDSYd-ARc",
        "colab_type": "code",
        "outputId": "f26e9919-43e1-45b4-9c22-d88af36050dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import transformers\n",
        "dir(transformers)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'ALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'ALL_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'AdamW',\n",
              " 'AdamWeightDecay',\n",
              " 'AdaptiveEmbedding',\n",
              " 'AlbertConfig',\n",
              " 'AlbertForMaskedLM',\n",
              " 'AlbertForQuestionAnswering',\n",
              " 'AlbertForSequenceClassification',\n",
              " 'AlbertForTokenClassification',\n",
              " 'AlbertModel',\n",
              " 'AlbertPreTrainedModel',\n",
              " 'AlbertTokenizer',\n",
              " 'AutoConfig',\n",
              " 'AutoModel',\n",
              " 'AutoModelForPreTraining',\n",
              " 'AutoModelForQuestionAnswering',\n",
              " 'AutoModelForSequenceClassification',\n",
              " 'AutoModelForTokenClassification',\n",
              " 'AutoModelWithLMHead',\n",
              " 'AutoTokenizer',\n",
              " 'BART_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'BERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'BERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'BartConfig',\n",
              " 'BartForConditionalGeneration',\n",
              " 'BartForSequenceClassification',\n",
              " 'BartModel',\n",
              " 'BartTokenizer',\n",
              " 'BasicTokenizer',\n",
              " 'BertConfig',\n",
              " 'BertForMaskedLM',\n",
              " 'BertForMultipleChoice',\n",
              " 'BertForNextSentencePrediction',\n",
              " 'BertForPreTraining',\n",
              " 'BertForQuestionAnswering',\n",
              " 'BertForSequenceClassification',\n",
              " 'BertForTokenClassification',\n",
              " 'BertJapaneseTokenizer',\n",
              " 'BertModel',\n",
              " 'BertPreTrainedModel',\n",
              " 'BertTokenizer',\n",
              " 'BertTokenizerFast',\n",
              " 'CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'CONFIG_MAPPING',\n",
              " 'CONFIG_NAME',\n",
              " 'CTRLConfig',\n",
              " 'CTRLLMHeadModel',\n",
              " 'CTRLModel',\n",
              " 'CTRLPreTrainedModel',\n",
              " 'CTRLTokenizer',\n",
              " 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'CTRL_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'CamembertConfig',\n",
              " 'CamembertForMaskedLM',\n",
              " 'CamembertForMultipleChoice',\n",
              " 'CamembertForQuestionAnswering',\n",
              " 'CamembertForSequenceClassification',\n",
              " 'CamembertForTokenClassification',\n",
              " 'CamembertModel',\n",
              " 'CamembertTokenizer',\n",
              " 'CharacterTokenizer',\n",
              " 'Conv1D',\n",
              " 'CsvPipelineDataFormat',\n",
              " 'DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'DISTILBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'DataProcessor',\n",
              " 'DistilBertConfig',\n",
              " 'DistilBertForMaskedLM',\n",
              " 'DistilBertForQuestionAnswering',\n",
              " 'DistilBertForSequenceClassification',\n",
              " 'DistilBertForTokenClassification',\n",
              " 'DistilBertModel',\n",
              " 'DistilBertPreTrainedModel',\n",
              " 'DistilBertTokenizer',\n",
              " 'DistilBertTokenizerFast',\n",
              " 'ELECTRA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'ELECTRA_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'ElectraConfig',\n",
              " 'ElectraForMaskedLM',\n",
              " 'ElectraForPreTraining',\n",
              " 'ElectraForTokenClassification',\n",
              " 'ElectraModel',\n",
              " 'ElectraTokenizer',\n",
              " 'ElectraTokenizerFast',\n",
              " 'FLAUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'FLAUBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'FeatureExtractionPipeline',\n",
              " 'FillMaskPipeline',\n",
              " 'FlaubertConfig',\n",
              " 'FlaubertForQuestionAnswering',\n",
              " 'FlaubertForQuestionAnsweringSimple',\n",
              " 'FlaubertForSequenceClassification',\n",
              " 'FlaubertModel',\n",
              " 'FlaubertTokenizer',\n",
              " 'FlaubertWithLMHeadModel',\n",
              " 'Frame',\n",
              " 'GPT2Config',\n",
              " 'GPT2DoubleHeadsModel',\n",
              " 'GPT2LMHeadModel',\n",
              " 'GPT2Model',\n",
              " 'GPT2PreTrainedModel',\n",
              " 'GPT2Tokenizer',\n",
              " 'GPT2TokenizerFast',\n",
              " 'GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'GPT2_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'GradientAccumulator',\n",
              " 'InputExample',\n",
              " 'InputFeatures',\n",
              " 'JsonPipelineDataFormat',\n",
              " 'MMBTConfig',\n",
              " 'MMBTForClassification',\n",
              " 'MMBTModel',\n",
              " 'MODEL_CARD_NAME',\n",
              " 'MODEL_FOR_PRETRAINING_MAPPING',\n",
              " 'MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n",
              " 'MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n",
              " 'MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n",
              " 'MODEL_MAPPING',\n",
              " 'MODEL_WITH_LM_HEAD_MAPPING',\n",
              " 'MecabTokenizer',\n",
              " 'Memory',\n",
              " 'MemoryState',\n",
              " 'MemorySummary',\n",
              " 'MemoryTrace',\n",
              " 'ModalEmbeddings',\n",
              " 'ModelCard',\n",
              " 'NerPipeline',\n",
              " 'OPENAI_GPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'OpenAIGPTConfig',\n",
              " 'OpenAIGPTDoubleHeadsModel',\n",
              " 'OpenAIGPTLMHeadModel',\n",
              " 'OpenAIGPTModel',\n",
              " 'OpenAIGPTPreTrainedModel',\n",
              " 'OpenAIGPTTokenizer',\n",
              " 'OpenAIGPTTokenizerFast',\n",
              " 'PYTORCH_PRETRAINED_BERT_CACHE',\n",
              " 'PYTORCH_TRANSFORMERS_CACHE',\n",
              " 'PipedPipelineDataFormat',\n",
              " 'Pipeline',\n",
              " 'PipelineDataFormat',\n",
              " 'PreTrainedEncoderDecoder',\n",
              " 'PreTrainedModel',\n",
              " 'PreTrainedTokenizer',\n",
              " 'PretrainedConfig',\n",
              " 'QuestionAnsweringPipeline',\n",
              " 'ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'RobertaConfig',\n",
              " 'RobertaForMaskedLM',\n",
              " 'RobertaForMultipleChoice',\n",
              " 'RobertaForQuestionAnswering',\n",
              " 'RobertaForSequenceClassification',\n",
              " 'RobertaForTokenClassification',\n",
              " 'RobertaModel',\n",
              " 'RobertaTokenizer',\n",
              " 'RobertaTokenizerFast',\n",
              " 'SPIECE_UNDERLINE',\n",
              " 'SingleSentenceClassificationProcessor',\n",
              " 'SquadExample',\n",
              " 'SquadFeatures',\n",
              " 'SquadV1Processor',\n",
              " 'SquadV2Processor',\n",
              " 'SummarizationPipeline',\n",
              " 'T5Config',\n",
              " 'T5ForConditionalGeneration',\n",
              " 'T5Model',\n",
              " 'T5PreTrainedModel',\n",
              " 'T5Tokenizer',\n",
              " 'T5_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'T5_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF2_WEIGHTS_NAME',\n",
              " 'TFAdaptiveEmbedding',\n",
              " 'TFAlbertForMaskedLM',\n",
              " 'TFAlbertForSequenceClassification',\n",
              " 'TFAlbertMainLayer',\n",
              " 'TFAlbertModel',\n",
              " 'TFAlbertPreTrainedModel',\n",
              " 'TFAutoModel',\n",
              " 'TFAutoModelForPreTraining',\n",
              " 'TFAutoModelForQuestionAnswering',\n",
              " 'TFAutoModelForSequenceClassification',\n",
              " 'TFAutoModelForTokenClassification',\n",
              " 'TFAutoModelWithLMHead',\n",
              " 'TFBertEmbeddings',\n",
              " 'TFBertForMaskedLM',\n",
              " 'TFBertForMultipleChoice',\n",
              " 'TFBertForNextSentencePrediction',\n",
              " 'TFBertForPreTraining',\n",
              " 'TFBertForQuestionAnswering',\n",
              " 'TFBertForSequenceClassification',\n",
              " 'TFBertForTokenClassification',\n",
              " 'TFBertMainLayer',\n",
              " 'TFBertModel',\n",
              " 'TFBertPreTrainedModel',\n",
              " 'TFCTRLLMHeadModel',\n",
              " 'TFCTRLModel',\n",
              " 'TFCTRLPreTrainedModel',\n",
              " 'TFCamembertForMaskedLM',\n",
              " 'TFCamembertForSequenceClassification',\n",
              " 'TFCamembertForTokenClassification',\n",
              " 'TFCamembertModel',\n",
              " 'TFDistilBertForMaskedLM',\n",
              " 'TFDistilBertForQuestionAnswering',\n",
              " 'TFDistilBertForSequenceClassification',\n",
              " 'TFDistilBertForTokenClassification',\n",
              " 'TFDistilBertMainLayer',\n",
              " 'TFDistilBertModel',\n",
              " 'TFDistilBertPreTrainedModel',\n",
              " 'TFElectraForMaskedLM',\n",
              " 'TFElectraForPreTraining',\n",
              " 'TFElectraForTokenClassification',\n",
              " 'TFElectraModel',\n",
              " 'TFElectraPreTrainedModel',\n",
              " 'TFFlaubertForSequenceClassification',\n",
              " 'TFFlaubertModel',\n",
              " 'TFFlaubertWithLMHeadModel',\n",
              " 'TFGPT2DoubleHeadsModel',\n",
              " 'TFGPT2LMHeadModel',\n",
              " 'TFGPT2MainLayer',\n",
              " 'TFGPT2Model',\n",
              " 'TFGPT2PreTrainedModel',\n",
              " 'TFOpenAIGPTDoubleHeadsModel',\n",
              " 'TFOpenAIGPTLMHeadModel',\n",
              " 'TFOpenAIGPTMainLayer',\n",
              " 'TFOpenAIGPTModel',\n",
              " 'TFOpenAIGPTPreTrainedModel',\n",
              " 'TFPreTrainedModel',\n",
              " 'TFRobertaForMaskedLM',\n",
              " 'TFRobertaForSequenceClassification',\n",
              " 'TFRobertaForTokenClassification',\n",
              " 'TFRobertaMainLayer',\n",
              " 'TFRobertaModel',\n",
              " 'TFRobertaPreTrainedModel',\n",
              " 'TFSequenceSummary',\n",
              " 'TFSharedEmbeddings',\n",
              " 'TFT5ForConditionalGeneration',\n",
              " 'TFT5Model',\n",
              " 'TFT5PreTrainedModel',\n",
              " 'TFTransfoXLLMHeadModel',\n",
              " 'TFTransfoXLMainLayer',\n",
              " 'TFTransfoXLModel',\n",
              " 'TFTransfoXLPreTrainedModel',\n",
              " 'TFXLMForQuestionAnsweringSimple',\n",
              " 'TFXLMForSequenceClassification',\n",
              " 'TFXLMMainLayer',\n",
              " 'TFXLMModel',\n",
              " 'TFXLMPreTrainedModel',\n",
              " 'TFXLMRobertaForMaskedLM',\n",
              " 'TFXLMRobertaForSequenceClassification',\n",
              " 'TFXLMRobertaForTokenClassification',\n",
              " 'TFXLMRobertaModel',\n",
              " 'TFXLMWithLMHeadModel',\n",
              " 'TFXLNetForQuestionAnsweringSimple',\n",
              " 'TFXLNetForSequenceClassification',\n",
              " 'TFXLNetForTokenClassification',\n",
              " 'TFXLNetLMHeadModel',\n",
              " 'TFXLNetMainLayer',\n",
              " 'TFXLNetModel',\n",
              " 'TFXLNetPreTrainedModel',\n",
              " 'TF_ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_ALL_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_CTRL_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_DISTILBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_ELECTRA_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_FLAUBERT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_GPT2_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_MODEL_FOR_PRETRAINING_MAPPING',\n",
              " 'TF_MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n",
              " 'TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n",
              " 'TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n",
              " 'TF_MODEL_MAPPING',\n",
              " 'TF_MODEL_WITH_LM_HEAD_MAPPING',\n",
              " 'TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_T5_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_WEIGHTS_NAME',\n",
              " 'TF_XLM_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TF_XLNET_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TOKENIZER_MAPPING',\n",
              " 'TRANSFORMERS_CACHE',\n",
              " 'TRANSFO_XL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'TextClassificationPipeline',\n",
              " 'TokenClassificationPipeline',\n",
              " 'TransfoXLConfig',\n",
              " 'TransfoXLCorpus',\n",
              " 'TransfoXLLMHeadModel',\n",
              " 'TransfoXLModel',\n",
              " 'TransfoXLPreTrainedModel',\n",
              " 'TransfoXLTokenizer',\n",
              " 'TransfoXLTokenizerFast',\n",
              " 'TranslationPipeline',\n",
              " 'UsedMemoryState',\n",
              " 'WEIGHTS_NAME',\n",
              " 'WarmUp',\n",
              " 'WordpieceTokenizer',\n",
              " 'XLMConfig',\n",
              " 'XLMForQuestionAnswering',\n",
              " 'XLMForQuestionAnsweringSimple',\n",
              " 'XLMForSequenceClassification',\n",
              " 'XLMForTokenClassification',\n",
              " 'XLMModel',\n",
              " 'XLMPreTrainedModel',\n",
              " 'XLMRobertaConfig',\n",
              " 'XLMRobertaForMaskedLM',\n",
              " 'XLMRobertaForMultipleChoice',\n",
              " 'XLMRobertaForSequenceClassification',\n",
              " 'XLMRobertaForTokenClassification',\n",
              " 'XLMRobertaModel',\n",
              " 'XLMRobertaTokenizer',\n",
              " 'XLMTokenizer',\n",
              " 'XLMWithLMHeadModel',\n",
              " 'XLM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'XLM_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'XLM_ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'XLNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
              " 'XLNET_PRETRAINED_MODEL_ARCHIVE_MAP',\n",
              " 'XLNetConfig',\n",
              " 'XLNetForMultipleChoice',\n",
              " 'XLNetForQuestionAnswering',\n",
              " 'XLNetForQuestionAnsweringSimple',\n",
              " 'XLNetForSequenceClassification',\n",
              " 'XLNetForTokenClassification',\n",
              " 'XLNetLMHeadModel',\n",
              " 'XLNetModel',\n",
              " 'XLNetPreTrainedModel',\n",
              " 'XLNetTokenizer',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " 'absl',\n",
              " 'activations',\n",
              " 'add_end_docstrings',\n",
              " 'add_start_docstrings',\n",
              " 'benchmark_utils',\n",
              " 'bytes_to_human_readable',\n",
              " 'cached_path',\n",
              " 'configuration_albert',\n",
              " 'configuration_auto',\n",
              " 'configuration_bart',\n",
              " 'configuration_bert',\n",
              " 'configuration_camembert',\n",
              " 'configuration_ctrl',\n",
              " 'configuration_distilbert',\n",
              " 'configuration_electra',\n",
              " 'configuration_flaubert',\n",
              " 'configuration_gpt2',\n",
              " 'configuration_mmbt',\n",
              " 'configuration_openai',\n",
              " 'configuration_roberta',\n",
              " 'configuration_t5',\n",
              " 'configuration_transfo_xl',\n",
              " 'configuration_utils',\n",
              " 'configuration_xlm',\n",
              " 'configuration_xlm_roberta',\n",
              " 'configuration_xlnet',\n",
              " 'convert_tf_weight_name_to_pt_weight_name',\n",
              " 'create_optimizer',\n",
              " 'data',\n",
              " 'file_utils',\n",
              " 'get_constant_schedule',\n",
              " 'get_constant_schedule_with_warmup',\n",
              " 'get_cosine_schedule_with_warmup',\n",
              " 'get_cosine_with_hard_restarts_schedule_with_warmup',\n",
              " 'get_linear_schedule_with_warmup',\n",
              " 'glue_compute_metrics',\n",
              " 'glue_convert_examples_to_features',\n",
              " 'glue_output_modes',\n",
              " 'glue_processors',\n",
              " 'glue_tasks_num_labels',\n",
              " 'is_sklearn_available',\n",
              " 'is_tf_available',\n",
              " 'is_torch_available',\n",
              " 'load_pytorch_checkpoint_in_tf2_model',\n",
              " 'load_pytorch_model_in_tf2_model',\n",
              " 'load_pytorch_weights_in_tf2_model',\n",
              " 'load_tf2_checkpoint_in_pytorch_model',\n",
              " 'load_tf2_model_in_pytorch_model',\n",
              " 'load_tf2_weights_in_pytorch_model',\n",
              " 'load_tf_weights_in_albert',\n",
              " 'load_tf_weights_in_bert',\n",
              " 'load_tf_weights_in_electra',\n",
              " 'load_tf_weights_in_gpt2',\n",
              " 'load_tf_weights_in_openai_gpt',\n",
              " 'load_tf_weights_in_t5',\n",
              " 'load_tf_weights_in_transfo_xl',\n",
              " 'load_tf_weights_in_xlnet',\n",
              " 'logger',\n",
              " 'logging',\n",
              " 'modelcard',\n",
              " 'modeling_albert',\n",
              " 'modeling_auto',\n",
              " 'modeling_bart',\n",
              " 'modeling_bert',\n",
              " 'modeling_camembert',\n",
              " 'modeling_ctrl',\n",
              " 'modeling_distilbert',\n",
              " 'modeling_electra',\n",
              " 'modeling_encoder_decoder',\n",
              " 'modeling_flaubert',\n",
              " 'modeling_gpt2',\n",
              " 'modeling_mmbt',\n",
              " 'modeling_openai',\n",
              " 'modeling_roberta',\n",
              " 'modeling_t5',\n",
              " 'modeling_tf_albert',\n",
              " 'modeling_tf_auto',\n",
              " 'modeling_tf_bert',\n",
              " 'modeling_tf_camembert',\n",
              " 'modeling_tf_ctrl',\n",
              " 'modeling_tf_distilbert',\n",
              " 'modeling_tf_electra',\n",
              " 'modeling_tf_flaubert',\n",
              " 'modeling_tf_gpt2',\n",
              " 'modeling_tf_openai',\n",
              " 'modeling_tf_pytorch_utils',\n",
              " 'modeling_tf_roberta',\n",
              " 'modeling_tf_t5',\n",
              " 'modeling_tf_transfo_xl',\n",
              " 'modeling_tf_transfo_xl_utilities',\n",
              " 'modeling_tf_utils',\n",
              " 'modeling_tf_xlm',\n",
              " 'modeling_tf_xlm_roberta',\n",
              " 'modeling_tf_xlnet',\n",
              " 'modeling_transfo_xl',\n",
              " 'modeling_transfo_xl_utilities',\n",
              " 'modeling_utils',\n",
              " 'modeling_xlm',\n",
              " 'modeling_xlm_roberta',\n",
              " 'modeling_xlnet',\n",
              " 'optimization',\n",
              " 'optimization_tf',\n",
              " 'pipeline',\n",
              " 'pipelines',\n",
              " 'prune_layer',\n",
              " 'shape_list',\n",
              " 'squad_convert_examples_to_features',\n",
              " 'start_memory_tracing',\n",
              " 'stop_memory_tracing',\n",
              " 'tf_top_k_top_p_filtering',\n",
              " 'tokenization_albert',\n",
              " 'tokenization_auto',\n",
              " 'tokenization_bart',\n",
              " 'tokenization_bert',\n",
              " 'tokenization_bert_japanese',\n",
              " 'tokenization_camembert',\n",
              " 'tokenization_ctrl',\n",
              " 'tokenization_distilbert',\n",
              " 'tokenization_electra',\n",
              " 'tokenization_flaubert',\n",
              " 'tokenization_gpt2',\n",
              " 'tokenization_openai',\n",
              " 'tokenization_roberta',\n",
              " 'tokenization_t5',\n",
              " 'tokenization_transfo_xl',\n",
              " 'tokenization_utils',\n",
              " 'tokenization_xlm',\n",
              " 'tokenization_xlm_roberta',\n",
              " 'tokenization_xlnet',\n",
              " 'top_k_top_p_filtering',\n",
              " 'xnli_compute_metrics',\n",
              " 'xnli_output_modes',\n",
              " 'xnli_processors',\n",
              " 'xnli_tasks_num_labels']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCU-tZ1q9v1b",
        "colab_type": "code",
        "outputId": "5503d7f6-eb19-42b5-c992-07e3c09f05a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "a = model.train()\n",
        "help(a.to)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method to in module torch.nn.modules.module:\n",
            "\n",
            "to(*args, **kwargs) method of transformers.modeling_bert.BertForTokenClassification instance\n",
            "    Moves and/or casts the parameters and buffers.\n",
            "    \n",
            "    This can be called as\n",
            "    \n",
            "    .. function:: to(device=None, dtype=None, non_blocking=False)\n",
            "    \n",
            "    .. function:: to(dtype, non_blocking=False)\n",
            "    \n",
            "    .. function:: to(tensor, non_blocking=False)\n",
            "    \n",
            "    Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
            "    floating point desired :attr:`dtype` s. In addition, this method will\n",
            "    only cast the floating point parameters and buffers to :attr:`dtype`\n",
            "    (if given). The integral parameters and buffers will be moved\n",
            "    :attr:`device`, if that is given, but with dtypes unchanged. When\n",
            "    :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
            "    with respect to the host if possible, e.g., moving CPU Tensors with\n",
            "    pinned memory to CUDA devices.\n",
            "    \n",
            "    See below for examples.\n",
            "    \n",
            "    .. note::\n",
            "        This method modifies the module in-place.\n",
            "    \n",
            "    Args:\n",
            "        device (:class:`torch.device`): the desired device of the parameters\n",
            "            and buffers in this module\n",
            "        dtype (:class:`torch.dtype`): the desired floating point type of\n",
            "            the floating point parameters and buffers in this module\n",
            "        tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
            "            dtype and device for all parameters and buffers in this module\n",
            "    \n",
            "    Returns:\n",
            "        Module: self\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> linear = nn.Linear(2, 2)\n",
            "        >>> linear.weight\n",
            "        Parameter containing:\n",
            "        tensor([[ 0.1913, -0.3420],\n",
            "                [-0.5113, -0.2325]])\n",
            "        >>> linear.to(torch.double)\n",
            "        Linear(in_features=2, out_features=2, bias=True)\n",
            "        >>> linear.weight\n",
            "        Parameter containing:\n",
            "        tensor([[ 0.1913, -0.3420],\n",
            "                [-0.5113, -0.2325]], dtype=torch.float64)\n",
            "        >>> gpu1 = torch.device(\"cuda:1\")\n",
            "        >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
            "        Linear(in_features=2, out_features=2, bias=True)\n",
            "        >>> linear.weight\n",
            "        Parameter containing:\n",
            "        tensor([[ 0.1914, -0.3420],\n",
            "                [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
            "        >>> cpu = torch.device(\"cpu\")\n",
            "        >>> linear.to(cpu)\n",
            "        Linear(in_features=2, out_features=2, bias=True)\n",
            "        >>> linear.weight\n",
            "        Parameter containing:\n",
            "        tensor([[ 0.1914, -0.3420],\n",
            "                [-0.5112, -0.2324]], dtype=torch.float16)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHDDIiXyDxe6",
        "colab_type": "code",
        "outputId": "2533a7d2-85e0-4d68-f226-ecf7843396c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "from transformers import TFCamembertForTokenClassification, CamembertTokenizer\n",
        "tokenizer = CamembertTokenizer\n",
        "#tfc = TFCamembertForTokenClassification\n",
        "tokenizer.tokenize(train_data[0][0])\n",
        "\n",
        "#dir(tfc.fit())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d5cc20027044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamembertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#tfc = TFCamembertForTokenClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#dir(tfc.fit())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tokenize() missing 1 required positional argument: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThZ_wWLDED1-",
        "colab_type": "code",
        "outputId": "7eeda565-8d82-4ebf-8e61-70947eb7eb49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TFCamembertForTokenClassification.from_pretrained()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class TFCamembertForTokenClassification in module transformers.modeling_tf_camembert:\n",
            "\n",
            "class TFCamembertForTokenClassification(transformers.modeling_tf_roberta.TFRobertaForTokenClassification)\n",
            " |  CamemBERT Model with a token classification head on top (a linear layer on top of\n",
            " |  the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. \n",
            " |  \n",
            " |  .. note::\n",
            " |  \n",
            " |      TF 2.0 models accepts two formats as inputs:\n",
            " |  \n",
            " |          - having all inputs as keyword arguments (like PyTorch models), or\n",
            " |          - having all inputs as a list, tuple or dict in the first positional arguments.\n",
            " |  \n",
            " |      This second option is useful when using :obj:`tf.keras.Model.fit()` method which currently requires having\n",
            " |      all the tensors in the first argument of the model call function: :obj:`model(inputs)`.\n",
            " |  \n",
            " |      If you choose this second option, there are three possibilities you can use to gather all the input Tensors\n",
            " |      in the first positional argument :\n",
            " |  \n",
            " |      - a single Tensor with input_ids only and nothing else: :obj:`model(inputs_ids)`\n",
            " |      - a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:\n",
            " |        :obj:`model([input_ids, attention_mask])` or :obj:`model([input_ids, attention_mask, token_type_ids])`\n",
            " |      - a dictionary with one or several input Tensors associated to the input names given in the docstring:\n",
            " |        :obj:`model({'input_ids': input_ids, 'token_type_ids': token_type_ids})`\n",
            " |  \n",
            " |  Parameters:\n",
            " |      config (:class:`~transformers.CamembertConfig`): Model configuration class with all the parameters of the\n",
            " |          model. Initializing with a config file does not load the weights associated with the model, only the configuration.\n",
            " |          Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.\n",
            " |  \n",
            " |  This class overrides :class:`~transformers.TFRobertaForTokenClassification`. Please check the\n",
            " |  superclass for the appropriate documentation alongside usage examples.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      TFCamembertForTokenClassification\n",
            " |      transformers.modeling_tf_roberta.TFRobertaForTokenClassification\n",
            " |      transformers.modeling_tf_roberta.TFRobertaPreTrainedModel\n",
            " |      transformers.modeling_tf_utils.TFPreTrainedModel\n",
            " |      tensorflow.python.keras.engine.training.Model\n",
            " |      tensorflow.python.keras.engine.network.Network\n",
            " |      tensorflow.python.keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
            " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
            " |      transformers.modeling_tf_utils.TFModelUtilsMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  config_class = <class 'transformers.configuration_camembert.CamembertC...\n",
            " |      This class overrides :class:`~transformers.RobertaConfig`. Please check the\n",
            " |      superclass for the appropriate documentation alongside usage examples.\n",
            " |  \n",
            " |  pretrained_model_archive_map = {}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from transformers.modeling_tf_roberta.TFRobertaForTokenClassification:\n",
            " |  \n",
            " |  __init__(self, config, *inputs, **kwargs)\n",
            " |  \n",
            " |  call(self, inputs, **kwargs)\n",
            " |      The :class:`~transformers.TFRobertaForTokenClassification` forward method, overrides the :func:`__call__` special method.\n",
            " |      \n",
            " |      .. note::\n",
            " |          Although the recipe for forward pass needs to be defined within\n",
            " |          this function, one should call the :class:`Module` instance afterwards\n",
            " |          instead of this since the former takes care of running the\n",
            " |          pre and post processing steps while the latter silently ignores them.\n",
            " |          \n",
            " |      Args:\n",
            " |          input_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length)`):\n",
            " |              Indices of input sequence tokens in the vocabulary.\n",
            " |      \n",
            " |              Indices can be obtained using :class:`transformers.RobertaTokenizer`.\n",
            " |              See :func:`transformers.PreTrainedTokenizer.encode` and\n",
            " |              :func:`transformers.PreTrainedTokenizer.encode_plus` for details.\n",
            " |      \n",
            " |              `What are input IDs? <../glossary.html#input-ids>`__\n",
            " |          attention_mask (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n",
            " |              Mask to avoid performing attention on padding token indices.\n",
            " |              Mask values selected in ``[0, 1]``:\n",
            " |              ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
            " |      \n",
            " |              `What are attention masks? <../glossary.html#attention-mask>`__\n",
            " |          token_type_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n",
            " |              Segment token indices to indicate first and second portions of the inputs.\n",
            " |              Indices are selected in ``[0, 1]``: ``0`` corresponds to a `sentence A` token, ``1``\n",
            " |              corresponds to a `sentence B` token\n",
            " |      \n",
            " |              `What are token type IDs? <../glossary.html#token-type-ids>`__\n",
            " |          position_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n",
            " |              Indices of positions of each input sequence tokens in the position embeddings.\n",
            " |              Selected in the range ``[0, config.max_position_embeddings - 1]``.\n",
            " |      \n",
            " |              `What are position IDs? <../glossary.html#position-ids>`__\n",
            " |          head_mask (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`, defaults to :obj:`None`):\n",
            " |              Mask to nullify selected heads of the self-attention modules.\n",
            " |              Mask values selected in ``[0, 1]``:\n",
            " |              :obj:`1` indicates the head is **not masked**, :obj:`0` indicates the head is **masked**.\n",
            " |          inputs_embeds (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length, embedding_dim)`, `optional`, defaults to :obj:`None`):\n",
            " |              Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\n",
            " |              This is useful if you want more control over how to convert `input_ids` indices into associated vectors\n",
            " |              than the model's internal embedding lookup matrix.\n",
            " |          training (:obj:`boolean`, `optional`, defaults to :obj:`False`):\n",
            " |              Whether to activate dropout modules (if set to :obj:`True`) during training or to de-activate them\n",
            " |              (if set to :obj:`False`) for evaluation.\n",
            " |      \n",
            " |      Return:\n",
            " |          :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.RobertaConfig`) and inputs:\n",
            " |          scores (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length, config.num_labels)`):\n",
            " |              Classification scores (before SoftMax).\n",
            " |          hidden_states (:obj:`tuple(tf.Tensor)`, `optional`, returned when :obj:`config.output_hidden_states=True`):\n",
            " |              tuple of :obj:`tf.Tensor` (one for the output of the embeddings + one for the output of each layer)\n",
            " |              of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
            " |      \n",
            " |              Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
            " |          attentions (:obj:`tuple(tf.Tensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
            " |              tuple of :obj:`tf.Tensor` (one for each layer) of shape\n",
            " |              :obj:`(batch_size, num_heads, sequence_length, sequence_length)`:\n",
            " |      \n",
            " |              Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          import tensorflow as tf\n",
            " |          from transformers import RobertaTokenizer, TFRobertaForTokenClassification\n",
            " |      \n",
            " |          tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
            " |          model = TFRobertaForTokenClassification.from_pretrained('roberta-base')\n",
            " |          input_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True))[None, :]  # Batch size 1\n",
            " |          outputs = model(input_ids)\n",
            " |          scores = outputs[0]\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from transformers.modeling_tf_roberta.TFRobertaPreTrainedModel:\n",
            " |  \n",
            " |  base_model_prefix = 'roberta'\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from transformers.modeling_tf_utils.TFPreTrainedModel:\n",
            " |  \n",
            " |  generate(self, input_ids=None, max_length=None, min_length=None, do_sample=None, early_stopping=None, num_beams=None, temperature=None, top_k=None, top_p=None, repetition_penalty=None, bad_words_ids=None, bos_token_id=None, pad_token_id=None, eos_token_id=None, length_penalty=None, no_repeat_ngram_size=None, num_return_sequences=None, attention_mask=None, decoder_start_token_id=None)\n",
            " |      Generates sequences for models with a LM head. The method currently supports greedy or penalized greedy decoding, sampling with top-k or nucleus sampling\n",
            " |      and beam-search.\n",
            " |      \n",
            " |      Adapted in part from `Facebook's XLM beam search code`_.\n",
            " |      \n",
            " |      .. _`Facebook's XLM beam search code`:\n",
            " |         https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n",
            " |      \n",
            " |      \n",
            " |      Parameters:\n",
            " |      \n",
            " |          input_ids: (`optional`) `tf.Tensor` of `dtype=tf.int32` of shape `(batch_size, sequence_length)`\n",
            " |              The sequence used as a prompt for the generation. If `None` the method initializes\n",
            " |              it as an empty `torch.LongTensor` of shape `(1,)`.\n",
            " |      \n",
            " |          max_length: (`optional`) int\n",
            " |              The max length of the sequence to be generated.  Between 1 and infinity. Default to 20.\n",
            " |      \n",
            " |          min_length: (`optional`) int\n",
            " |              The min length of the sequence to be generated.  Between 0 and infinity. Default to 0.\n",
            " |          do_sample: (`optional`) bool\n",
            " |              If set to `False` greedy decoding is used. Otherwise sampling is used. Defaults to `False` as defined in `configuration_utils.PretrainedConfig`.\n",
            " |      \n",
            " |          early_stopping: (`optional`) bool\n",
            " |              if set to `True` beam search is stopped when at least `num_beams` sentences finished per batch. Defaults to `False` as defined in `configuration_utils.PretrainedConfig`.\n",
            " |      \n",
            " |          num_beams: (`optional`) int\n",
            " |              Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n",
            " |      \n",
            " |          temperature: (`optional`) float\n",
            " |              The value used to module the next token probabilities. Must be strictely positive. Default to 1.0.\n",
            " |      \n",
            " |          top_k: (`optional`) int\n",
            " |              The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n",
            " |      \n",
            " |          top_p: (`optional`) float\n",
            " |              The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n",
            " |      \n",
            " |          repetition_penalty: (`optional`) float\n",
            " |              The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n",
            " |      \n",
            " |          bos_token_id: (`optional`) int\n",
            " |              Beginning of sentence token if no prompt is provided. Default to specicic model bos_token_id or None if it does not exist.\n",
            " |      \n",
            " |          pad_token_id: (`optional`) int\n",
            " |              Pad token. Defaults to pad_token_id as defined in the models config.\n",
            " |      \n",
            " |          eos_token_id: (`optional`) int\n",
            " |              EOS token. Defaults to eos_token_id as defined in the models config.\n",
            " |      \n",
            " |          length_penalty: (`optional`) float\n",
            " |              Exponential penalty to the length. Default to 1.\n",
            " |      \n",
            " |          no_repeat_ngram_size: (`optional`) int\n",
            " |              If set to int > 0, all ngrams of size `no_repeat_ngram_size` can only occur once.\n",
            " |      \n",
            " |          bad_words_ids: (`optional`) list of lists of int\n",
            " |              `bad_words_ids` contains tokens that are not allowed to be generated. In order to get the tokens of the words that should not appear in the generated text, use `tokenizer.encode(bad_word, add_prefix_space=True)`.\n",
            " |      \n",
            " |          num_return_sequences: (`optional`) int\n",
            " |              The number of independently computed returned sequences for each element in the batch. Default to 1.\n",
            " |      \n",
            " |          attention_mask (`optional`) obj: `tf.Tensor` with `dtype=tf.int32` of same shape as `input_ids`\n",
            " |              Mask to avoid performing attention on padding token indices.\n",
            " |              Mask values selected in ``[0, 1]``:\n",
            " |              ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
            " |              Defaults to `None`.\n",
            " |      \n",
            " |              `What are attention masks? <../glossary.html#attention-mask>`__\n",
            " |      \n",
            " |          decoder_start_token_id=None: (`optional`) int\n",
            " |              If an encoder-decoder model starts decoding with a different token than BOS.\n",
            " |              Defaults to `None` and is changed to `BOS` later.\n",
            " |      \n",
            " |      Return:\n",
            " |      \n",
            " |          output: `tf.Tensor` of `dtype=tf.int32` shape `(batch_size * num_return_sequences, sequence_length)`\n",
            " |              sequence_length is either equal to max_length or shorter if all batches finished early due to the `eos_token_id`\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n",
            " |          model = TFAutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n",
            " |          outputs = model.generate(max_length=40)  # do greedy decoding\n",
            " |          print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n",
            " |      \n",
            " |          tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n",
            " |          model = TFAutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n",
            " |          input_context = 'The dog'\n",
            " |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            " |          outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n",
            " |          for i in range(3): #  3 output sequences were generated\n",
            " |              print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n",
            " |      \n",
            " |          tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n",
            " |          model = TFAutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n",
            " |          input_context = 'The dog'\n",
            " |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            " |          outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, num_return_sequences=3)  # 3 generate sequences using by sampling\n",
            " |          for i in range(3): #  3 output sequences were generated\n",
            " |              print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n",
            " |      \n",
            " |          tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n",
            " |          model = TFAutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n",
            " |          input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n",
            " |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            " |          outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences\n",
            " |          print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n",
            " |      \n",
            " |          tokenizer = AutoTokenizer.from_pretrained('gpt2')   # Initialize tokenizer\n",
            " |          model = TFAutoModelWithLMHead.from_pretrained('gpt2')    # Download model and configuration from S3 and cache.\n",
            " |          input_context = 'My cute dog'  # \"Legal\" is one of the control codes for ctrl\n",
            " |          bad_words_ids = [tokenizer.encode(bad_word, add_prefix_space=True) for bad_word in ['idiot', 'stupid', 'shut up']]\n",
            " |          input_ids = tokenizer.encode(input_context, return_tensors='tf')  # encode input context\n",
            " |          outputs = model.generate(input_ids=input_ids, max_length=100, do_sample=True, bad_words_ids=bad_words_ids)  # generate sequences without allowing bad_words to be generated\n",
            " |  \n",
            " |  get_input_embeddings(self)\n",
            " |      Returns the model's input embeddings.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :obj:`tf.keras.layers.Layer`:\n",
            " |              A torch module mapping vocabulary to hidden states.\n",
            " |  \n",
            " |  get_output_embeddings(self)\n",
            " |      Returns the model's output embeddings.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :obj:`tf.keras.layers.Layer`:\n",
            " |              A torch module mapping hidden states to vocabulary.\n",
            " |  \n",
            " |  prepare_inputs_for_generation(self, inputs, **kwargs)\n",
            " |  \n",
            " |  prune_heads(self, heads_to_prune)\n",
            " |      Prunes heads of the base model.\n",
            " |      \n",
            " |      Arguments:\n",
            " |      \n",
            " |          heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n",
            " |  \n",
            " |  resize_token_embeddings(self, new_num_tokens=None)\n",
            " |      Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n",
            " |      Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n",
            " |      \n",
            " |      Arguments:\n",
            " |      \n",
            " |          new_num_tokens: (`optional`) int:\n",
            " |              New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n",
            " |              If not provided or None: does nothing and just returns a pointer to the input tokens ``tf.Variable`` Module of the model.\n",
            " |      \n",
            " |      Return: ``tf.Variable``\n",
            " |          Pointer to the input tokens Embeddings Module of the model\n",
            " |  \n",
            " |  save_pretrained(self, save_directory)\n",
            " |      Save a model and its configuration file to a directory, so that it\n",
            " |      can be re-loaded using the :func:`~transformers.PreTrainedModel.from_pretrained` class method.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from transformers.modeling_tf_utils.TFPreTrainedModel:\n",
            " |  \n",
            " |  from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs) from builtins.type\n",
            " |      Instantiate a pretrained TF 2.0 model from a pre-trained model configuration.\n",
            " |      \n",
            " |      The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n",
            " |      It is up to you to train those weights with a downstream fine-tuning task.\n",
            " |      \n",
            " |      The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          pretrained_model_name_or_path: either:\n",
            " |      \n",
            " |              - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n",
            " |              - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n",
            " |              - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n",
            " |              - a path or url to a `PyTorch state_dict save file` (e.g. `./pt_model/pytorch_model.bin`). In this case, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the PyTorch checkpoint in a TensorFlow model using the provided conversion scripts and loading the TensorFlow model afterwards.\n",
            " |      \n",
            " |          model_args: (`optional`) Sequence of positional arguments:\n",
            " |              All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n",
            " |      \n",
            " |          config: (`optional`) one of:\n",
            " |                  - an instance of a class derived from :class:`~transformers.PretrainedConfig`, or\n",
            " |                  - a string valid as input to :func:`~transformers.PretrainedConfig.from_pretrained()`\n",
            " |              Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n",
            " |      \n",
            " |              - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n",
            " |              - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n",
            " |              - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n",
            " |      \n",
            " |          from_pt: (`optional`) boolean, default False:\n",
            " |              Load the model weights from a PyTorch state_dict save file (see docstring of pretrained_model_name_or_path argument).\n",
            " |      \n",
            " |          cache_dir: (`optional`) string:\n",
            " |              Path to a directory in which a downloaded pre-trained model\n",
            " |              configuration should be cached if the standard cache should not be used.\n",
            " |      \n",
            " |          force_download: (`optional`) boolean, default False:\n",
            " |              Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n",
            " |      \n",
            " |          resume_download: (`optional`) boolean, default False:\n",
            " |              Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n",
            " |      \n",
            " |          proxies: (`optional`) dict, default None:\n",
            " |              A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n",
            " |              The proxies are used on each request.\n",
            " |      \n",
            " |          output_loading_info: (`optional`) boolean:\n",
            " |              Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n",
            " |      \n",
            " |          kwargs: (`optional`) Remaining dictionary of keyword arguments:\n",
            " |              Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n",
            " |      \n",
            " |              - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n",
            " |              - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          # For example purposes. Not runnable.\n",
            " |          model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n",
            " |          model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n",
            " |          model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n",
            " |          assert model.config.output_attention == True\n",
            " |          # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n",
            " |          config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n",
            " |          model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_pt=True, config=config)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from transformers.modeling_tf_utils.TFPreTrainedModel:\n",
            " |  \n",
            " |  dummy_inputs\n",
            " |      Dummy inputs to build the network.\n",
            " |      \n",
            " |      Returns:\n",
            " |          tf.Tensor with dummy inputs\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            " |  \n",
            " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, **kwargs)\n",
            " |      Configures the model for training.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          optimizer: String (name of optimizer) or optimizer instance.\n",
            " |              See `tf.keras.optimizers`.\n",
            " |          loss: String (name of objective function), objective function or\n",
            " |              `tf.keras.losses.Loss` instance. See `tf.keras.losses`.\n",
            " |              An objective function is any callable with the signature\n",
            " |              `loss = fn(y_true, y_pred)`, where\n",
            " |              y_true = ground truth values with shape = `[batch_size, d0, .. dN]`,\n",
            " |              except sparse loss functions such as sparse categorical crossentropy\n",
            " |              where shape = `[batch_size, d0, .. dN-1]`.\n",
            " |              y_pred = predicted values with shape = `[batch_size, d0, .. dN]`.\n",
            " |              It returns a weighted loss float tensor.\n",
            " |              If a custom `Loss` instance is used and reduction is set to NONE,\n",
            " |              return value has the shape [batch_size, d0, .. dN-1] ie. per-sample\n",
            " |              or per-timestep loss values; otherwise, it is a scalar.\n",
            " |              If the model has multiple outputs, you can use a different loss on\n",
            " |              each output by passing a dictionary or a list of losses. The loss\n",
            " |              value that will be minimized by the model will then be the sum of\n",
            " |              all individual losses.\n",
            " |          metrics: List of metrics to be evaluated by the model during training\n",
            " |              and testing.\n",
            " |              Each of this can be a string (name of a built-in function), function\n",
            " |              or a `tf.keras.metrics.Metric` instance. See `tf.keras.metrics`.\n",
            " |              Typically you will use `metrics=['accuracy']`. A function is any\n",
            " |              callable with the signature `result = fn(y_true, y_pred)`.\n",
            " |              To specify different metrics for different outputs of a\n",
            " |              multi-output model, you could also pass a dictionary, such as\n",
            " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
            " |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
            " |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
            " |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
            " |              When you pass the strings 'accuracy' or 'acc', we convert this to\n",
            " |              one of `tf.keras.metrics.BinaryAccuracy`,\n",
            " |              `tf.keras.metrics.CategoricalAccuracy`,\n",
            " |              `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
            " |              function used and the model output shape. We do a similar conversion\n",
            " |              for the strings 'crossentropy' and 'ce' as well.\n",
            " |          loss_weights: Optional list or dictionary specifying scalar\n",
            " |              coefficients (Python floats) to weight the loss contributions\n",
            " |              of different model outputs.\n",
            " |              The loss value that will be minimized by the model\n",
            " |              will then be the *weighted sum* of all individual losses,\n",
            " |              weighted by the `loss_weights` coefficients.\n",
            " |              If a list, it is expected to have a 1:1 mapping\n",
            " |              to the model's outputs. If a dict, it is expected to map\n",
            " |              output names (strings) to scalar coefficients.\n",
            " |          sample_weight_mode: If you need to do timestep-wise\n",
            " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
            " |              `None` defaults to sample-wise weights (1D).\n",
            " |              If the model has multiple outputs, you can use a different\n",
            " |              `sample_weight_mode` on each output by passing a\n",
            " |              dictionary or a list of modes.\n",
            " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
            " |              by sample_weight or class_weight during training and testing.\n",
            " |          **kwargs: Any additional arguments. For eager execution, pass\n",
            " |              `run_eagerly=True`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of invalid arguments for\n",
            " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors, if\n",
            " |            the model has named inputs. - A `tf.data` dataset. - A generator or\n",
            " |            `keras.utils.Sequence` instance. A more detailed description of\n",
            " |            unpacking behavior for iterator types (Dataset, generator, Sequence)\n",
            " |            is given in the `Unpacking behavior for iterator-like inputs` section\n",
            " |            of `Model.fit`.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            " |            should not be specified (since targets will be obtained from the\n",
            " |            iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per gradient update. If\n",
            " |            unspecified, `batch_size` will default to 32. Do not specify the\n",
            " |            `batch_size` if your data is in the form of a dataset, generators,\n",
            " |            or `keras.utils.Sequence` instances (since they generate batches).\n",
            " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            " |            used for weighting the loss function. You can either pass a flat (1D)\n",
            " |            Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |                temporal data, you can pass a 2D array with shape `(samples,\n",
            " |                sequence_length)`, to apply a different weight to every timestep\n",
            " |                of every sample. In this case you should make sure to specify\n",
            " |                `sample_weight_mode=\"temporal\"` in `compile()`. This argument is\n",
            " |                not supported when `x` is a dataset, instead pass sample weights\n",
            " |                as the third element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |            before declaring the evaluation round finished. Ignored with the\n",
            " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
            " |            argument is not supported with array inputs.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            " |            callbacks to apply during evaluation. See\n",
            " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |            input only. Maximum size for the generator queue. If unspecified,\n",
            " |            `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |            only. Maximum number of processes to spin up when using process-based\n",
            " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
            " |            execute the generator on the main thread.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |            threading. If unspecified, `use_multiprocessing` will default to\n",
            " |            `False`. Note that because this implementation relies on\n",
            " |            multiprocessing, you should not pass non-picklable arguments to the\n",
            " |            generator as they can't be passed easily to children processes.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: in case of invalid arguments.\n",
            " |  \n",
            " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Evaluates the model on a data generator. (deprecated)\n",
            " |      \n",
            " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Please use Model.evaluate, which supports generators.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
            " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given below.\n",
            " |          y: Target data. Like the input data `x`,\n",
            " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            " |            or `keras.utils.Sequence` instance, `y` should\n",
            " |            not be specified (since targets will be obtained from `x`).\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per gradient update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          epochs: Integer. Number of epochs to train the model.\n",
            " |              An epoch is an iteration over the entire `x` and `y`\n",
            " |              data provided.\n",
            " |              Note that in conjunction with `initial_epoch`,\n",
            " |              `epochs` is to be understood as \"final epoch\".\n",
            " |              The model is not trained for a number of iterations\n",
            " |              given by `epochs`, but merely until the epoch\n",
            " |              of index `epochs` is reached.\n",
            " |          verbose: 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            " |              Note that the progress bar is not particularly useful when\n",
            " |              logged to a file, so verbose=2 is recommended when not running\n",
            " |              interactively (eg, in a production environment).\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during training.\n",
            " |              See `tf.keras.callbacks`.\n",
            " |          validation_split: Float between 0 and 1.\n",
            " |              Fraction of the training data to be used as validation data.\n",
            " |              The model will set apart this fraction of the training data,\n",
            " |              will not train on it, and will evaluate\n",
            " |              the loss and any model metrics\n",
            " |              on this data at the end of each epoch.\n",
            " |              The validation data is selected from the last samples\n",
            " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
            " |              not supported when `x` is a dataset, generator or\n",
            " |             `keras.utils.Sequence` instance.\n",
            " |          validation_data: Data on which to evaluate\n",
            " |              the loss and any model metrics at the end of each epoch.\n",
            " |              The model will not be trained on this data.\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_data` could be:\n",
            " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
            " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
            " |                - dataset\n",
            " |      \n",
            " |              For the first two cases, `batch_size` must be provided.\n",
            " |              For the last case, `validation_steps` could be provided.\n",
            " |              Note that `validation_data` does not support all the data types that\n",
            " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
            " |          shuffle: Boolean (whether to shuffle the training data\n",
            " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
            " |              when `x` is a generator. 'batch' is a special option for dealing\n",
            " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) value, used for weighting the loss function\n",
            " |              (during training only).\n",
            " |              This can be useful to tell the model to\n",
            " |              \"pay more attention\" to samples from\n",
            " |              an under-represented class.\n",
            " |          sample_weight: Optional Numpy array of weights for\n",
            " |              the training samples, used for weighting the loss function\n",
            " |              (during training only). You can either pass a flat (1D)\n",
            " |              Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples),\n",
            " |              or in the case of temporal data,\n",
            " |              you can pass a 2D array with shape\n",
            " |              `(samples, sequence_length)`,\n",
            " |              to apply a different weight to every timestep of every sample.\n",
            " |              In this case you should make sure to specify\n",
            " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
            " |              supported when `x` is a dataset, generator, or\n",
            " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
            " |              as the third element of `x`.\n",
            " |          initial_epoch: Integer.\n",
            " |              Epoch at which to start training\n",
            " |              (useful for resuming a previous training run).\n",
            " |          steps_per_epoch: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              before declaring one epoch finished and starting the\n",
            " |              next epoch. When training with input tensors such as\n",
            " |              TensorFlow data tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If x is a\n",
            " |              `tf.data` dataset, and 'steps_per_epoch'\n",
            " |              is None, the epoch will run until the input dataset is exhausted.\n",
            " |              When passing an infinitely repeating dataset, you must specify the\n",
            " |              `steps_per_epoch` argument. This argument is not supported with\n",
            " |              array inputs.\n",
            " |          validation_steps: Only relevant if `validation_data` is provided and\n",
            " |              is a `tf.data` dataset. Total number of steps (batches of\n",
            " |              samples) to draw before stopping when performing validation\n",
            " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
            " |              will run until the `validation_data` dataset is exhausted. In the\n",
            " |              case of an infinitely repeated dataset, it will run into an\n",
            " |              infinite loop. If 'validation_steps' is specified and only part of\n",
            " |              the dataset will be consumed, the evaluation will start from the\n",
            " |              beginning of the dataset at each epoch. This ensures that the same\n",
            " |              validation samples are used every time.\n",
            " |          validation_batch_size: Integer or `None`.\n",
            " |              Number of samples per validation batch.\n",
            " |              If unspecified, will default to `batch_size`.\n",
            " |              Do not specify the `validation_batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          validation_freq: Only relevant if validation data is provided. Integer\n",
            " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
            " |              If an integer, specifies how many training epochs to run before a\n",
            " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
            " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
            " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
            " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up\n",
            " |              when using process-based threading. If unspecified, `workers`\n",
            " |              will default to 1. If 0, will execute the generator on the main\n",
            " |              thread.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |          **kwargs: Used for backwards compatibility.\n",
            " |      \n",
            " |      Unpacking behavior for iterator-like inputs:\n",
            " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
            " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
            " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
            " |        second and third elements will be used for y and sample_weight\n",
            " |        respectively. Any other type provided will be wrapped in a length one\n",
            " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
            " |        should still adhere to the top-level tuple structure.\n",
            " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            " |        features, targets, and weights from the keys of a single dict.\n",
            " |          A notable unsupported data type is the namedtuple. The reason is that\n",
            " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
            " |        datatype (dict). So given a namedtuple of the form:\n",
            " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            " |        it is ambiguous whether to reverse the order of the elements when\n",
            " |        interpreting the value. Even worse is a tuple of the form:\n",
            " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
            " |        and sample_weight or passed through as a single element to `x`. As a\n",
            " |        result the data processing code will simply raise a ValueError if it\n",
            " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `History` object. Its `History.history` attribute is\n",
            " |          a record of training loss values and metrics values\n",
            " |          at successive epochs, as well as validation loss values\n",
            " |          and validation metrics values (if applicable).\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If the model was never compiled.\n",
            " |          ValueError: In case of mismatch between the provided input data\n",
            " |              and what the model expects.\n",
            " |  \n",
            " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            " |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
            " |      \n",
            " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Please use Model.fit, which supports generators.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
            " |        this endpoint.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Retrieves the weights of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A flat list of Numpy arrays.\n",
            " |  \n",
            " |  load_weights(self, filepath, by_name=False, skip_mismatch=False)\n",
            " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
            " |      \n",
            " |      If `by_name` is False weights are loaded based on the network's\n",
            " |      topology. This means the architecture should be the same as when the weights\n",
            " |      were saved.  Note that layers that don't have weights are not taken into\n",
            " |      account in the topological ordering, so adding or removing layers is fine as\n",
            " |      long as they don't have weights.\n",
            " |      \n",
            " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
            " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
            " |      some of the layers have changed.\n",
            " |      \n",
            " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
            " |      from the TensorFlow format. Note that topological loading differs slightly\n",
            " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
            " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
            " |      TensorFlow format loads based on the object-local names of attributes to\n",
            " |      which layers are assigned in the `Model`'s constructor.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          filepath: String, path to the weights file to load. For weight files in\n",
            " |              TensorFlow format, this is the file prefix (the same as was passed\n",
            " |              to `save_weights`).\n",
            " |          by_name: Boolean, whether to load weights by name or by topological\n",
            " |              order. Only topological loading is supported for weight files in\n",
            " |              TensorFlow format.\n",
            " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
            " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
            " |              the weight (only valid when `by_name=True`).\n",
            " |      \n",
            " |      Returns:\n",
            " |          When loading a weight file in TensorFlow format, returns the same status\n",
            " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
            " |          ops are run automatically as soon as the network is built (on first call\n",
            " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
            " |          already built).\n",
            " |      \n",
            " |          When loading weights in HDF5 format, returns `None`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
            " |              format.\n",
            " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
            " |            `False`.\n",
            " |  \n",
            " |  make_predict_function(self)\n",
            " |      Creates a function that executes one step of inference.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.predict_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.predict` or\n",
            " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            " |  \n",
            " |  make_test_function(self)\n",
            " |      Creates a function that executes one step of evaluation.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.test_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.evaluate` or\n",
            " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            " |  \n",
            " |  make_train_function(self)\n",
            " |      Creates a function that executes one step of training.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            " |      logic to `Model.train_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.fit` or\n",
            " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for performance in\n",
            " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
            " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
            " |      inference.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input samples. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A `tf.data` dataset.\n",
            " |            - A generator or `keras.utils.Sequence` instance.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: Verbosity mode, 0 or 1.\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            " |              dataset and `steps` is None, `predict` will\n",
            " |              run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up when using\n",
            " |              process-based threading. If unspecified, `workers` will default\n",
            " |              to 1. If 0, will execute the generator on the main thread.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
            " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
            " |      three methods.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of mismatch between the provided\n",
            " |              input data and the model's expectations,\n",
            " |              or in case a stateful model receives a number of samples\n",
            " |              that is not a multiple of the batch size.\n",
            " |  \n",
            " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Generates predictions for the input samples from a data generator. (deprecated)\n",
            " |      \n",
            " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Please use Model.predict, which supports generators.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.predict` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of mismatch between given number of inputs and\n",
            " |            expectations of the model.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |      The logic for one inference step.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.make_predict_function`.\n",
            " |      \n",
            " |      This method should contain the mathemetical logic for one step of inference.\n",
            " |      This typically includes the forward pass.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_predict_function`, which can also be overridden.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of one inference step, typically the output of calling the\n",
            " |        `Model` on data.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |      Resets the state of metrics.\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors, if\n",
            " |            the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample. In this case you should make sure to specify\n",
            " |            sample_weight_mode=\"temporal\" in compile().\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of invalid user-provided arguments.\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |      The logic for one evaluation step.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.make_test_function`.\n",
            " |      \n",
            " |      This function should contain the mathemetical logic for one step of\n",
            " |      evaluation.\n",
            " |      This typically includes the forward pass, loss calculation, and metrics\n",
            " |      updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_test_function`, which can also be overridden.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned.\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample. In this case you should make sure to specify\n",
            " |            sample_weight_mode=\"temporal\" in compile().\n",
            " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
            " |            weight (float) to apply to the model's loss for the samples from this\n",
            " |            class during training. This can be useful to tell the model to \"pay\n",
            " |            more attention\" to samples from an under-represented class.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar training loss\n",
            " |          (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: In case of invalid user-provided arguments.\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |      The logic for one training step.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.make_train_function`.\n",
            " |      \n",
            " |      This method should contain the mathemetical logic for one step of training.\n",
            " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
            " |      and metric updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_train_function`, which can also be overridden.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |      The `tf.distribute.Strategy` this model was created under.\n",
            " |  \n",
            " |  metrics\n",
            " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
            " |      \n",
            " |      Note: `metrics` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.add_metric(\n",
            " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> _ = model.fit(x, (y, y), verbose=0)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc', 'mean']\n",
            " |  \n",
            " |  metrics_names\n",
            " |      Returns the model's display labels for all outputs.\n",
            " |      \n",
            " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> model.metrics_names\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> _ = model.fit(x, (y, y), verbose=0)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc']\n",
            " |  \n",
            " |  run_eagerly\n",
            " |      Settable attribute indicating whether the model should run eagerly.\n",
            " |      \n",
            " |      Running eagerly means that your model will be run step by step,\n",
            " |      like Python code. Your model might run slower, but it should become easier\n",
            " |      for you to debug it by stepping into individual layer calls.\n",
            " |      \n",
            " |      By default, we will attempt to compile your model to a static graph to\n",
            " |      deliver the best execution performance.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Boolean, whether the model should run eagerly.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  build(self, input_shape)\n",
            " |      Builds the model based on input shapes received.\n",
            " |      \n",
            " |      This is to be used for subclassed models, which do not know at instantiation\n",
            " |      time what their inputs look like.\n",
            " |      \n",
            " |      This method only exists for users who want to call `model.build()` in a\n",
            " |      standalone way (as a substitute for calling the model on real data to\n",
            " |      build it). It will never be called by the framework (and thus it will\n",
            " |      never throw unexpected errors in an unrelated workflow).\n",
            " |      \n",
            " |      Args:\n",
            " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
            " |           are tuples, integers, or TensorShapes.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          1. In case of invalid user-provided data (not of type tuple,\n",
            " |             list, or TensorShape).\n",
            " |          2. If the model requires call arguments that are agnostic\n",
            " |             to the input shapes (positional or kwarg in call signature).\n",
            " |          3. If not all layers were properly built.\n",
            " |          4. If float type inputs are not supported within the layers.\n",
            " |      \n",
            " |        In each of these cases, the user should build their model by calling it\n",
            " |        on real tensor data.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      If the layer has not been built, this method will call `build` on the\n",
            " |      layer. This assumes that the layer will later be used with inputs that\n",
            " |      match the input shape provided here.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of invalid layer name or index.\n",
            " |  \n",
            " |  reset_states(self)\n",
            " |  \n",
            " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
            " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
            " |      \n",
            " |      The savefile includes:\n",
            " |          - The model architecture, allowing to re-instantiate the model.\n",
            " |          - The model weights.\n",
            " |          - The state of the optimizer, allowing to resume training\n",
            " |              exactly where you left off.\n",
            " |      \n",
            " |      This allows you to save the entirety of the state of a model\n",
            " |      in a single file.\n",
            " |      \n",
            " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
            " |      The model returned by `load_model` is a compiled model ready to be used\n",
            " |      (unless the saved model was never compiled in the first place).\n",
            " |      \n",
            " |      Models built with the Sequential and Functional API can be saved to both the\n",
            " |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
            " |      SavedModel format.\n",
            " |      \n",
            " |      Note that the model weights may have different scoped names after being\n",
            " |      loaded. Scoped names include the model/layer names, such as\n",
            " |      \"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n",
            " |       access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          filepath: String, path to SavedModel or H5 file to save the model.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          include_optimizer: If True, save optimizer's state together.\n",
            " |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
            " |              to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X, and\n",
            " |              'h5' in TF 1.X.\n",
            " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
            " |              'tf' format only. Please see the `signatures` argument in\n",
            " |              `tf.saved_model.save` for details.\n",
            " |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
            " |              options for saving to SavedModel.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      from keras.models import load_model\n",
            " |      \n",
            " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
            " |      del model  # deletes the existing model\n",
            " |      \n",
            " |      # returns a compiled model\n",
            " |      # identical to the previous one\n",
            " |      model = load_model('my_model.h5')\n",
            " |      ```\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
            " |      Saves all layer weights.\n",
            " |      \n",
            " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            " |      argument.\n",
            " |      \n",
            " |      When saving in HDF5 format, the weight file has:\n",
            " |        - `layer_names` (attribute), a list of strings\n",
            " |            (ordered names of model layers).\n",
            " |        - For every layer, a `group` named `layer.name`\n",
            " |            - For every such layer group, a group attribute `weight_names`,\n",
            " |                a list of strings\n",
            " |                (ordered names of weights tensor of the layer).\n",
            " |            - For every weight in the layer, a dataset\n",
            " |                storing the weight value, named after the weight tensor.\n",
            " |      \n",
            " |      When saving in TensorFlow format, all objects referenced by the network are\n",
            " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
            " |      instances or `Optimizer` instances assigned to object attributes. For\n",
            " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
            " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
            " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
            " |      `Layer` instances must be assigned to object attributes, typically in the\n",
            " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
            " |      `tf.keras.Model` for details.\n",
            " |      \n",
            " |      While the formats are the same, do not mix `save_weights` and\n",
            " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
            " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
            " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            " |      `save_weights` for training checkpoints.\n",
            " |      \n",
            " |      The TensorFlow format matches objects and variables by starting at a root\n",
            " |      object, `self` for `save_weights`, and greedily matching attribute\n",
            " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
            " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
            " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
            " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
            " |      the `Model`'s variables. See the [guide to training\n",
            " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
            " |      on the TensorFlow format.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          filepath: String, path to the file to save the weights to. When saving\n",
            " |              in TensorFlow format, this is the prefix used for checkpoint files\n",
            " |              (multiple files are generated). Note that the '.h5' suffix causes\n",
            " |              weights to be saved in HDF5 format.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
            " |              `None` defaults to 'tf'.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
            " |              format.\n",
            " |          ValueError: For invalid/unknown format arguments.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
            " |      Prints a string summary of the network.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          line_length: Total length of printed lines\n",
            " |              (e.g. set this to adapt the display to different\n",
            " |              terminal window sizes).\n",
            " |          positions: Relative or absolute positions of log elements\n",
            " |              in each line. If not provided,\n",
            " |              defaults to `[.33, .55, .67, 1.]`.\n",
            " |          print_fn: Print function to use. Defaults to `print`.\n",
            " |              It will be called on each line of the summary.\n",
            " |              You can set it to a custom function\n",
            " |              in order to capture the string summary.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if `summary()` is called before the model is built.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  to_yaml(self, **kwargs)\n",
            " |      Returns a yaml string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a yaml save file, use\n",
            " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            " |      \n",
            " |      `custom_objects` should be a dictionary mapping\n",
            " |      the names of custom losses / layers / etc to the corresponding\n",
            " |      functions / classes.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `yaml.dump()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A YAML string.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: if yaml module is not found.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.keras.engine.network.Network:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Instantiates a Model from its config (output of `get_config()`).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          config: Model config dictionary.\n",
            " |          custom_objects: Optional dictionary mapping names\n",
            " |              (strings) to custom classes or functions to be\n",
            " |              considered during deserialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A model instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of improperly formatted config dict.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  input_spec\n",
            " |      Gets the network's input specs.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of `InputSpec` instances (one per input to the model)\n",
            " |              or a single instance if the model has only one input.\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  state_updates\n",
            " |      Returns the `updates` from all layers that are stateful.\n",
            " |      \n",
            " |      This is useful for separating training updates and\n",
            " |      state updates, e.g. when we need to update a layer's internal state\n",
            " |      during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of update ops.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        *args: Positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, inputs=None)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(inputs, self):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
            " |      specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
            " |          passed, it signals the losses are conditional on some of the layer's\n",
            " |          inputs, and thus they should only be run where these inputs are\n",
            " |          available. This is the case for activity regularization losses, for\n",
            " |          instance. If `None` is passed, the losses are assumed\n",
            " |          to be unconditional, and will apply across all dataflows of the layer\n",
            " |          (e.g. weight regularization losses).\n",
            " |  \n",
            " |  add_metric(self, value, aggregation=None, name=None)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
            " |          it indicates that the metric tensor provided has been aggregated\n",
            " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
            " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
            " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
            " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
            " |          aggregation='mean')`.\n",
            " |        name: String metric name.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
            " |      \n",
            " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      `inputs` is now automatically inferred\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
            " |      specific set of inputs.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Arguments:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
            " |      \n",
            " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Please use `layer.add_weight` method instead.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
            " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
            " |        instance is returned.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called with partitioned variable regularization and\n",
            " |          eager execution is enabled.\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! (deprecated)\n",
            " |      \n",
            " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Please use `layer.__call__` method instead.\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from Numpy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a Dense layer returns a list of two values-- per-output\n",
            " |      weights and the bias value. These can be used to set the weights of another\n",
            " |      Dense layer:\n",
            " |      \n",
            " |      >>> a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> b.set_weights(a.get_weights())\n",
            " |      >>> b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Arguments:\n",
            " |          weights: a list of Numpy arrays. The number\n",
            " |              of arrays and their shape must match\n",
            " |              number of the dimensions of the weights\n",
            " |              of the layer (i.e. it should match the\n",
            " |              output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: If the provided weights list does not match the\n",
            " |              layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  dtype\n",
            " |      Dtype used by the weights of the layer, set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  losses\n",
            " |      Losses which are associated with this `Layer`.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from tensorflow.python.keras.utils.version_utils.LayerVersionSelector:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from transformers.modeling_tf_utils.TFModelUtilsMixin:\n",
            " |  \n",
            " |  num_parameters(self, only_trainable:bool=False) -> int\n",
            " |      Get number of (optionally, trainable) parameters in the model.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbnK0dRhEoFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}